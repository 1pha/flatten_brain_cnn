{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:17:23.339118Z",
     "start_time": "2020-07-18T08:17:20.837898Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:17:23.343108Z",
     "start_time": "2020-07-18T08:17:23.340115Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read-in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:17:23.384996Z",
     "start_time": "2020-07-18T08:17:23.346100Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH = '../res/npy_img/left/'\n",
    "files = glob(PATH+'*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:17:23.623358Z",
     "start_time": "2020-07-18T08:17:23.385994Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = torch.tensor(np.load(files[0]))\n",
    "x, y, f = np.load(files[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:17:23.629342Z",
     "start_time": "2020-07-18T08:17:23.624356Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_loader(files):\n",
    "    out = []\n",
    "    x, y, f = np.load(files[0]).shape\n",
    "    for file in tqdm(files):\n",
    "        file = np.load(file)\n",
    "        out.append(file.transpose(2, 0, 1))\n",
    "    out = np.array(out)\n",
    "    return torch.tensor(out, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:17:23.648292Z",
     "start_time": "2020-07-18T08:17:23.630340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 375, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(files[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:17:52.032493Z",
     "start_time": "2020-07-18T08:17:23.649289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044208fbf9f44d79ad4d67a79b93856d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=867.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = data_loader(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:17:52.061417Z",
     "start_time": "2020-07-18T08:17:52.034489Z"
    }
   },
   "outputs": [],
   "source": [
    "label = pd.read_csv('../res/age_balanced.csv', index_col=0)\n",
    "y_multi = torch.tensor(label.multiclass.values)\n",
    "y_binary = torch.tensor(label.binary.values)\n",
    "y_reg = torch.tensor(label.age.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:17:52.066402Z",
     "start_time": "2020-07-18T08:17:52.063411Z"
    }
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:17:52.725147Z",
     "start_time": "2020-07-18T08:17:52.068398Z"
    }
   },
   "outputs": [],
   "source": [
    "# Binary\n",
    "X_train, X_test, y_binary_train, y_binary_test = train_test_split(X, y_binary,\n",
    "                                                                  test_size=0.2, random_state=SEED)\n",
    "train_binary_ds = TensorDataset(X_train, y_binary_train)\n",
    "test_binary_ds = TensorDataset(X_test, y_binary_test)\n",
    "train_binary_loader = DataLoader(train_binary_ds, batch_size=64, shuffle=True)\n",
    "test_binary_loader = DataLoader(test_binary_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "sample_multi_ds = TensorDataset(X_train[2:4], y_binary_train[2:4])\n",
    "sample_multi_loader = DataLoader(sample_multi_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:17:53.364436Z",
     "start_time": "2020-07-18T08:17:52.726145Z"
    }
   },
   "outputs": [],
   "source": [
    "# Binary\n",
    "X_train, X_test, y_multi_train, y_multi_test = train_test_split(X, y_multi,\n",
    "                                                                test_size=0.2, random_state=SEED)\n",
    "train_multi_ds = TensorDataset(X_train, y_multi_train)\n",
    "test_multi_ds = TensorDataset(X_test, y_multi_test)\n",
    "train_multi_loader = DataLoader(train_multi_ds, batch_size=128, shuffle=True)\n",
    "test_multi_loader = DataLoader(test_multi_ds, batch_size=128, shuffle=True)\n",
    "\n",
    "sample_binary_ds = TensorDataset(X_train[2:4], y_binary_train[2:4])\n",
    "sample_binary_loader = DataLoader(sample_binary_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:18:15.681930Z",
     "start_time": "2020-07-18T08:18:09.291461Z"
    }
   },
   "outputs": [],
   "source": [
    "# Binary\n",
    "X_train, X_test, y_reg_train, y_reg_test = train_test_split(X, y_reg,\n",
    "                                                            test_size=0.2, random_state=SEED)\n",
    "train_reg_ds = TensorDataset(X_train, y_reg_train)\n",
    "test_reg_ds = TensorDataset(X_test, y_reg_test)\n",
    "train_reg_loader = DataLoader(train_reg_ds, batch_size=128, shuffle=True)\n",
    "test_reg_loader = DataLoader(test_reg_ds, batch_size=128, shuffle=True)\n",
    "\n",
    "sample_reg_ds = TensorDataset(X_train[2:4], y_reg_train[2:4])\n",
    "sample_reg_loader = DataLoader(sample_reg_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions in Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:18:15.705866Z",
     "start_time": "2020-07-18T08:18:15.692901Z"
    }
   },
   "outputs": [],
   "source": [
    "def count(y_pred, y_true):\n",
    "    y_pred_ = y_pred.argmax(axis=1)\n",
    "    \n",
    "    corr = 0\n",
    "    for p, t in zip(y_pred_, y_true):\n",
    "        if p == t:\n",
    "            corr += 1\n",
    "            \n",
    "    return corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:18:15.725813Z",
     "start_time": "2020-07-18T08:18:15.708858Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, ctype):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.ctype = ctype\n",
    "        if self.ctype=='binary':\n",
    "            out_node = 1\n",
    "            self.last_layer = F.sigmoid\n",
    "        elif self.ctype=='multi':\n",
    "            out_node = 10\n",
    "            self.last_layer = F.softmax\n",
    "        elif self.ctype=='regression':\n",
    "            out_node = 1\n",
    "            self.last_layer = nn.Identity(x)\n",
    "        else:\n",
    "            print(\"Put either 'binary' or 'multi'\")\n",
    "        \n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(6, 10, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(10),\n",
    "            nn.Dropout(.2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(10, 20, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(20),\n",
    "            nn.Dropout(.2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(20, 40, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(40),\n",
    "            nn.Dropout(.2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.fc1 = nn.Linear(480, 100)\n",
    "        self.fc2 = nn.Linear(100, out_node)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.last_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions need in Future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:18:15.731797Z",
     "start_time": "2020-07-18T08:18:15.727808Z"
    }
   },
   "outputs": [],
   "source": [
    "def acc_multi(pred, true):\n",
    "    result = 0\n",
    "    cnt = 0\n",
    "    for p, t in zip(pred.argmax(axis=1), true):\n",
    "        cnt += 1\n",
    "        if p == t:\n",
    "            result += 1\n",
    "            \n",
    "    return result, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:18:15.740772Z",
     "start_time": "2020-07-18T08:18:15.733792Z"
    }
   },
   "outputs": [],
   "source": [
    "def acc_binary(pred, true):\n",
    "    correct, cnt = 0, 0\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for p, t in zip(pred, true):\n",
    "        cnt += 1\n",
    "        if (p >= 0.5) & (t == 1):\n",
    "            correct += 1\n",
    "            tp += 1\n",
    "            \n",
    "        elif (p >= 0.5) & (t == 0):\n",
    "            fp += 1\n",
    "            \n",
    "        elif (p < 0.5) & (t == 1):\n",
    "            tn += 1\n",
    "            \n",
    "        elif (p < 0.5) & (t == 0):\n",
    "            correct += 1\n",
    "            fn += 1\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return correct, cnt, np.array([tp, tn, fp, fn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:18:15.749749Z",
     "start_time": "2020-07-18T08:18:15.741770Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_binary(data):\n",
    "    result = []\n",
    "    for d in data:\n",
    "        if d >= 0.5:\n",
    "            result.append(1)\n",
    "        elif d < 0.5:\n",
    "            result.append(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:18:15.934256Z",
     "start_time": "2020-07-18T08:18:15.751744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3502]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.4517]], grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "conv = ConvNet(ctype='binary')\n",
    "for x, y in sample_binary_loader:\n",
    "    print(conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:18:21.649179Z",
     "start_time": "2020-07-18T08:18:15.936251Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 1, 1, 9, 5, 9, 1, 9, 9, 7, 1, 7, 0, 5,\n",
      "        1, 7, 9, 9, 9, 9, 5, 0, 5, 9, 9, 1, 9, 7, 9, 0, 9, 5, 9, 9, 9, 9, 9, 5,\n",
      "        7, 0, 0, 9, 9, 5, 9, 9, 1, 9, 9, 9, 9, 1, 0, 1, 9, 9, 9, 7, 1, 9, 9, 9,\n",
      "        9, 9, 7, 9, 1, 0, 0, 9, 9, 9, 9, 9, 7, 0, 9, 1, 0, 9, 9, 9, 9, 7, 9, 5,\n",
      "        9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 5, 9, 0, 9, 9, 9, 9, 1, 9, 9, 9, 9, 5, 5,\n",
      "        1, 1, 1, 9, 9, 5, 5, 9], grad_fn=<NotImplemented>)\n",
      "tensor([7, 9, 0, 7, 9, 7, 9, 9, 9, 7, 9, 9, 0, 9, 9, 1, 9, 0, 9, 1, 0, 0, 5, 9,\n",
      "        9, 0, 0, 9, 9, 3, 0, 1, 9, 1, 9, 9, 9, 7, 9, 9, 9, 9, 0, 9, 7, 9, 5, 9,\n",
      "        1, 0, 0, 0, 9, 9, 9, 5, 9, 9, 9, 1, 1, 9, 9, 5, 9, 0, 9, 9, 1, 9, 9, 9,\n",
      "        9, 9, 9, 9, 9, 5, 9, 0, 0, 9, 9, 9, 7, 9, 9, 0, 9, 0, 9, 9, 0, 9, 0, 9,\n",
      "        9, 9, 9, 9, 9, 5, 5, 5, 9, 5, 1, 9, 9, 9, 9, 0, 9, 0, 9, 9, 0, 1, 0, 9,\n",
      "        3, 9, 9, 9, 9, 7, 7, 0], grad_fn=<NotImplemented>)\n",
      "tensor([9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 7, 9, 9, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "        9, 7, 0, 0, 9, 9, 0, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9,\n",
      "        9, 9, 0, 9, 1, 5, 9, 0, 9, 9, 1, 9, 7, 9, 0, 1, 9, 9, 9, 9, 3, 9, 0, 9,\n",
      "        9, 9, 0, 5, 1, 9, 9, 9, 7, 9, 9, 5, 0, 9, 0, 9, 5, 1, 9, 5, 1, 9, 1, 9,\n",
      "        1, 9, 9, 5, 9, 9, 9, 7, 0, 1, 7, 7, 9, 1, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9,\n",
      "        9, 9, 9, 3, 9, 9, 9, 9], grad_fn=<NotImplemented>)\n",
      "tensor([9, 9, 9, 9, 7, 1, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 3, 9, 9, 7, 9, 9, 9, 7,\n",
      "        9, 9, 1, 9, 5, 9, 9, 9, 9, 1, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0,\n",
      "        9, 9, 9, 9, 1, 9, 5, 9, 7, 9, 9, 7, 9, 0, 1, 9, 9, 9, 0, 0, 9, 5, 9, 9,\n",
      "        9, 9, 9, 9, 9, 1, 9, 0, 9, 0, 9, 1, 9, 1, 9, 9, 7, 0, 7, 1, 9, 9, 1, 5,\n",
      "        9, 9, 9, 9, 9, 9, 9, 5, 9, 1, 9, 5, 9, 0, 9, 1, 9, 9, 9, 9, 9, 1, 7, 5,\n",
      "        9, 9, 9, 9, 1, 9, 9, 9], grad_fn=<NotImplemented>)\n",
      "tensor([0, 0, 0, 9, 9, 9, 9, 9, 9, 5, 1, 9, 9, 9, 9, 9, 9, 0, 1, 9, 9, 9, 9, 5,\n",
      "        9, 9, 9, 0, 0, 0, 5, 1, 5, 9, 9, 9, 0, 9, 0, 7, 9, 9, 0, 9, 9, 9, 1, 9,\n",
      "        1, 9, 9, 5, 0, 7, 5, 9, 5, 9, 9, 9, 9, 9, 5, 9, 1, 9, 1, 9, 9, 9, 9, 5,\n",
      "        9, 1, 5, 9, 9, 0, 0, 9, 9, 1, 0, 5, 9, 9, 9, 9, 9, 7, 9, 0, 9, 1, 9, 0,\n",
      "        5, 9, 3, 7, 0, 9, 9, 9, 0, 1, 7, 1, 1, 9, 9, 9, 9, 9, 0, 7, 7, 7, 0, 9,\n",
      "        9, 9, 9, 9, 9, 9, 1, 9], grad_fn=<NotImplemented>)\n",
      "tensor([9, 5, 9, 9, 0, 9, 9, 9, 9, 9, 7, 7, 9, 9, 9, 9, 0, 5, 0, 9, 9, 1, 9, 1,\n",
      "        5, 0, 9, 5, 5, 9, 9, 7, 0, 9, 9, 7, 9, 9, 0, 9, 9, 9, 9, 9, 0, 7, 7, 0,\n",
      "        9, 5, 9, 9, 9], grad_fn=<NotImplemented>)\n"
     ]
    }
   ],
   "source": [
    "conv = ConvNet(ctype='multi')\n",
    "for x, y in sample_multi_loader:\n",
    "    print(conv(x).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:18:38.840791Z",
     "start_time": "2020-07-18T08:18:38.794914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0081]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.2678]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "conv = ConvNet(ctype='regression')\n",
    "for x, y in sample_reg_loader:\n",
    "    print(conv(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:05:06.103593Z",
     "start_time": "2020-07-18T08:05:06.099604Z"
    }
   },
   "outputs": [],
   "source": [
    "multi_weight = sorted(Counter(label.multiclass).items(), key=(lambda x: x[0]))\n",
    "multi_weight = 1 / np.array([w[1] for w in multi_weight])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T08:05:06.358912Z",
     "start_time": "2020-07-18T08:05:06.354923Z"
    }
   },
   "outputs": [],
   "source": [
    "binary_weight = sorted(Counter(label.binary).items(), key=(lambda x: x[0]))\n",
    "binary_weight = 1 / np.array([w[1] for w in binary_weight])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T12:09:25.264905Z",
     "start_time": "2020-07-16T07:27:48.306137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 0th Fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "[LOSS] train: 11.538, val: 2.312\n",
      "[ACC%] train: 10.59%, val: 5.71%\n",
      "EPOCH: 1\n",
      "[LOSS] train: 11.542, val: 2.315\n",
      "[ACC%] train: 7.7%, val: 7.14%\n",
      "EPOCH: 2\n",
      "[LOSS] train: 11.588, val: 2.319\n",
      "[ACC%] train: 8.99%, val: 7.14%\n",
      "EPOCH: 3\n",
      "[LOSS] train: 11.556, val: 2.31\n",
      "[ACC%] train: 7.7%, val: 10.0%\n",
      "EPOCH: 4\n",
      "[LOSS] train: 11.539, val: 2.326\n",
      "[ACC%] train: 9.15%, val: 4.29%\n",
      "EPOCH: 5\n",
      "[LOSS] train: 11.5, val: 2.317\n",
      "[ACC%] train: 9.95%, val: 4.29%\n",
      "EPOCH: 6\n",
      "[LOSS] train: 11.51, val: 2.314\n",
      "[ACC%] train: 9.79%, val: 5.71%\n",
      "EPOCH: 7\n",
      "[LOSS] train: 11.507, val: 2.301\n",
      "[ACC%] train: 10.43%, val: 18.57%\n",
      "EPOCH: 8\n",
      "[LOSS] train: 11.521, val: 2.303\n",
      "[ACC%] train: 10.11%, val: 18.57%\n",
      "EPOCH: 9\n",
      "[LOSS] train: 11.506, val: 2.32\n",
      "[ACC%] train: 10.75%, val: 7.14%\n",
      "EPOCH: 10\n",
      "[LOSS] train: 11.491, val: 2.319\n",
      "[ACC%] train: 10.91%, val: 4.29%\n",
      "EPOCH: 11\n",
      "[LOSS] train: 11.497, val: 2.315\n",
      "[ACC%] train: 11.56%, val: 7.14%\n",
      "EPOCH: 12\n",
      "[LOSS] train: 11.502, val: 2.307\n",
      "[ACC%] train: 10.27%, val: 7.14%\n",
      "EPOCH: 13\n",
      "[LOSS] train: 11.478, val: 2.304\n",
      "[ACC%] train: 12.68%, val: 10.0%\n",
      "EPOCH: 14\n",
      "[LOSS] train: 11.495, val: 2.313\n",
      "[ACC%] train: 11.72%, val: 7.14%\n",
      "EPOCH: 15\n",
      "[LOSS] train: 11.452, val: 2.32\n",
      "[ACC%] train: 13.64%, val: 10.0%\n",
      "EPOCH: 16\n",
      "[LOSS] train: 11.421, val: 2.32\n",
      "[ACC%] train: 15.73%, val: 10.0%\n",
      "EPOCH: 17\n",
      "[LOSS] train: 11.394, val: 2.318\n",
      "[ACC%] train: 16.37%, val: 10.0%\n",
      "EPOCH: 18\n",
      "[LOSS] train: 11.401, val: 2.324\n",
      "[ACC%] train: 15.41%, val: 10.0%\n",
      "EPOCH: 19\n",
      "[LOSS] train: 11.34, val: 2.324\n",
      "[ACC%] train: 16.85%, val: 10.0%\n",
      "EPOCH: 20\n",
      "[LOSS] train: 11.286, val: 2.344\n",
      "[ACC%] train: 19.58%, val: 5.71%\n",
      "EPOCH: 21\n",
      "[LOSS] train: 11.308, val: 2.387\n",
      "[ACC%] train: 17.34%, val: 4.29%\n",
      "EPOCH: 22\n",
      "[LOSS] train: 11.233, val: 2.397\n",
      "[ACC%] train: 19.26%, val: 4.29%\n",
      "EPOCH: 23\n",
      "[LOSS] train: 11.229, val: 2.344\n",
      "[ACC%] train: 18.78%, val: 5.71%\n",
      "EPOCH: 24\n",
      "[LOSS] train: 11.198, val: 2.347\n",
      "[ACC%] train: 19.9%, val: 8.57%\n",
      "EPOCH: 25\n",
      "[LOSS] train: 11.262, val: 2.315\n",
      "[ACC%] train: 18.46%, val: 12.86%\n",
      "EPOCH: 26\n",
      "[LOSS] train: 11.233, val: 2.334\n",
      "[ACC%] train: 20.06%, val: 8.57%\n",
      "EPOCH: 27\n",
      "[LOSS] train: 11.204, val: 2.356\n",
      "[ACC%] train: 20.71%, val: 10.0%\n",
      "EPOCH: 28\n",
      "[LOSS] train: 11.205, val: 2.342\n",
      "[ACC%] train: 18.46%, val: 5.71%\n",
      "EPOCH: 29\n",
      "[LOSS] train: 11.165, val: 2.367\n",
      "[ACC%] train: 21.19%, val: 5.71%\n",
      "EPOCH: 30\n",
      "[LOSS] train: 11.089, val: 2.41\n",
      "[ACC%] train: 23.27%, val: 4.29%\n",
      "EPOCH: 31\n",
      "[LOSS] train: 11.077, val: 2.415\n",
      "[ACC%] train: 22.63%, val: 4.29%\n",
      "EPOCH: 32\n",
      "[LOSS] train: 11.021, val: 2.388\n",
      "[ACC%] train: 23.43%, val: 5.71%\n",
      "EPOCH: 33\n",
      "[LOSS] train: 11.026, val: 2.342\n",
      "[ACC%] train: 24.4%, val: 11.43%\n",
      "EPOCH: 34\n",
      "[LOSS] train: 10.953, val: 2.373\n",
      "[ACC%] train: 27.45%, val: 7.14%\n",
      "EPOCH: 35\n",
      "[LOSS] train: 10.881, val: 2.375\n",
      "[ACC%] train: 27.45%, val: 7.14%\n",
      "EPOCH: 36\n",
      "[LOSS] train: 10.868, val: 2.371\n",
      "[ACC%] train: 28.25%, val: 7.14%\n",
      "EPOCH: 37\n",
      "[LOSS] train: 10.827, val: 2.375\n",
      "[ACC%] train: 28.89%, val: 7.14%\n",
      "EPOCH: 38\n",
      "[LOSS] train: 10.937, val: 2.375\n",
      "[ACC%] train: 24.88%, val: 7.14%\n",
      "EPOCH: 39\n",
      "[LOSS] train: 10.761, val: 2.375\n",
      "[ACC%] train: 30.66%, val: 7.14%\n",
      "EPOCH: 40\n",
      "[LOSS] train: 10.771, val: 2.375\n",
      "[ACC%] train: 29.37%, val: 7.14%\n",
      "EPOCH: 41\n",
      "[LOSS] train: 10.701, val: 2.375\n",
      "[ACC%] train: 31.46%, val: 7.14%\n",
      "EPOCH: 42\n",
      "[LOSS] train: 10.683, val: 2.375\n",
      "[ACC%] train: 30.82%, val: 7.14%\n",
      "EPOCH: 43\n",
      "[LOSS] train: 10.645, val: 2.375\n",
      "[ACC%] train: 32.1%, val: 7.14%\n",
      "EPOCH: 44\n",
      "[LOSS] train: 10.652, val: 2.375\n",
      "[ACC%] train: 32.26%, val: 7.14%\n",
      "EPOCH: 45\n",
      "[LOSS] train: 10.478, val: 2.375\n",
      "[ACC%] train: 36.6%, val: 7.14%\n",
      "EPOCH: 46\n",
      "[LOSS] train: 10.489, val: 2.375\n",
      "[ACC%] train: 34.83%, val: 7.14%\n",
      "EPOCH: 47\n",
      "[LOSS] train: 10.396, val: 2.376\n",
      "[ACC%] train: 38.04%, val: 7.14%\n",
      "EPOCH: 48\n",
      "[LOSS] train: 10.453, val: 2.405\n",
      "[ACC%] train: 36.28%, val: 2.86%\n",
      "EPOCH: 49\n",
      "[LOSS] train: 10.344, val: 2.4\n",
      "[ACC%] train: 39.49%, val: 2.86%\n",
      "EPOCH: 50\n",
      "[LOSS] train: 10.262, val: 2.376\n",
      "[ACC%] train: 39.0%, val: 7.14%\n",
      "EPOCH: 51\n",
      "[LOSS] train: 10.298, val: 2.375\n",
      "[ACC%] train: 39.81%, val: 7.14%\n",
      "EPOCH: 52\n",
      "[LOSS] train: 10.227, val: 2.375\n",
      "[ACC%] train: 41.89%, val: 7.14%\n",
      "EPOCH: 53\n",
      "[LOSS] train: 10.194, val: 2.368\n",
      "[ACC%] train: 41.73%, val: 7.14%\n",
      "EPOCH: 54\n",
      "[LOSS] train: 10.107, val: 2.375\n",
      "[ACC%] train: 44.94%, val: 7.14%\n",
      "EPOCH: 55\n",
      "[LOSS] train: 10.192, val: 2.375\n",
      "[ACC%] train: 41.09%, val: 7.14%\n",
      "EPOCH: 56\n",
      "[LOSS] train: 10.113, val: 2.375\n",
      "[ACC%] train: 43.02%, val: 7.14%\n",
      "EPOCH: 57\n",
      "[LOSS] train: 10.087, val: 2.375\n",
      "[ACC%] train: 45.91%, val: 7.14%\n",
      "EPOCH: 58\n",
      "[LOSS] train: 10.149, val: 2.374\n",
      "[ACC%] train: 42.86%, val: 7.14%\n",
      "EPOCH: 59\n",
      "[LOSS] train: 10.13, val: 2.375\n",
      "[ACC%] train: 41.89%, val: 7.14%\n",
      "EPOCH: 60\n",
      "[LOSS] train: 10.065, val: 2.375\n",
      "[ACC%] train: 44.78%, val: 7.14%\n",
      "EPOCH: 61\n",
      "[LOSS] train: 10.177, val: 2.375\n",
      "[ACC%] train: 42.86%, val: 7.14%\n",
      "EPOCH: 62\n",
      "[LOSS] train: 10.16, val: 2.337\n",
      "[ACC%] train: 42.38%, val: 10.0%\n",
      "EPOCH: 63\n",
      "[LOSS] train: 10.009, val: 2.375\n",
      "[ACC%] train: 46.55%, val: 7.14%\n",
      "EPOCH: 64\n",
      "[LOSS] train: 9.917, val: 2.375\n",
      "[ACC%] train: 47.35%, val: 7.14%\n",
      "EPOCH: 65\n",
      "[LOSS] train: 10.052, val: 2.375\n",
      "[ACC%] train: 45.1%, val: 7.14%\n",
      "EPOCH: 66\n",
      "[LOSS] train: 9.929, val: 2.333\n",
      "[ACC%] train: 46.07%, val: 11.43%\n",
      "EPOCH: 67\n",
      "[LOSS] train: 9.945, val: 2.396\n",
      "[ACC%] train: 47.51%, val: 5.71%\n",
      "EPOCH: 68\n",
      "[LOSS] train: 9.908, val: 2.341\n",
      "[ACC%] train: 47.67%, val: 8.57%\n",
      "EPOCH: 69\n",
      "[LOSS] train: 9.829, val: 2.359\n",
      "[ACC%] train: 48.31%, val: 7.14%\n",
      "EPOCH: 70\n",
      "[LOSS] train: 9.834, val: 2.356\n",
      "[ACC%] train: 46.71%, val: 8.57%\n",
      "EPOCH: 71\n",
      "[LOSS] train: 9.768, val: 2.372\n",
      "[ACC%] train: 51.04%, val: 7.14%\n",
      "EPOCH: 72\n",
      "[LOSS] train: 9.727, val: 2.334\n",
      "[ACC%] train: 52.01%, val: 11.43%\n",
      "EPOCH: 73\n",
      "[LOSS] train: 9.638, val: 2.379\n",
      "[ACC%] train: 53.77%, val: 4.29%\n",
      "EPOCH: 74\n",
      "[LOSS] train: 9.756, val: 2.343\n",
      "[ACC%] train: 50.88%, val: 10.0%\n",
      "EPOCH: 75\n",
      "[LOSS] train: 9.664, val: 2.374\n",
      "[ACC%] train: 52.17%, val: 5.71%\n",
      "EPOCH: 76\n",
      "[LOSS] train: 9.718, val: 2.331\n",
      "[ACC%] train: 51.85%, val: 10.0%\n",
      "EPOCH: 77\n",
      "[LOSS] train: 9.693, val: 2.322\n",
      "[ACC%] train: 51.2%, val: 11.43%\n",
      "EPOCH: 78\n",
      "[LOSS] train: 9.761, val: 2.349\n",
      "[ACC%] train: 50.24%, val: 8.57%\n",
      "EPOCH: 79\n",
      "[LOSS] train: 9.623, val: 2.327\n",
      "[ACC%] train: 55.06%, val: 10.0%\n",
      "EPOCH: 80\n",
      "[LOSS] train: 9.589, val: 2.327\n",
      "[ACC%] train: 54.57%, val: 10.0%\n",
      "EPOCH: 81\n",
      "[LOSS] train: 9.452, val: 2.335\n",
      "[ACC%] train: 56.82%, val: 11.43%\n",
      "EPOCH: 82\n",
      "[LOSS] train: 9.471, val: 2.336\n",
      "[ACC%] train: 57.3%, val: 10.0%\n",
      "EPOCH: 83\n",
      "[LOSS] train: 9.617, val: 2.365\n",
      "[ACC%] train: 53.61%, val: 4.29%\n",
      "EPOCH: 84\n",
      "[LOSS] train: 9.431, val: 2.327\n",
      "[ACC%] train: 57.3%, val: 11.43%\n",
      "EPOCH: 85\n",
      "[LOSS] train: 9.587, val: 2.327\n",
      "[ACC%] train: 54.09%, val: 10.0%\n",
      "EPOCH: 86\n",
      "[LOSS] train: 9.473, val: 2.351\n",
      "[ACC%] train: 56.82%, val: 8.57%\n",
      "EPOCH: 87\n",
      "[LOSS] train: 9.342, val: 2.367\n",
      "[ACC%] train: 59.23%, val: 7.14%\n",
      "EPOCH: 88\n",
      "[LOSS] train: 9.323, val: 2.347\n",
      "[ACC%] train: 60.19%, val: 8.57%\n",
      "EPOCH: 89\n",
      "[LOSS] train: 9.364, val: 2.336\n",
      "[ACC%] train: 58.91%, val: 10.0%\n",
      "EPOCH: 90\n",
      "[LOSS] train: 9.391, val: 2.333\n",
      "[ACC%] train: 58.43%, val: 11.43%\n",
      "EPOCH: 91\n",
      "[LOSS] train: 9.44, val: 2.362\n",
      "[ACC%] train: 57.62%, val: 8.57%\n",
      "EPOCH: 92\n",
      "[LOSS] train: 9.399, val: 2.374\n",
      "[ACC%] train: 56.98%, val: 7.14%\n",
      "EPOCH: 93\n",
      "[LOSS] train: 9.309, val: 2.374\n",
      "[ACC%] train: 59.55%, val: 7.14%\n",
      "EPOCH: 94\n",
      "[LOSS] train: 9.2, val: 2.344\n",
      "[ACC%] train: 62.28%, val: 10.0%\n",
      "EPOCH: 95\n",
      "[LOSS] train: 9.172, val: 2.372\n",
      "[ACC%] train: 63.08%, val: 7.14%\n",
      "EPOCH: 96\n",
      "[LOSS] train: 9.222, val: 2.365\n",
      "[ACC%] train: 61.48%, val: 7.14%\n",
      "EPOCH: 97\n",
      "[LOSS] train: 9.274, val: 2.343\n",
      "[ACC%] train: 60.51%, val: 11.43%\n",
      "EPOCH: 98\n",
      "[LOSS] train: 9.182, val: 2.311\n",
      "[ACC%] train: 63.24%, val: 12.86%\n",
      "EPOCH: 99\n",
      "[LOSS] train: 9.117, val: 2.372\n",
      "[ACC%] train: 63.88%, val: 7.14%\n",
      "EPOCH: 100\n",
      "[LOSS] train: 9.124, val: 2.345\n",
      "[ACC%] train: 64.53%, val: 10.0%\n",
      "EPOCH: 101\n",
      "[LOSS] train: 9.05, val: 2.332\n",
      "[ACC%] train: 64.53%, val: 11.43%\n",
      "EPOCH: 102\n",
      "[LOSS] train: 8.989, val: 2.354\n",
      "[ACC%] train: 66.29%, val: 10.0%\n",
      "EPOCH: 103\n",
      "[LOSS] train: 9.138, val: 2.311\n",
      "[ACC%] train: 64.21%, val: 12.86%\n",
      "EPOCH: 104\n",
      "[LOSS] train: 9.04, val: 2.305\n",
      "[ACC%] train: 66.29%, val: 14.29%\n",
      "EPOCH: 105\n",
      "[LOSS] train: 8.944, val: 2.336\n",
      "[ACC%] train: 67.74%, val: 11.43%\n",
      "EPOCH: 106\n",
      "[LOSS] train: 8.987, val: 2.319\n",
      "[ACC%] train: 67.09%, val: 11.43%\n",
      "EPOCH: 107\n",
      "[LOSS] train: 9.021, val: 2.339\n",
      "[ACC%] train: 65.01%, val: 10.0%\n",
      "EPOCH: 108\n",
      "[LOSS] train: 9.08, val: 2.322\n",
      "[ACC%] train: 64.37%, val: 11.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 109\n",
      "[LOSS] train: 9.048, val: 2.353\n",
      "[ACC%] train: 65.49%, val: 8.57%\n",
      "EPOCH: 110\n",
      "[LOSS] train: 9.011, val: 2.353\n",
      "[ACC%] train: 66.61%, val: 8.57%\n",
      "EPOCH: 111\n",
      "[LOSS] train: 8.99, val: 2.306\n",
      "[ACC%] train: 66.61%, val: 14.29%\n",
      "EPOCH: 112\n",
      "[LOSS] train: 8.934, val: 2.314\n",
      "[ACC%] train: 67.42%, val: 12.86%\n",
      "EPOCH: 113\n",
      "[LOSS] train: 8.897, val: 2.358\n",
      "[ACC%] train: 69.34%, val: 8.57%\n",
      "EPOCH: 114\n",
      "[LOSS] train: 8.96, val: 2.349\n",
      "[ACC%] train: 65.97%, val: 8.57%\n",
      "EPOCH: 115\n",
      "[LOSS] train: 8.885, val: 2.331\n",
      "[ACC%] train: 68.7%, val: 11.43%\n",
      "EPOCH: 116\n",
      "[LOSS] train: 8.883, val: 2.342\n",
      "[ACC%] train: 69.18%, val: 10.0%\n",
      "EPOCH: 117\n",
      "[LOSS] train: 8.818, val: 2.32\n",
      "[ACC%] train: 69.66%, val: 12.86%\n",
      "EPOCH: 118\n",
      "[LOSS] train: 8.901, val: 2.325\n",
      "[ACC%] train: 68.7%, val: 11.43%\n",
      "EPOCH: 119\n",
      "[LOSS] train: 8.886, val: 2.318\n",
      "[ACC%] train: 69.18%, val: 12.86%\n",
      "EPOCH: 120\n",
      "[LOSS] train: 8.82, val: 2.339\n",
      "[ACC%] train: 70.47%, val: 10.0%\n",
      "EPOCH: 121\n",
      "[LOSS] train: 8.885, val: 2.35\n",
      "[ACC%] train: 69.02%, val: 8.57%\n",
      "EPOCH: 122\n",
      "[LOSS] train: 8.902, val: 2.354\n",
      "[ACC%] train: 67.74%, val: 8.57%\n",
      "EPOCH: 123\n",
      "[LOSS] train: 8.797, val: 2.32\n",
      "[ACC%] train: 70.14%, val: 12.86%\n",
      "EPOCH: 124\n",
      "[LOSS] train: 8.811, val: 2.306\n",
      "[ACC%] train: 69.98%, val: 14.29%\n",
      "EPOCH: 125\n",
      "[LOSS] train: 8.871, val: 2.32\n",
      "[ACC%] train: 69.18%, val: 11.43%\n",
      "EPOCH: 126\n",
      "[LOSS] train: 8.869, val: 2.313\n",
      "[ACC%] train: 68.38%, val: 12.86%\n",
      "EPOCH: 127\n",
      "[LOSS] train: 8.811, val: 2.322\n",
      "[ACC%] train: 69.66%, val: 11.43%\n",
      "EPOCH: 128\n",
      "[LOSS] train: 8.845, val: 2.318\n",
      "[ACC%] train: 69.98%, val: 11.43%\n",
      "EPOCH: 129\n",
      "[LOSS] train: 8.792, val: 2.296\n",
      "[ACC%] train: 69.98%, val: 17.14%\n",
      "EPOCH: 130\n",
      "[LOSS] train: 8.706, val: 2.282\n",
      "[ACC%] train: 71.75%, val: 18.57%\n",
      "EPOCH: 131\n",
      "[LOSS] train: 8.675, val: 2.309\n",
      "[ACC%] train: 72.23%, val: 14.29%\n",
      "EPOCH: 132\n",
      "[LOSS] train: 8.809, val: 2.347\n",
      "[ACC%] train: 69.18%, val: 10.0%\n",
      "EPOCH: 133\n",
      "[LOSS] train: 8.757, val: 2.371\n",
      "[ACC%] train: 70.63%, val: 7.14%\n",
      "EPOCH: 134\n",
      "[LOSS] train: 8.787, val: 2.358\n",
      "[ACC%] train: 69.98%, val: 8.57%\n",
      "EPOCH: 135\n",
      "[LOSS] train: 8.597, val: 2.329\n",
      "[ACC%] train: 74.64%, val: 11.43%\n",
      "EPOCH: 136\n",
      "[LOSS] train: 8.729, val: 2.318\n",
      "[ACC%] train: 72.23%, val: 12.86%\n",
      "EPOCH: 137\n",
      "[LOSS] train: 8.577, val: 2.353\n",
      "[ACC%] train: 75.12%, val: 8.57%\n",
      "EPOCH: 138\n",
      "[LOSS] train: 8.668, val: 2.338\n",
      "[ACC%] train: 72.71%, val: 11.43%\n",
      "EPOCH: 139\n",
      "[LOSS] train: 8.656, val: 2.333\n",
      "[ACC%] train: 72.71%, val: 10.0%\n",
      "EPOCH: 140\n",
      "[LOSS] train: 8.713, val: 2.333\n",
      "[ACC%] train: 71.27%, val: 10.0%\n",
      "EPOCH: 141\n",
      "[LOSS] train: 8.659, val: 2.296\n",
      "[ACC%] train: 72.23%, val: 14.29%\n",
      "EPOCH: 142\n",
      "[LOSS] train: 8.611, val: 2.301\n",
      "[ACC%] train: 73.84%, val: 14.29%\n",
      "EPOCH: 143\n",
      "[LOSS] train: 8.637, val: 2.347\n",
      "[ACC%] train: 73.84%, val: 10.0%\n",
      "EPOCH: 144\n",
      "[LOSS] train: 8.641, val: 2.357\n",
      "[ACC%] train: 73.68%, val: 8.57%\n",
      "EPOCH: 145\n",
      "[LOSS] train: 8.554, val: 2.342\n",
      "[ACC%] train: 74.8%, val: 11.43%\n",
      "EPOCH: 146\n",
      "[LOSS] train: 8.585, val: 2.294\n",
      "[ACC%] train: 74.8%, val: 17.14%\n",
      "EPOCH: 147\n",
      "[LOSS] train: 8.595, val: 2.334\n",
      "[ACC%] train: 74.48%, val: 10.0%\n",
      "EPOCH: 148\n",
      "[LOSS] train: 8.624, val: 2.327\n",
      "[ACC%] train: 73.03%, val: 11.43%\n",
      "EPOCH: 149\n",
      "[LOSS] train: 8.67, val: 2.328\n",
      "[ACC%] train: 73.19%, val: 12.86%\n",
      "EPOCH: 150\n",
      "[LOSS] train: 8.602, val: 2.312\n",
      "[ACC%] train: 74.0%, val: 12.86%\n",
      "EPOCH: 151\n",
      "[LOSS] train: 8.587, val: 2.358\n",
      "[ACC%] train: 73.35%, val: 8.57%\n",
      "EPOCH: 152\n",
      "[LOSS] train: 8.527, val: 2.364\n",
      "[ACC%] train: 74.8%, val: 7.14%\n",
      "EPOCH: 153\n",
      "[LOSS] train: 8.617, val: 2.333\n",
      "[ACC%] train: 73.35%, val: 11.43%\n",
      "EPOCH: 154\n",
      "[LOSS] train: 8.537, val: 2.347\n",
      "[ACC%] train: 75.92%, val: 10.0%\n",
      "EPOCH: 155\n",
      "[LOSS] train: 8.448, val: 2.328\n",
      "[ACC%] train: 76.57%, val: 10.0%\n",
      "EPOCH: 156\n",
      "[LOSS] train: 8.532, val: 2.365\n",
      "[ACC%] train: 75.28%, val: 7.14%\n",
      "EPOCH: 157\n",
      "[LOSS] train: 8.527, val: 2.344\n",
      "[ACC%] train: 76.24%, val: 10.0%\n",
      "EPOCH: 158\n",
      "[LOSS] train: 8.743, val: 2.33\n",
      "[ACC%] train: 70.47%, val: 11.43%\n",
      "EPOCH: 159\n",
      "[LOSS] train: 8.511, val: 2.336\n",
      "[ACC%] train: 76.89%, val: 14.29%\n",
      "EPOCH: 160\n",
      "[LOSS] train: 8.503, val: 2.308\n",
      "[ACC%] train: 76.73%, val: 18.57%\n",
      "EPOCH: 161\n",
      "[LOSS] train: 8.641, val: 2.318\n",
      "[ACC%] train: 72.87%, val: 15.71%\n",
      "EPOCH: 162\n",
      "[LOSS] train: 8.451, val: 2.332\n",
      "[ACC%] train: 76.4%, val: 14.29%\n",
      "EPOCH: 163\n",
      "[LOSS] train: 8.506, val: 2.311\n",
      "[ACC%] train: 76.24%, val: 15.71%\n",
      "EPOCH: 164\n",
      "[LOSS] train: 8.432, val: 2.309\n",
      "[ACC%] train: 77.85%, val: 14.29%\n",
      "EPOCH: 165\n",
      "[LOSS] train: 8.521, val: 2.335\n",
      "[ACC%] train: 75.12%, val: 8.57%\n",
      "EPOCH: 166\n",
      "[LOSS] train: 8.478, val: 2.295\n",
      "[ACC%] train: 76.89%, val: 15.71%\n",
      "EPOCH: 167\n",
      "[LOSS] train: 8.445, val: 2.278\n",
      "[ACC%] train: 78.01%, val: 17.14%\n",
      "EPOCH: 168\n",
      "[LOSS] train: 8.432, val: 2.287\n",
      "[ACC%] train: 77.53%, val: 15.71%\n",
      "EPOCH: 169\n",
      "[LOSS] train: 8.587, val: 2.332\n",
      "[ACC%] train: 74.16%, val: 11.43%\n",
      "EPOCH: 170\n",
      "[LOSS] train: 8.487, val: 2.33\n",
      "[ACC%] train: 76.24%, val: 11.43%\n",
      "EPOCH: 171\n",
      "[LOSS] train: 8.544, val: 2.334\n",
      "[ACC%] train: 74.8%, val: 10.0%\n",
      "EPOCH: 172\n",
      "[LOSS] train: 8.492, val: 2.328\n",
      "[ACC%] train: 76.73%, val: 11.43%\n",
      "EPOCH: 173\n",
      "[LOSS] train: 8.53, val: 2.336\n",
      "[ACC%] train: 73.84%, val: 10.0%\n",
      "EPOCH: 174\n",
      "[LOSS] train: 8.41, val: 2.336\n",
      "[ACC%] train: 77.85%, val: 11.43%\n",
      "EPOCH: 175\n",
      "[LOSS] train: 8.532, val: 2.336\n",
      "[ACC%] train: 75.92%, val: 10.0%\n",
      "EPOCH: 176\n",
      "[LOSS] train: 8.459, val: 2.355\n",
      "[ACC%] train: 76.89%, val: 7.14%\n",
      "EPOCH: 177\n",
      "[LOSS] train: 8.396, val: 2.351\n",
      "[ACC%] train: 78.65%, val: 8.57%\n",
      "EPOCH: 178\n",
      "[LOSS] train: 8.362, val: 2.339\n",
      "[ACC%] train: 79.13%, val: 10.0%\n",
      "EPOCH: 179\n",
      "[LOSS] train: 8.371, val: 2.334\n",
      "[ACC%] train: 77.85%, val: 10.0%\n",
      "EPOCH: 180\n",
      "[LOSS] train: 8.484, val: 2.347\n",
      "[ACC%] train: 76.57%, val: 8.57%\n",
      "EPOCH: 181\n",
      "[LOSS] train: 8.366, val: 2.333\n",
      "[ACC%] train: 78.81%, val: 11.43%\n",
      "EPOCH: 182\n",
      "[LOSS] train: 8.41, val: 2.308\n",
      "[ACC%] train: 78.81%, val: 14.29%\n",
      "EPOCH: 183\n",
      "[LOSS] train: 8.406, val: 2.347\n",
      "[ACC%] train: 78.33%, val: 10.0%\n",
      "EPOCH: 184\n",
      "[LOSS] train: 8.499, val: 2.333\n",
      "[ACC%] train: 76.08%, val: 10.0%\n",
      "EPOCH: 185\n",
      "[LOSS] train: 8.382, val: 2.346\n",
      "[ACC%] train: 78.81%, val: 11.43%\n",
      "EPOCH: 186\n",
      "[LOSS] train: 8.393, val: 2.346\n",
      "[ACC%] train: 77.85%, val: 10.0%\n",
      "EPOCH: 187\n",
      "[LOSS] train: 8.389, val: 2.368\n",
      "[ACC%] train: 77.85%, val: 8.57%\n",
      "EPOCH: 188\n",
      "[LOSS] train: 8.374, val: 2.356\n",
      "[ACC%] train: 78.17%, val: 10.0%\n",
      "EPOCH: 189\n",
      "[LOSS] train: 8.316, val: 2.337\n",
      "[ACC%] train: 79.94%, val: 11.43%\n",
      "EPOCH: 190\n",
      "[LOSS] train: 8.382, val: 2.332\n",
      "[ACC%] train: 78.65%, val: 12.86%\n",
      "EPOCH: 191\n",
      "[LOSS] train: 8.247, val: 2.337\n",
      "[ACC%] train: 80.9%, val: 12.86%\n",
      "EPOCH: 192\n",
      "[LOSS] train: 8.258, val: 2.326\n",
      "[ACC%] train: 81.06%, val: 12.86%\n",
      "EPOCH: 193\n",
      "[LOSS] train: 8.281, val: 2.343\n",
      "[ACC%] train: 81.06%, val: 11.43%\n",
      "EPOCH: 194\n",
      "[LOSS] train: 8.236, val: 2.333\n",
      "[ACC%] train: 82.02%, val: 11.43%\n",
      "EPOCH: 195\n",
      "[LOSS] train: 8.28, val: 2.336\n",
      "[ACC%] train: 80.26%, val: 10.0%\n",
      "EPOCH: 196\n",
      "[LOSS] train: 8.192, val: 2.307\n",
      "[ACC%] train: 82.18%, val: 14.29%\n",
      "EPOCH: 197\n",
      "[LOSS] train: 8.346, val: 2.334\n",
      "[ACC%] train: 78.65%, val: 11.43%\n",
      "EPOCH: 198\n",
      "[LOSS] train: 8.262, val: 2.334\n",
      "[ACC%] train: 81.22%, val: 12.86%\n",
      "EPOCH: 199\n",
      "[LOSS] train: 8.312, val: 2.315\n",
      "[ACC%] train: 79.45%, val: 14.29%\n",
      "\n",
      "\n",
      "Working on 1th Fold\n",
      "EPOCH: 0\n",
      "[LOSS] train: 8.696, val: 1.6\n",
      "[ACC%] train: 71.91%, val: 85.71%\n",
      "EPOCH: 1\n",
      "[LOSS] train: 8.655, val: 1.811\n",
      "[ACC%] train: 73.03%, val: 62.86%\n",
      "EPOCH: 2\n",
      "[LOSS] train: 8.711, val: 1.805\n",
      "[ACC%] train: 71.59%, val: 62.86%\n",
      "EPOCH: 3\n",
      "[LOSS] train: 8.656, val: 2.047\n",
      "[ACC%] train: 72.87%, val: 37.14%\n",
      "EPOCH: 4\n",
      "[LOSS] train: 8.767, val: 2.023\n",
      "[ACC%] train: 71.91%, val: 38.57%\n",
      "EPOCH: 5\n",
      "[LOSS] train: 8.679, val: 1.857\n",
      "[ACC%] train: 72.71%, val: 57.14%\n",
      "EPOCH: 6\n",
      "[LOSS] train: 8.66, val: 1.704\n",
      "[ACC%] train: 72.71%, val: 72.86%\n",
      "EPOCH: 7\n",
      "[LOSS] train: 8.653, val: 2.038\n",
      "[ACC%] train: 72.23%, val: 37.14%\n",
      "EPOCH: 8\n",
      "[LOSS] train: 8.678, val: 2.028\n",
      "[ACC%] train: 72.55%, val: 38.57%\n",
      "EPOCH: 9\n",
      "[LOSS] train: 8.595, val: 1.781\n",
      "[ACC%] train: 74.48%, val: 65.71%\n",
      "EPOCH: 10\n",
      "[LOSS] train: 8.561, val: 1.756\n",
      "[ACC%] train: 74.32%, val: 68.57%\n",
      "EPOCH: 11\n",
      "[LOSS] train: 8.545, val: 1.599\n",
      "[ACC%] train: 75.28%, val: 87.14%\n",
      "EPOCH: 12\n",
      "[LOSS] train: 8.552, val: 1.602\n",
      "[ACC%] train: 74.8%, val: 85.71%\n",
      "EPOCH: 13\n",
      "[LOSS] train: 8.563, val: 1.935\n",
      "[ACC%] train: 75.28%, val: 48.57%\n",
      "EPOCH: 14\n",
      "[LOSS] train: 8.729, val: 2.04\n",
      "[ACC%] train: 71.59%, val: 37.14%\n",
      "EPOCH: 15\n",
      "[LOSS] train: 8.678, val: 1.982\n",
      "[ACC%] train: 73.03%, val: 44.29%\n",
      "EPOCH: 16\n",
      "[LOSS] train: 8.509, val: 1.628\n",
      "[ACC%] train: 75.92%, val: 84.29%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 17\n",
      "[LOSS] train: 8.57, val: 1.6\n",
      "[ACC%] train: 75.12%, val: 85.71%\n",
      "EPOCH: 18\n",
      "[LOSS] train: 8.581, val: 1.637\n",
      "[ACC%] train: 74.48%, val: 81.43%\n",
      "EPOCH: 19\n",
      "[LOSS] train: 8.562, val: 1.599\n",
      "[ACC%] train: 73.68%, val: 85.71%\n",
      "EPOCH: 20\n",
      "[LOSS] train: 8.567, val: 1.929\n",
      "[ACC%] train: 74.16%, val: 50.0%\n",
      "EPOCH: 21\n",
      "[LOSS] train: 8.45, val: 2.06\n",
      "[ACC%] train: 77.53%, val: 35.71%\n",
      "EPOCH: 22\n",
      "[LOSS] train: 8.475, val: 2.082\n",
      "[ACC%] train: 77.37%, val: 34.29%\n",
      "EPOCH: 23\n",
      "[LOSS] train: 8.627, val: 2.124\n",
      "[ACC%] train: 73.03%, val: 28.57%\n",
      "EPOCH: 24\n",
      "[LOSS] train: 8.512, val: 2.101\n",
      "[ACC%] train: 75.76%, val: 34.29%\n",
      "EPOCH: 25\n",
      "[LOSS] train: 8.496, val: 2.096\n",
      "[ACC%] train: 76.08%, val: 32.86%\n",
      "EPOCH: 26\n",
      "[LOSS] train: 8.52, val: 2.088\n",
      "[ACC%] train: 75.28%, val: 34.29%\n",
      "EPOCH: 27\n",
      "[LOSS] train: 8.435, val: 2.048\n",
      "[ACC%] train: 77.05%, val: 37.14%\n",
      "EPOCH: 28\n",
      "[LOSS] train: 8.484, val: 2.036\n",
      "[ACC%] train: 76.57%, val: 37.14%\n",
      "EPOCH: 29\n",
      "[LOSS] train: 8.477, val: 2.023\n",
      "[ACC%] train: 76.73%, val: 40.0%\n",
      "EPOCH: 30\n",
      "[LOSS] train: 8.405, val: 1.912\n",
      "[ACC%] train: 77.21%, val: 51.43%\n",
      "EPOCH: 31\n",
      "[LOSS] train: 8.313, val: 1.74\n",
      "[ACC%] train: 79.61%, val: 70.0%\n",
      "EPOCH: 32\n",
      "[LOSS] train: 8.366, val: 1.648\n",
      "[ACC%] train: 78.49%, val: 80.0%\n",
      "EPOCH: 33\n",
      "[LOSS] train: 8.311, val: 1.629\n",
      "[ACC%] train: 79.78%, val: 82.86%\n",
      "EPOCH: 34\n",
      "[LOSS] train: 8.375, val: 1.643\n",
      "[ACC%] train: 78.49%, val: 80.0%\n",
      "EPOCH: 35\n",
      "[LOSS] train: 8.437, val: 1.643\n",
      "[ACC%] train: 76.73%, val: 80.0%\n",
      "EPOCH: 36\n",
      "[LOSS] train: 8.395, val: 1.7\n",
      "[ACC%] train: 79.13%, val: 74.29%\n",
      "EPOCH: 37\n",
      "[LOSS] train: 8.445, val: 1.743\n",
      "[ACC%] train: 75.92%, val: 68.57%\n",
      "EPOCH: 38\n",
      "[LOSS] train: 8.489, val: 1.782\n",
      "[ACC%] train: 76.08%, val: 64.29%\n",
      "EPOCH: 39\n",
      "[LOSS] train: 8.47, val: 1.868\n",
      "[ACC%] train: 77.05%, val: 55.71%\n",
      "EPOCH: 40\n",
      "[LOSS] train: 8.278, val: 1.746\n",
      "[ACC%] train: 80.9%, val: 70.0%\n",
      "EPOCH: 41\n",
      "[LOSS] train: 8.288, val: 2.033\n",
      "[ACC%] train: 80.9%, val: 38.57%\n",
      "EPOCH: 42\n",
      "[LOSS] train: 8.367, val: 2.101\n",
      "[ACC%] train: 79.94%, val: 31.43%\n",
      "EPOCH: 43\n",
      "[LOSS] train: 8.442, val: 2.016\n",
      "[ACC%] train: 77.05%, val: 38.57%\n",
      "EPOCH: 44\n",
      "[LOSS] train: 8.446, val: 1.822\n",
      "[ACC%] train: 77.21%, val: 61.43%\n",
      "EPOCH: 45\n",
      "[LOSS] train: 8.471, val: 1.794\n",
      "[ACC%] train: 76.4%, val: 64.29%\n",
      "EPOCH: 46\n",
      "[LOSS] train: 8.4, val: 1.865\n",
      "[ACC%] train: 78.33%, val: 57.14%\n",
      "EPOCH: 47\n",
      "[LOSS] train: 8.349, val: 2.084\n",
      "[ACC%] train: 78.33%, val: 32.86%\n",
      "EPOCH: 48\n",
      "[LOSS] train: 8.405, val: 2.077\n",
      "[ACC%] train: 77.53%, val: 34.29%\n",
      "EPOCH: 49\n",
      "[LOSS] train: 8.387, val: 2.073\n",
      "[ACC%] train: 78.49%, val: 34.29%\n",
      "EPOCH: 50\n",
      "[LOSS] train: 8.251, val: 2.076\n",
      "[ACC%] train: 80.9%, val: 34.29%\n",
      "EPOCH: 51\n",
      "[LOSS] train: 8.394, val: 2.076\n",
      "[ACC%] train: 77.21%, val: 34.29%\n",
      "EPOCH: 52\n",
      "[LOSS] train: 8.37, val: 2.033\n",
      "[ACC%] train: 78.33%, val: 41.43%\n",
      "EPOCH: 53\n",
      "[LOSS] train: 8.323, val: 1.782\n",
      "[ACC%] train: 78.97%, val: 65.71%\n",
      "EPOCH: 54\n",
      "[LOSS] train: 8.284, val: 1.75\n",
      "[ACC%] train: 80.74%, val: 71.43%\n",
      "EPOCH: 55\n",
      "[LOSS] train: 8.338, val: 1.672\n",
      "[ACC%] train: 79.29%, val: 77.14%\n",
      "EPOCH: 56\n",
      "[LOSS] train: 8.37, val: 2.108\n",
      "[ACC%] train: 78.17%, val: 30.0%\n",
      "EPOCH: 57\n",
      "[LOSS] train: 8.383, val: 2.128\n",
      "[ACC%] train: 78.01%, val: 30.0%\n",
      "EPOCH: 58\n",
      "[LOSS] train: 8.307, val: 2.071\n",
      "[ACC%] train: 80.9%, val: 35.71%\n",
      "EPOCH: 59\n",
      "[LOSS] train: 8.331, val: 2.126\n",
      "[ACC%] train: 79.29%, val: 28.57%\n",
      "EPOCH: 60\n",
      "[LOSS] train: 8.328, val: 1.896\n",
      "[ACC%] train: 79.29%, val: 54.29%\n",
      "EPOCH: 61\n",
      "[LOSS] train: 8.289, val: 1.781\n",
      "[ACC%] train: 80.42%, val: 65.71%\n",
      "EPOCH: 62\n",
      "[LOSS] train: 8.264, val: 1.722\n",
      "[ACC%] train: 80.26%, val: 72.86%\n",
      "EPOCH: 63\n",
      "[LOSS] train: 8.286, val: 1.703\n",
      "[ACC%] train: 80.42%, val: 75.71%\n",
      "EPOCH: 64\n",
      "[LOSS] train: 8.336, val: 1.727\n",
      "[ACC%] train: 79.13%, val: 71.43%\n",
      "EPOCH: 65\n",
      "[LOSS] train: 8.238, val: 1.757\n",
      "[ACC%] train: 81.06%, val: 70.0%\n",
      "EPOCH: 66\n",
      "[LOSS] train: 8.238, val: 1.772\n",
      "[ACC%] train: 81.86%, val: 67.14%\n",
      "EPOCH: 67\n",
      "[LOSS] train: 8.218, val: 1.789\n",
      "[ACC%] train: 82.18%, val: 64.29%\n",
      "EPOCH: 68\n",
      "[LOSS] train: 8.311, val: 1.932\n",
      "[ACC%] train: 79.61%, val: 48.57%\n",
      "EPOCH: 69\n",
      "[LOSS] train: 8.224, val: 2.074\n",
      "[ACC%] train: 81.7%, val: 35.71%\n",
      "EPOCH: 70\n",
      "[LOSS] train: 8.25, val: 2.077\n",
      "[ACC%] train: 80.74%, val: 32.86%\n",
      "EPOCH: 71\n",
      "[LOSS] train: 8.327, val: 2.047\n",
      "[ACC%] train: 79.45%, val: 35.71%\n",
      "EPOCH: 72\n",
      "[LOSS] train: 8.238, val: 2.102\n",
      "[ACC%] train: 81.06%, val: 32.86%\n",
      "EPOCH: 73\n",
      "[LOSS] train: 8.286, val: 2.088\n",
      "[ACC%] train: 79.94%, val: 32.86%\n",
      "EPOCH: 74\n",
      "[LOSS] train: 8.181, val: 2.171\n",
      "[ACC%] train: 81.86%, val: 25.71%\n",
      "EPOCH: 75\n",
      "[LOSS] train: 8.217, val: 2.155\n",
      "[ACC%] train: 81.54%, val: 27.14%\n",
      "EPOCH: 76\n",
      "[LOSS] train: 8.27, val: 2.115\n",
      "[ACC%] train: 80.74%, val: 31.43%\n",
      "EPOCH: 77\n",
      "[LOSS] train: 8.229, val: 2.123\n",
      "[ACC%] train: 82.18%, val: 30.0%\n",
      "EPOCH: 78\n",
      "[LOSS] train: 8.297, val: 2.153\n",
      "[ACC%] train: 80.42%, val: 27.14%\n",
      "EPOCH: 79\n",
      "[LOSS] train: 8.209, val: 2.114\n",
      "[ACC%] train: 81.38%, val: 31.43%\n",
      "EPOCH: 80\n",
      "[LOSS] train: 8.209, val: 2.044\n",
      "[ACC%] train: 82.18%, val: 38.57%\n",
      "EPOCH: 81\n",
      "[LOSS] train: 8.326, val: 1.739\n",
      "[ACC%] train: 79.45%, val: 70.0%\n",
      "EPOCH: 82\n",
      "[LOSS] train: 8.201, val: 1.761\n",
      "[ACC%] train: 82.34%, val: 67.14%\n",
      "EPOCH: 83\n",
      "[LOSS] train: 8.11, val: 2.038\n",
      "[ACC%] train: 83.79%, val: 40.0%\n",
      "EPOCH: 84\n",
      "[LOSS] train: 8.16, val: 2.233\n",
      "[ACC%] train: 82.83%, val: 20.0%\n",
      "EPOCH: 85\n",
      "[LOSS] train: 8.162, val: 2.208\n",
      "[ACC%] train: 82.34%, val: 21.43%\n",
      "EPOCH: 86\n",
      "[LOSS] train: 8.22, val: 2.152\n",
      "[ACC%] train: 81.22%, val: 27.14%\n",
      "EPOCH: 87\n",
      "[LOSS] train: 8.237, val: 2.193\n",
      "[ACC%] train: 80.74%, val: 24.29%\n",
      "EPOCH: 88\n",
      "[LOSS] train: 8.192, val: 2.16\n",
      "[ACC%] train: 82.02%, val: 27.14%\n",
      "EPOCH: 89\n",
      "[LOSS] train: 8.236, val: 1.864\n",
      "[ACC%] train: 81.22%, val: 58.57%\n",
      "EPOCH: 90\n",
      "[LOSS] train: 8.206, val: 2.011\n",
      "[ACC%] train: 81.7%, val: 41.43%\n",
      "EPOCH: 91\n",
      "[LOSS] train: 8.267, val: 2.168\n",
      "[ACC%] train: 81.06%, val: 25.71%\n",
      "EPOCH: 92\n",
      "[LOSS] train: 8.212, val: 2.13\n",
      "[ACC%] train: 81.86%, val: 30.0%\n",
      "EPOCH: 93\n",
      "[LOSS] train: 8.283, val: 2.17\n",
      "[ACC%] train: 80.26%, val: 25.71%\n",
      "EPOCH: 94\n",
      "[LOSS] train: 8.205, val: 2.153\n",
      "[ACC%] train: 82.18%, val: 27.14%\n",
      "EPOCH: 95\n",
      "[LOSS] train: 8.191, val: 2.115\n",
      "[ACC%] train: 81.86%, val: 30.0%\n",
      "EPOCH: 96\n",
      "[LOSS] train: 8.252, val: 2.086\n",
      "[ACC%] train: 81.22%, val: 32.86%\n",
      "EPOCH: 97\n",
      "[LOSS] train: 8.253, val: 2.092\n",
      "[ACC%] train: 81.38%, val: 32.86%\n",
      "EPOCH: 98\n",
      "[LOSS] train: 8.096, val: 2.08\n",
      "[ACC%] train: 84.91%, val: 34.29%\n",
      "EPOCH: 99\n",
      "[LOSS] train: 8.212, val: 2.014\n",
      "[ACC%] train: 82.34%, val: 41.43%\n",
      "EPOCH: 100\n",
      "[LOSS] train: 8.066, val: 2.082\n",
      "[ACC%] train: 85.23%, val: 34.29%\n",
      "EPOCH: 101\n",
      "[LOSS] train: 8.08, val: 2.09\n",
      "[ACC%] train: 84.75%, val: 32.86%\n",
      "EPOCH: 102\n",
      "[LOSS] train: 8.146, val: 2.106\n",
      "[ACC%] train: 82.99%, val: 31.43%\n",
      "EPOCH: 103\n",
      "[LOSS] train: 8.209, val: 2.136\n",
      "[ACC%] train: 81.86%, val: 28.57%\n",
      "EPOCH: 104\n",
      "[LOSS] train: 8.116, val: 2.209\n",
      "[ACC%] train: 83.47%, val: 21.43%\n",
      "EPOCH: 105\n",
      "[LOSS] train: 8.148, val: 2.201\n",
      "[ACC%] train: 83.15%, val: 21.43%\n",
      "EPOCH: 106\n",
      "[LOSS] train: 8.099, val: 2.035\n",
      "[ACC%] train: 84.27%, val: 40.0%\n",
      "EPOCH: 107\n",
      "[LOSS] train: 8.201, val: 1.831\n",
      "[ACC%] train: 82.18%, val: 62.86%\n",
      "EPOCH: 108\n",
      "[LOSS] train: 8.059, val: 1.806\n",
      "[ACC%] train: 85.23%, val: 62.86%\n",
      "EPOCH: 109\n",
      "[LOSS] train: 8.043, val: 1.807\n",
      "[ACC%] train: 84.91%, val: 65.71%\n",
      "EPOCH: 110\n",
      "[LOSS] train: 8.076, val: 1.781\n",
      "[ACC%] train: 84.43%, val: 65.71%\n",
      "EPOCH: 111\n",
      "[LOSS] train: 8.083, val: 1.772\n",
      "[ACC%] train: 84.27%, val: 70.0%\n",
      "EPOCH: 112\n",
      "[LOSS] train: 8.075, val: 1.785\n",
      "[ACC%] train: 83.95%, val: 68.57%\n",
      "EPOCH: 113\n",
      "[LOSS] train: 8.073, val: 1.772\n",
      "[ACC%] train: 84.11%, val: 67.14%\n",
      "EPOCH: 114\n",
      "[LOSS] train: 8.124, val: 1.808\n",
      "[ACC%] train: 83.63%, val: 64.29%\n",
      "EPOCH: 115\n",
      "[LOSS] train: 8.059, val: 2.081\n",
      "[ACC%] train: 84.75%, val: 34.29%\n",
      "EPOCH: 116\n",
      "[LOSS] train: 8.136, val: 2.086\n",
      "[ACC%] train: 83.47%, val: 34.29%\n",
      "EPOCH: 117\n",
      "[LOSS] train: 8.104, val: 2.076\n",
      "[ACC%] train: 84.43%, val: 34.29%\n",
      "EPOCH: 118\n",
      "[LOSS] train: 8.127, val: 1.889\n",
      "[ACC%] train: 83.95%, val: 51.43%\n",
      "EPOCH: 119\n",
      "[LOSS] train: 8.134, val: 1.777\n",
      "[ACC%] train: 83.47%, val: 65.71%\n",
      "EPOCH: 120\n",
      "[LOSS] train: 7.982, val: 1.809\n",
      "[ACC%] train: 87.0%, val: 64.29%\n",
      "EPOCH: 121\n",
      "[LOSS] train: 8.115, val: 1.846\n",
      "[ACC%] train: 83.79%, val: 58.57%\n",
      "EPOCH: 122\n",
      "[LOSS] train: 8.156, val: 2.153\n",
      "[ACC%] train: 83.47%, val: 27.14%\n",
      "EPOCH: 123\n",
      "[LOSS] train: 8.213, val: 2.173\n",
      "[ACC%] train: 81.22%, val: 25.71%\n",
      "EPOCH: 124\n",
      "[LOSS] train: 8.139, val: 2.204\n",
      "[ACC%] train: 83.63%, val: 22.86%\n",
      "EPOCH: 125\n",
      "[LOSS] train: 8.086, val: 2.187\n",
      "[ACC%] train: 84.43%, val: 24.29%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 126\n",
      "[LOSS] train: 8.113, val: 2.173\n",
      "[ACC%] train: 84.27%, val: 25.71%\n",
      "EPOCH: 127\n",
      "[LOSS] train: 8.11, val: 2.144\n",
      "[ACC%] train: 84.11%, val: 27.14%\n",
      "EPOCH: 128\n",
      "[LOSS] train: 8.237, val: 1.83\n",
      "[ACC%] train: 80.74%, val: 61.43%\n",
      "EPOCH: 129\n",
      "[LOSS] train: 8.134, val: 1.798\n",
      "[ACC%] train: 83.31%, val: 65.71%\n",
      "EPOCH: 130\n",
      "[LOSS] train: 8.052, val: 1.814\n",
      "[ACC%] train: 84.91%, val: 60.0%\n",
      "EPOCH: 131\n",
      "[LOSS] train: 8.119, val: 1.863\n",
      "[ACC%] train: 83.63%, val: 58.57%\n",
      "EPOCH: 132\n",
      "[LOSS] train: 8.066, val: 1.847\n",
      "[ACC%] train: 84.91%, val: 58.57%\n",
      "EPOCH: 133\n",
      "[LOSS] train: 8.129, val: 1.816\n",
      "[ACC%] train: 83.31%, val: 64.29%\n",
      "EPOCH: 134\n",
      "[LOSS] train: 8.098, val: 1.874\n",
      "[ACC%] train: 84.43%, val: 57.14%\n",
      "EPOCH: 135\n",
      "[LOSS] train: 8.067, val: 1.843\n",
      "[ACC%] train: 84.91%, val: 60.0%\n",
      "EPOCH: 136\n",
      "[LOSS] train: 8.034, val: 1.847\n",
      "[ACC%] train: 86.04%, val: 57.14%\n",
      "EPOCH: 137\n",
      "[LOSS] train: 8.013, val: 1.875\n",
      "[ACC%] train: 85.55%, val: 54.29%\n",
      "EPOCH: 138\n",
      "[LOSS] train: 8.046, val: 1.831\n",
      "[ACC%] train: 85.07%, val: 61.43%\n",
      "EPOCH: 139\n",
      "[LOSS] train: 8.052, val: 1.822\n",
      "[ACC%] train: 85.55%, val: 62.86%\n",
      "EPOCH: 140\n",
      "[LOSS] train: 8.021, val: 1.823\n",
      "[ACC%] train: 85.71%, val: 67.14%\n",
      "EPOCH: 141\n",
      "[LOSS] train: 8.067, val: 1.865\n",
      "[ACC%] train: 84.43%, val: 58.57%\n",
      "EPOCH: 142\n",
      "[LOSS] train: 8.099, val: 1.868\n",
      "[ACC%] train: 84.75%, val: 60.0%\n",
      "EPOCH: 143\n",
      "[LOSS] train: 8.19, val: 1.977\n",
      "[ACC%] train: 82.18%, val: 47.14%\n",
      "EPOCH: 144\n",
      "[LOSS] train: 8.076, val: 1.992\n",
      "[ACC%] train: 84.59%, val: 44.29%\n",
      "EPOCH: 145\n",
      "[LOSS] train: 8.029, val: 2.003\n",
      "[ACC%] train: 85.71%, val: 45.71%\n",
      "EPOCH: 146\n",
      "[LOSS] train: 8.136, val: 1.912\n",
      "[ACC%] train: 83.63%, val: 52.86%\n",
      "EPOCH: 147\n",
      "[LOSS] train: 8.218, val: 1.813\n",
      "[ACC%] train: 81.86%, val: 62.86%\n",
      "EPOCH: 148\n",
      "[LOSS] train: 8.07, val: 1.923\n",
      "[ACC%] train: 84.43%, val: 51.43%\n",
      "EPOCH: 149\n",
      "[LOSS] train: 8.298, val: 1.974\n",
      "[ACC%] train: 79.45%, val: 45.71%\n",
      "EPOCH: 150\n",
      "[LOSS] train: 8.002, val: 1.95\n",
      "[ACC%] train: 86.04%, val: 48.57%\n",
      "EPOCH: 151\n",
      "[LOSS] train: 8.043, val: 1.869\n",
      "[ACC%] train: 84.43%, val: 54.29%\n",
      "EPOCH: 152\n",
      "[LOSS] train: 8.031, val: 1.839\n",
      "[ACC%] train: 85.23%, val: 58.57%\n",
      "EPOCH: 153\n",
      "[LOSS] train: 8.066, val: 1.966\n",
      "[ACC%] train: 84.75%, val: 45.71%\n",
      "EPOCH: 154\n",
      "[LOSS] train: 8.132, val: 2.059\n",
      "[ACC%] train: 83.15%, val: 37.14%\n",
      "EPOCH: 155\n",
      "[LOSS] train: 8.006, val: 2.059\n",
      "[ACC%] train: 86.04%, val: 37.14%\n",
      "EPOCH: 156\n",
      "[LOSS] train: 8.038, val: 2.0\n",
      "[ACC%] train: 85.87%, val: 42.86%\n",
      "EPOCH: 157\n",
      "[LOSS] train: 8.061, val: 2.002\n",
      "[ACC%] train: 84.75%, val: 41.43%\n",
      "EPOCH: 158\n",
      "[LOSS] train: 8.015, val: 1.976\n",
      "[ACC%] train: 86.52%, val: 44.29%\n",
      "EPOCH: 159\n",
      "[LOSS] train: 7.994, val: 1.93\n",
      "[ACC%] train: 86.36%, val: 48.57%\n",
      "EPOCH: 160\n",
      "[LOSS] train: 7.987, val: 2.077\n",
      "[ACC%] train: 86.36%, val: 32.86%\n",
      "EPOCH: 161\n",
      "[LOSS] train: 8.08, val: 2.031\n",
      "[ACC%] train: 85.07%, val: 38.57%\n",
      "EPOCH: 162\n",
      "[LOSS] train: 8.104, val: 1.919\n",
      "[ACC%] train: 84.59%, val: 51.43%\n",
      "EPOCH: 163\n",
      "[LOSS] train: 8.099, val: 1.914\n",
      "[ACC%] train: 83.79%, val: 52.86%\n",
      "EPOCH: 164\n",
      "[LOSS] train: 7.968, val: 1.958\n",
      "[ACC%] train: 86.84%, val: 47.14%\n",
      "EPOCH: 165\n",
      "[LOSS] train: 7.939, val: 1.924\n",
      "[ACC%] train: 87.48%, val: 47.14%\n",
      "EPOCH: 166\n",
      "[LOSS] train: 8.016, val: 1.983\n",
      "[ACC%] train: 85.55%, val: 42.86%\n",
      "EPOCH: 167\n",
      "[LOSS] train: 7.997, val: 2.076\n",
      "[ACC%] train: 86.68%, val: 35.71%\n",
      "EPOCH: 168\n",
      "[LOSS] train: 7.99, val: 2.051\n",
      "[ACC%] train: 86.36%, val: 35.71%\n",
      "EPOCH: 169\n",
      "[LOSS] train: 8.036, val: 2.045\n",
      "[ACC%] train: 85.55%, val: 37.14%\n",
      "EPOCH: 170\n",
      "[LOSS] train: 8.101, val: 1.987\n",
      "[ACC%] train: 83.79%, val: 44.29%\n",
      "EPOCH: 171\n",
      "[LOSS] train: 8.041, val: 1.935\n",
      "[ACC%] train: 85.71%, val: 50.0%\n",
      "EPOCH: 172\n",
      "[LOSS] train: 8.038, val: 1.958\n",
      "[ACC%] train: 85.39%, val: 48.57%\n",
      "EPOCH: 173\n",
      "[LOSS] train: 8.095, val: 1.974\n",
      "[ACC%] train: 83.95%, val: 47.14%\n",
      "EPOCH: 174\n",
      "[LOSS] train: 8.055, val: 1.94\n",
      "[ACC%] train: 84.75%, val: 51.43%\n",
      "EPOCH: 175\n",
      "[LOSS] train: 8.098, val: 2.028\n",
      "[ACC%] train: 84.27%, val: 40.0%\n",
      "EPOCH: 176\n",
      "[LOSS] train: 8.014, val: 2.055\n",
      "[ACC%] train: 86.2%, val: 37.14%\n",
      "EPOCH: 177\n",
      "[LOSS] train: 8.062, val: 2.092\n",
      "[ACC%] train: 84.27%, val: 32.86%\n",
      "EPOCH: 178\n",
      "[LOSS] train: 7.983, val: 2.055\n",
      "[ACC%] train: 86.52%, val: 37.14%\n",
      "EPOCH: 179\n",
      "[LOSS] train: 8.033, val: 2.013\n",
      "[ACC%] train: 85.39%, val: 41.43%\n",
      "EPOCH: 180\n",
      "[LOSS] train: 7.971, val: 1.919\n",
      "[ACC%] train: 86.52%, val: 52.86%\n",
      "EPOCH: 181\n",
      "[LOSS] train: 8.0, val: 1.875\n",
      "[ACC%] train: 86.2%, val: 55.71%\n",
      "EPOCH: 182\n",
      "[LOSS] train: 7.964, val: 1.904\n",
      "[ACC%] train: 87.0%, val: 55.71%\n",
      "EPOCH: 183\n",
      "[LOSS] train: 8.015, val: 1.909\n",
      "[ACC%] train: 85.87%, val: 55.71%\n",
      "EPOCH: 184\n",
      "[LOSS] train: 8.005, val: 1.959\n",
      "[ACC%] train: 86.04%, val: 50.0%\n",
      "EPOCH: 185\n",
      "[LOSS] train: 8.028, val: 1.917\n",
      "[ACC%] train: 85.55%, val: 54.29%\n",
      "EPOCH: 186\n",
      "[LOSS] train: 7.967, val: 1.925\n",
      "[ACC%] train: 86.52%, val: 51.43%\n",
      "EPOCH: 187\n",
      "[LOSS] train: 8.037, val: 2.007\n",
      "[ACC%] train: 84.75%, val: 44.29%\n",
      "EPOCH: 188\n",
      "[LOSS] train: 7.991, val: 2.023\n",
      "[ACC%] train: 86.2%, val: 40.0%\n",
      "EPOCH: 189\n",
      "[LOSS] train: 7.889, val: 1.942\n",
      "[ACC%] train: 88.12%, val: 51.43%\n",
      "EPOCH: 190\n",
      "[LOSS] train: 7.916, val: 1.949\n",
      "[ACC%] train: 88.12%, val: 48.57%\n",
      "EPOCH: 191\n",
      "[LOSS] train: 7.954, val: 1.92\n",
      "[ACC%] train: 87.32%, val: 51.43%\n",
      "EPOCH: 192\n",
      "[LOSS] train: 7.909, val: 1.96\n",
      "[ACC%] train: 87.8%, val: 47.14%\n",
      "EPOCH: 193\n",
      "[LOSS] train: 7.922, val: 1.966\n",
      "[ACC%] train: 87.8%, val: 47.14%\n",
      "EPOCH: 194\n",
      "[LOSS] train: 7.895, val: 1.951\n",
      "[ACC%] train: 87.8%, val: 48.57%\n",
      "EPOCH: 195\n",
      "[LOSS] train: 7.954, val: 1.913\n",
      "[ACC%] train: 87.48%, val: 52.86%\n",
      "EPOCH: 196\n",
      "[LOSS] train: 7.975, val: 1.951\n",
      "[ACC%] train: 86.68%, val: 48.57%\n",
      "EPOCH: 197\n",
      "[LOSS] train: 7.924, val: 1.95\n",
      "[ACC%] train: 87.48%, val: 47.14%\n",
      "EPOCH: 198\n",
      "[LOSS] train: 7.895, val: 1.993\n",
      "[ACC%] train: 88.44%, val: 42.86%\n",
      "EPOCH: 199\n",
      "[LOSS] train: 7.903, val: 1.976\n",
      "[ACC%] train: 87.64%, val: 47.14%\n",
      "\n",
      "\n",
      "Working on 2th Fold\n",
      "EPOCH: 0\n",
      "[LOSS] train: 8.164, val: 1.517\n",
      "[ACC%] train: 82.99%, val: 94.29%\n",
      "EPOCH: 1\n",
      "[LOSS] train: 8.139, val: 1.521\n",
      "[ACC%] train: 82.99%, val: 94.29%\n",
      "EPOCH: 2\n",
      "[LOSS] train: 8.139, val: 1.568\n",
      "[ACC%] train: 83.63%, val: 88.57%\n",
      "EPOCH: 3\n",
      "[LOSS] train: 8.229, val: 1.582\n",
      "[ACC%] train: 80.9%, val: 87.14%\n",
      "EPOCH: 4\n",
      "[LOSS] train: 8.255, val: 1.57\n",
      "[ACC%] train: 80.26%, val: 87.14%\n",
      "EPOCH: 5\n",
      "[LOSS] train: 8.231, val: 1.517\n",
      "[ACC%] train: 81.22%, val: 94.29%\n",
      "EPOCH: 6\n",
      "[LOSS] train: 8.305, val: 1.517\n",
      "[ACC%] train: 79.45%, val: 94.29%\n",
      "EPOCH: 7\n",
      "[LOSS] train: 8.106, val: 1.518\n",
      "[ACC%] train: 84.11%, val: 94.29%\n",
      "EPOCH: 8\n",
      "[LOSS] train: 8.13, val: 1.52\n",
      "[ACC%] train: 83.47%, val: 94.29%\n",
      "EPOCH: 9\n",
      "[LOSS] train: 8.153, val: 1.56\n",
      "[ACC%] train: 82.5%, val: 88.57%\n",
      "EPOCH: 10\n",
      "[LOSS] train: 8.104, val: 1.517\n",
      "[ACC%] train: 83.47%, val: 94.29%\n",
      "EPOCH: 11\n",
      "[LOSS] train: 8.137, val: 1.517\n",
      "[ACC%] train: 82.99%, val: 94.29%\n",
      "EPOCH: 12\n",
      "[LOSS] train: 8.09, val: 1.517\n",
      "[ACC%] train: 84.75%, val: 94.29%\n",
      "EPOCH: 13\n",
      "[LOSS] train: 8.12, val: 1.583\n",
      "[ACC%] train: 83.47%, val: 87.14%\n",
      "EPOCH: 14\n",
      "[LOSS] train: 8.102, val: 1.693\n",
      "[ACC%] train: 84.27%, val: 74.29%\n",
      "EPOCH: 15\n",
      "[LOSS] train: 8.097, val: 1.703\n",
      "[ACC%] train: 84.11%, val: 72.86%\n",
      "EPOCH: 16\n",
      "[LOSS] train: 8.052, val: 1.722\n",
      "[ACC%] train: 85.07%, val: 70.0%\n",
      "EPOCH: 17\n",
      "[LOSS] train: 8.207, val: 1.656\n",
      "[ACC%] train: 81.86%, val: 75.71%\n",
      "EPOCH: 18\n",
      "[LOSS] train: 8.042, val: 1.54\n",
      "[ACC%] train: 85.55%, val: 91.43%\n",
      "EPOCH: 19\n",
      "[LOSS] train: 8.084, val: 1.518\n",
      "[ACC%] train: 84.43%, val: 94.29%\n",
      "EPOCH: 20\n",
      "[LOSS] train: 8.067, val: 1.518\n",
      "[ACC%] train: 84.59%, val: 94.29%\n",
      "EPOCH: 21\n",
      "[LOSS] train: 8.045, val: 1.518\n",
      "[ACC%] train: 85.39%, val: 94.29%\n",
      "EPOCH: 22\n",
      "[LOSS] train: 8.021, val: 1.518\n",
      "[ACC%] train: 86.2%, val: 94.29%\n",
      "EPOCH: 23\n",
      "[LOSS] train: 8.095, val: 1.636\n",
      "[ACC%] train: 83.79%, val: 81.43%\n",
      "EPOCH: 24\n",
      "[LOSS] train: 8.04, val: 1.716\n",
      "[ACC%] train: 85.55%, val: 71.43%\n",
      "EPOCH: 25\n",
      "[LOSS] train: 8.065, val: 1.555\n",
      "[ACC%] train: 84.91%, val: 90.0%\n",
      "EPOCH: 26\n",
      "[LOSS] train: 7.954, val: 1.671\n",
      "[ACC%] train: 86.84%, val: 75.71%\n",
      "EPOCH: 27\n",
      "[LOSS] train: 8.026, val: 1.824\n",
      "[ACC%] train: 85.39%, val: 60.0%\n",
      "EPOCH: 28\n",
      "[LOSS] train: 8.102, val: 1.827\n",
      "[ACC%] train: 83.95%, val: 60.0%\n",
      "EPOCH: 29\n",
      "[LOSS] train: 7.903, val: 1.842\n",
      "[ACC%] train: 88.12%, val: 58.57%\n",
      "EPOCH: 30\n",
      "[LOSS] train: 8.084, val: 1.812\n",
      "[ACC%] train: 84.43%, val: 62.86%\n",
      "EPOCH: 31\n",
      "[LOSS] train: 8.055, val: 1.548\n",
      "[ACC%] train: 85.39%, val: 91.43%\n",
      "EPOCH: 32\n",
      "[LOSS] train: 8.008, val: 1.518\n",
      "[ACC%] train: 86.04%, val: 94.29%\n",
      "EPOCH: 33\n",
      "[LOSS] train: 8.012, val: 1.532\n",
      "[ACC%] train: 85.71%, val: 94.29%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 34\n",
      "[LOSS] train: 8.011, val: 1.538\n",
      "[ACC%] train: 85.39%, val: 91.43%\n",
      "EPOCH: 35\n",
      "[LOSS] train: 8.0, val: 1.522\n",
      "[ACC%] train: 86.52%, val: 94.29%\n",
      "EPOCH: 36\n",
      "[LOSS] train: 8.166, val: 1.524\n",
      "[ACC%] train: 82.83%, val: 92.86%\n",
      "EPOCH: 37\n",
      "[LOSS] train: 8.037, val: 1.518\n",
      "[ACC%] train: 84.59%, val: 94.29%\n",
      "EPOCH: 38\n",
      "[LOSS] train: 7.953, val: 1.518\n",
      "[ACC%] train: 86.68%, val: 94.29%\n",
      "EPOCH: 39\n",
      "[LOSS] train: 8.027, val: 1.522\n",
      "[ACC%] train: 85.23%, val: 94.29%\n",
      "EPOCH: 40\n",
      "[LOSS] train: 8.014, val: 1.523\n",
      "[ACC%] train: 86.52%, val: 94.29%\n",
      "EPOCH: 41\n",
      "[LOSS] train: 7.974, val: 1.527\n",
      "[ACC%] train: 86.52%, val: 92.86%\n",
      "EPOCH: 42\n",
      "[LOSS] train: 8.011, val: 1.55\n",
      "[ACC%] train: 85.71%, val: 90.0%\n",
      "EPOCH: 43\n",
      "[LOSS] train: 8.11, val: 1.573\n",
      "[ACC%] train: 83.79%, val: 88.57%\n",
      "EPOCH: 44\n",
      "[LOSS] train: 8.017, val: 1.529\n",
      "[ACC%] train: 85.87%, val: 92.86%\n",
      "EPOCH: 45\n",
      "[LOSS] train: 8.047, val: 1.519\n",
      "[ACC%] train: 84.75%, val: 94.29%\n",
      "EPOCH: 46\n",
      "[LOSS] train: 8.061, val: 1.556\n",
      "[ACC%] train: 85.23%, val: 90.0%\n",
      "EPOCH: 47\n",
      "[LOSS] train: 7.996, val: 1.584\n",
      "[ACC%] train: 85.39%, val: 88.57%\n",
      "EPOCH: 48\n",
      "[LOSS] train: 7.926, val: 1.521\n",
      "[ACC%] train: 87.32%, val: 94.29%\n",
      "EPOCH: 49\n",
      "[LOSS] train: 7.871, val: 1.519\n",
      "[ACC%] train: 88.76%, val: 94.29%\n",
      "EPOCH: 50\n",
      "[LOSS] train: 7.944, val: 1.53\n",
      "[ACC%] train: 87.0%, val: 92.86%\n",
      "EPOCH: 51\n",
      "[LOSS] train: 8.049, val: 1.54\n",
      "[ACC%] train: 85.07%, val: 91.43%\n",
      "EPOCH: 52\n",
      "[LOSS] train: 7.94, val: 1.529\n",
      "[ACC%] train: 87.0%, val: 92.86%\n",
      "EPOCH: 53\n",
      "[LOSS] train: 7.948, val: 1.545\n",
      "[ACC%] train: 87.16%, val: 91.43%\n",
      "EPOCH: 54\n",
      "[LOSS] train: 7.897, val: 1.537\n",
      "[ACC%] train: 87.96%, val: 92.86%\n",
      "EPOCH: 55\n",
      "[LOSS] train: 7.945, val: 1.544\n",
      "[ACC%] train: 86.52%, val: 91.43%\n",
      "EPOCH: 56\n",
      "[LOSS] train: 8.013, val: 1.534\n",
      "[ACC%] train: 86.2%, val: 92.86%\n",
      "EPOCH: 57\n",
      "[LOSS] train: 7.92, val: 1.53\n",
      "[ACC%] train: 87.96%, val: 92.86%\n",
      "EPOCH: 58\n",
      "[LOSS] train: 8.004, val: 1.525\n",
      "[ACC%] train: 85.71%, val: 92.86%\n",
      "EPOCH: 59\n",
      "[LOSS] train: 7.944, val: 1.545\n",
      "[ACC%] train: 87.16%, val: 91.43%\n",
      "EPOCH: 60\n",
      "[LOSS] train: 7.995, val: 1.552\n",
      "[ACC%] train: 86.04%, val: 91.43%\n",
      "EPOCH: 61\n",
      "[LOSS] train: 7.875, val: 1.595\n",
      "[ACC%] train: 88.76%, val: 85.71%\n",
      "EPOCH: 62\n",
      "[LOSS] train: 7.96, val: 1.555\n",
      "[ACC%] train: 86.68%, val: 90.0%\n",
      "EPOCH: 63\n",
      "[LOSS] train: 7.946, val: 1.547\n",
      "[ACC%] train: 87.16%, val: 91.43%\n",
      "EPOCH: 64\n",
      "[LOSS] train: 7.995, val: 1.562\n",
      "[ACC%] train: 85.87%, val: 90.0%\n",
      "EPOCH: 65\n",
      "[LOSS] train: 7.859, val: 1.589\n",
      "[ACC%] train: 89.09%, val: 88.57%\n",
      "EPOCH: 66\n",
      "[LOSS] train: 7.917, val: 1.587\n",
      "[ACC%] train: 87.48%, val: 87.14%\n",
      "EPOCH: 67\n",
      "[LOSS] train: 7.894, val: 1.552\n",
      "[ACC%] train: 87.96%, val: 91.43%\n",
      "EPOCH: 68\n",
      "[LOSS] train: 7.892, val: 1.602\n",
      "[ACC%] train: 88.12%, val: 87.14%\n",
      "EPOCH: 69\n",
      "[LOSS] train: 7.915, val: 1.643\n",
      "[ACC%] train: 87.8%, val: 82.86%\n",
      "EPOCH: 70\n",
      "[LOSS] train: 7.906, val: 1.565\n",
      "[ACC%] train: 88.12%, val: 88.57%\n",
      "EPOCH: 71\n",
      "[LOSS] train: 7.918, val: 1.535\n",
      "[ACC%] train: 87.96%, val: 92.86%\n",
      "EPOCH: 72\n",
      "[LOSS] train: 7.921, val: 1.527\n",
      "[ACC%] train: 87.48%, val: 92.86%\n",
      "EPOCH: 73\n",
      "[LOSS] train: 7.908, val: 1.525\n",
      "[ACC%] train: 87.96%, val: 92.86%\n",
      "EPOCH: 74\n",
      "[LOSS] train: 7.936, val: 1.526\n",
      "[ACC%] train: 87.48%, val: 92.86%\n",
      "EPOCH: 75\n",
      "[LOSS] train: 7.891, val: 1.535\n",
      "[ACC%] train: 88.6%, val: 91.43%\n",
      "EPOCH: 76\n",
      "[LOSS] train: 7.828, val: 1.549\n",
      "[ACC%] train: 89.57%, val: 90.0%\n",
      "EPOCH: 77\n",
      "[LOSS] train: 7.927, val: 1.577\n",
      "[ACC%] train: 87.48%, val: 88.57%\n",
      "EPOCH: 78\n",
      "[LOSS] train: 7.861, val: 1.59\n",
      "[ACC%] train: 89.25%, val: 87.14%\n",
      "EPOCH: 79\n",
      "[LOSS] train: 7.844, val: 1.567\n",
      "[ACC%] train: 89.09%, val: 88.57%\n",
      "EPOCH: 80\n",
      "[LOSS] train: 7.871, val: 1.56\n",
      "[ACC%] train: 88.12%, val: 90.0%\n",
      "EPOCH: 81\n",
      "[LOSS] train: 7.965, val: 1.53\n",
      "[ACC%] train: 86.68%, val: 92.86%\n",
      "EPOCH: 82\n",
      "[LOSS] train: 7.909, val: 1.526\n",
      "[ACC%] train: 87.8%, val: 94.29%\n",
      "EPOCH: 83\n",
      "[LOSS] train: 7.914, val: 1.526\n",
      "[ACC%] train: 87.64%, val: 94.29%\n",
      "EPOCH: 84\n",
      "[LOSS] train: 7.852, val: 1.549\n",
      "[ACC%] train: 88.92%, val: 91.43%\n",
      "EPOCH: 85\n",
      "[LOSS] train: 7.919, val: 1.554\n",
      "[ACC%] train: 87.0%, val: 90.0%\n",
      "EPOCH: 86\n",
      "[LOSS] train: 7.837, val: 1.547\n",
      "[ACC%] train: 89.25%, val: 91.43%\n",
      "EPOCH: 87\n",
      "[LOSS] train: 7.833, val: 1.527\n",
      "[ACC%] train: 89.73%, val: 94.29%\n",
      "EPOCH: 88\n",
      "[LOSS] train: 7.95, val: 1.532\n",
      "[ACC%] train: 87.16%, val: 92.86%\n",
      "EPOCH: 89\n",
      "[LOSS] train: 7.913, val: 1.601\n",
      "[ACC%] train: 88.28%, val: 85.71%\n",
      "EPOCH: 90\n",
      "[LOSS] train: 7.859, val: 1.642\n",
      "[ACC%] train: 89.25%, val: 84.29%\n",
      "EPOCH: 91\n",
      "[LOSS] train: 7.842, val: 1.638\n",
      "[ACC%] train: 89.41%, val: 82.86%\n",
      "EPOCH: 92\n",
      "[LOSS] train: 7.888, val: 1.6\n",
      "[ACC%] train: 88.28%, val: 87.14%\n",
      "EPOCH: 93\n",
      "[LOSS] train: 7.837, val: 1.561\n",
      "[ACC%] train: 89.57%, val: 90.0%\n",
      "EPOCH: 94\n",
      "[LOSS] train: 7.919, val: 1.63\n",
      "[ACC%] train: 87.8%, val: 82.86%\n",
      "EPOCH: 95\n",
      "[LOSS] train: 7.923, val: 1.558\n",
      "[ACC%] train: 87.32%, val: 90.0%\n",
      "EPOCH: 96\n",
      "[LOSS] train: 7.834, val: 1.568\n",
      "[ACC%] train: 89.57%, val: 88.57%\n",
      "EPOCH: 97\n",
      "[LOSS] train: 7.873, val: 1.574\n",
      "[ACC%] train: 87.8%, val: 87.14%\n",
      "EPOCH: 98\n",
      "[LOSS] train: 7.849, val: 1.551\n",
      "[ACC%] train: 89.09%, val: 91.43%\n",
      "EPOCH: 99\n",
      "[LOSS] train: 7.877, val: 1.565\n",
      "[ACC%] train: 88.12%, val: 90.0%\n",
      "EPOCH: 100\n",
      "[LOSS] train: 7.939, val: 1.623\n",
      "[ACC%] train: 87.32%, val: 82.86%\n",
      "EPOCH: 101\n",
      "[LOSS] train: 7.911, val: 1.631\n",
      "[ACC%] train: 87.8%, val: 82.86%\n",
      "EPOCH: 102\n",
      "[LOSS] train: 7.961, val: 1.603\n",
      "[ACC%] train: 86.52%, val: 84.29%\n",
      "EPOCH: 103\n",
      "[LOSS] train: 7.756, val: 1.576\n",
      "[ACC%] train: 90.69%, val: 88.57%\n",
      "EPOCH: 104\n",
      "[LOSS] train: 7.894, val: 1.562\n",
      "[ACC%] train: 87.96%, val: 90.0%\n",
      "EPOCH: 105\n",
      "[LOSS] train: 7.868, val: 1.555\n",
      "[ACC%] train: 88.44%, val: 90.0%\n",
      "EPOCH: 106\n",
      "[LOSS] train: 7.84, val: 1.568\n",
      "[ACC%] train: 89.25%, val: 88.57%\n",
      "EPOCH: 107\n",
      "[LOSS] train: 7.923, val: 1.628\n",
      "[ACC%] train: 87.64%, val: 81.43%\n",
      "EPOCH: 108\n",
      "[LOSS] train: 7.955, val: 1.643\n",
      "[ACC%] train: 87.16%, val: 78.57%\n",
      "EPOCH: 109\n",
      "[LOSS] train: 7.988, val: 1.641\n",
      "[ACC%] train: 86.36%, val: 82.86%\n",
      "EPOCH: 110\n",
      "[LOSS] train: 7.9, val: 1.742\n",
      "[ACC%] train: 87.8%, val: 71.43%\n",
      "EPOCH: 111\n",
      "[LOSS] train: 7.902, val: 1.654\n",
      "[ACC%] train: 88.12%, val: 80.0%\n",
      "EPOCH: 112\n",
      "[LOSS] train: 7.803, val: 1.587\n",
      "[ACC%] train: 90.21%, val: 87.14%\n",
      "EPOCH: 113\n",
      "[LOSS] train: 7.881, val: 1.587\n",
      "[ACC%] train: 88.28%, val: 87.14%\n",
      "EPOCH: 114\n",
      "[LOSS] train: 7.924, val: 1.609\n",
      "[ACC%] train: 87.64%, val: 84.29%\n",
      "EPOCH: 115\n",
      "[LOSS] train: 8.018, val: 1.607\n",
      "[ACC%] train: 85.71%, val: 85.71%\n",
      "EPOCH: 116\n",
      "[LOSS] train: 7.895, val: 1.59\n",
      "[ACC%] train: 88.44%, val: 87.14%\n",
      "EPOCH: 117\n",
      "[LOSS] train: 7.926, val: 1.561\n",
      "[ACC%] train: 87.64%, val: 90.0%\n",
      "EPOCH: 118\n",
      "[LOSS] train: 7.857, val: 1.711\n",
      "[ACC%] train: 88.44%, val: 75.71%\n",
      "EPOCH: 119\n",
      "[LOSS] train: 7.912, val: 1.791\n",
      "[ACC%] train: 88.12%, val: 68.57%\n",
      "EPOCH: 120\n",
      "[LOSS] train: 7.889, val: 1.72\n",
      "[ACC%] train: 88.6%, val: 75.71%\n",
      "EPOCH: 121\n",
      "[LOSS] train: 7.864, val: 1.6\n",
      "[ACC%] train: 88.6%, val: 85.71%\n",
      "EPOCH: 122\n",
      "[LOSS] train: 7.852, val: 1.561\n",
      "[ACC%] train: 89.09%, val: 90.0%\n",
      "EPOCH: 123\n",
      "[LOSS] train: 7.833, val: 1.618\n",
      "[ACC%] train: 89.25%, val: 84.29%\n",
      "EPOCH: 124\n",
      "[LOSS] train: 7.768, val: 1.622\n",
      "[ACC%] train: 91.33%, val: 84.29%\n",
      "EPOCH: 125\n",
      "[LOSS] train: 7.909, val: 1.623\n",
      "[ACC%] train: 87.96%, val: 84.29%\n",
      "EPOCH: 126\n",
      "[LOSS] train: 7.832, val: 1.642\n",
      "[ACC%] train: 89.89%, val: 82.86%\n",
      "EPOCH: 127\n",
      "[LOSS] train: 7.819, val: 1.623\n",
      "[ACC%] train: 90.05%, val: 82.86%\n",
      "EPOCH: 128\n",
      "[LOSS] train: 7.774, val: 1.644\n",
      "[ACC%] train: 90.37%, val: 81.43%\n",
      "EPOCH: 129\n",
      "[LOSS] train: 7.91, val: 1.68\n",
      "[ACC%] train: 87.48%, val: 77.14%\n",
      "EPOCH: 130\n",
      "[LOSS] train: 7.731, val: 1.689\n",
      "[ACC%] train: 91.65%, val: 75.71%\n",
      "EPOCH: 131\n",
      "[LOSS] train: 7.858, val: 1.717\n",
      "[ACC%] train: 88.28%, val: 75.71%\n",
      "EPOCH: 132\n",
      "[LOSS] train: 7.866, val: 1.657\n",
      "[ACC%] train: 88.76%, val: 81.43%\n",
      "EPOCH: 133\n",
      "[LOSS] train: 7.888, val: 1.6\n",
      "[ACC%] train: 88.6%, val: 87.14%\n",
      "EPOCH: 134\n",
      "[LOSS] train: 7.82, val: 1.6\n",
      "[ACC%] train: 90.05%, val: 85.71%\n",
      "EPOCH: 135\n",
      "[LOSS] train: 7.839, val: 1.612\n",
      "[ACC%] train: 89.25%, val: 85.71%\n",
      "EPOCH: 136\n",
      "[LOSS] train: 7.906, val: 1.591\n",
      "[ACC%] train: 87.8%, val: 87.14%\n",
      "EPOCH: 137\n",
      "[LOSS] train: 7.822, val: 1.587\n",
      "[ACC%] train: 89.89%, val: 87.14%\n",
      "EPOCH: 138\n",
      "[LOSS] train: 7.793, val: 1.613\n",
      "[ACC%] train: 89.89%, val: 84.29%\n",
      "EPOCH: 139\n",
      "[LOSS] train: 7.88, val: 1.647\n",
      "[ACC%] train: 88.44%, val: 81.43%\n",
      "EPOCH: 140\n",
      "[LOSS] train: 7.847, val: 1.644\n",
      "[ACC%] train: 89.57%, val: 82.86%\n",
      "EPOCH: 141\n",
      "[LOSS] train: 7.871, val: 1.68\n",
      "[ACC%] train: 88.6%, val: 78.57%\n",
      "EPOCH: 142\n",
      "[LOSS] train: 7.894, val: 1.664\n",
      "[ACC%] train: 88.6%, val: 80.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 143\n",
      "[LOSS] train: 7.776, val: 1.596\n",
      "[ACC%] train: 90.53%, val: 87.14%\n",
      "EPOCH: 144\n",
      "[LOSS] train: 7.804, val: 1.619\n",
      "[ACC%] train: 90.37%, val: 85.71%\n",
      "EPOCH: 145\n",
      "[LOSS] train: 7.869, val: 1.611\n",
      "[ACC%] train: 88.28%, val: 84.29%\n",
      "EPOCH: 146\n",
      "[LOSS] train: 7.79, val: 1.593\n",
      "[ACC%] train: 90.37%, val: 87.14%\n",
      "EPOCH: 147\n",
      "[LOSS] train: 7.852, val: 1.595\n",
      "[ACC%] train: 88.76%, val: 88.57%\n",
      "EPOCH: 148\n",
      "[LOSS] train: 7.754, val: 1.703\n",
      "[ACC%] train: 91.49%, val: 77.14%\n",
      "EPOCH: 149\n",
      "[LOSS] train: 7.837, val: 1.647\n",
      "[ACC%] train: 89.89%, val: 82.86%\n",
      "EPOCH: 150\n",
      "[LOSS] train: 7.81, val: 1.559\n",
      "[ACC%] train: 90.05%, val: 91.43%\n",
      "EPOCH: 151\n",
      "[LOSS] train: 7.76, val: 1.597\n",
      "[ACC%] train: 90.53%, val: 85.71%\n",
      "EPOCH: 152\n",
      "[LOSS] train: 7.906, val: 1.573\n",
      "[ACC%] train: 87.64%, val: 88.57%\n",
      "EPOCH: 153\n",
      "[LOSS] train: 7.838, val: 1.574\n",
      "[ACC%] train: 89.25%, val: 88.57%\n",
      "EPOCH: 154\n",
      "[LOSS] train: 7.913, val: 1.585\n",
      "[ACC%] train: 87.8%, val: 87.14%\n",
      "EPOCH: 155\n",
      "[LOSS] train: 7.773, val: 1.614\n",
      "[ACC%] train: 90.53%, val: 84.29%\n",
      "EPOCH: 156\n",
      "[LOSS] train: 7.928, val: 1.655\n",
      "[ACC%] train: 87.48%, val: 80.0%\n",
      "EPOCH: 157\n",
      "[LOSS] train: 7.853, val: 1.682\n",
      "[ACC%] train: 88.76%, val: 78.57%\n",
      "EPOCH: 158\n",
      "[LOSS] train: 7.799, val: 1.662\n",
      "[ACC%] train: 90.21%, val: 80.0%\n",
      "EPOCH: 159\n",
      "[LOSS] train: 7.86, val: 1.69\n",
      "[ACC%] train: 88.6%, val: 80.0%\n",
      "EPOCH: 160\n",
      "[LOSS] train: 7.87, val: 1.673\n",
      "[ACC%] train: 89.25%, val: 77.14%\n",
      "EPOCH: 161\n",
      "[LOSS] train: 7.837, val: 1.61\n",
      "[ACC%] train: 89.73%, val: 84.29%\n",
      "EPOCH: 162\n",
      "[LOSS] train: 7.845, val: 1.605\n",
      "[ACC%] train: 89.41%, val: 85.71%\n",
      "EPOCH: 163\n",
      "[LOSS] train: 7.785, val: 1.615\n",
      "[ACC%] train: 89.57%, val: 84.29%\n",
      "EPOCH: 164\n",
      "[LOSS] train: 7.742, val: 1.676\n",
      "[ACC%] train: 90.85%, val: 78.57%\n",
      "EPOCH: 165\n",
      "[LOSS] train: 7.769, val: 1.688\n",
      "[ACC%] train: 90.53%, val: 75.71%\n",
      "EPOCH: 166\n",
      "[LOSS] train: 7.842, val: 1.663\n",
      "[ACC%] train: 89.25%, val: 80.0%\n",
      "EPOCH: 167\n",
      "[LOSS] train: 7.774, val: 1.681\n",
      "[ACC%] train: 90.85%, val: 78.57%\n",
      "EPOCH: 168\n",
      "[LOSS] train: 7.845, val: 1.652\n",
      "[ACC%] train: 89.41%, val: 80.0%\n",
      "EPOCH: 169\n",
      "[LOSS] train: 7.762, val: 1.625\n",
      "[ACC%] train: 90.69%, val: 84.29%\n",
      "EPOCH: 170\n",
      "[LOSS] train: 7.788, val: 1.665\n",
      "[ACC%] train: 90.69%, val: 80.0%\n",
      "EPOCH: 171\n",
      "[LOSS] train: 7.759, val: 1.678\n",
      "[ACC%] train: 90.85%, val: 77.14%\n",
      "EPOCH: 172\n",
      "[LOSS] train: 7.803, val: 1.684\n",
      "[ACC%] train: 89.89%, val: 77.14%\n",
      "EPOCH: 173\n",
      "[LOSS] train: 7.818, val: 1.672\n",
      "[ACC%] train: 89.41%, val: 78.57%\n",
      "EPOCH: 174\n",
      "[LOSS] train: 7.768, val: 1.618\n",
      "[ACC%] train: 91.01%, val: 84.29%\n",
      "EPOCH: 175\n",
      "[LOSS] train: 7.777, val: 1.727\n",
      "[ACC%] train: 90.69%, val: 72.86%\n",
      "EPOCH: 176\n",
      "[LOSS] train: 7.818, val: 1.753\n",
      "[ACC%] train: 89.89%, val: 70.0%\n",
      "EPOCH: 177\n",
      "[LOSS] train: 7.791, val: 1.841\n",
      "[ACC%] train: 90.53%, val: 60.0%\n",
      "EPOCH: 178\n",
      "[LOSS] train: 7.824, val: 1.84\n",
      "[ACC%] train: 89.73%, val: 61.43%\n",
      "EPOCH: 179\n",
      "[LOSS] train: 7.802, val: 1.984\n",
      "[ACC%] train: 90.21%, val: 47.14%\n",
      "EPOCH: 180\n",
      "[LOSS] train: 7.806, val: 1.84\n",
      "[ACC%] train: 90.05%, val: 62.86%\n",
      "EPOCH: 181\n",
      "[LOSS] train: 7.736, val: 1.805\n",
      "[ACC%] train: 91.49%, val: 65.71%\n",
      "EPOCH: 182\n",
      "[LOSS] train: 7.727, val: 1.703\n",
      "[ACC%] train: 91.81%, val: 75.71%\n",
      "EPOCH: 183\n",
      "[LOSS] train: 7.721, val: 1.682\n",
      "[ACC%] train: 91.81%, val: 78.57%\n",
      "EPOCH: 184\n",
      "[LOSS] train: 7.741, val: 1.663\n",
      "[ACC%] train: 91.33%, val: 81.43%\n",
      "EPOCH: 185\n",
      "[LOSS] train: 7.764, val: 1.607\n",
      "[ACC%] train: 90.69%, val: 87.14%\n",
      "EPOCH: 186\n",
      "[LOSS] train: 7.802, val: 1.633\n",
      "[ACC%] train: 90.21%, val: 82.86%\n",
      "EPOCH: 187\n",
      "[LOSS] train: 7.818, val: 1.728\n",
      "[ACC%] train: 89.89%, val: 71.43%\n",
      "EPOCH: 188\n",
      "[LOSS] train: 7.766, val: 2.151\n",
      "[ACC%] train: 91.01%, val: 31.43%\n",
      "EPOCH: 189\n",
      "[LOSS] train: 7.753, val: 2.128\n",
      "[ACC%] train: 91.33%, val: 34.29%\n",
      "EPOCH: 190\n",
      "[LOSS] train: 7.796, val: 1.978\n",
      "[ACC%] train: 90.21%, val: 48.57%\n",
      "EPOCH: 191\n",
      "[LOSS] train: 7.728, val: 1.976\n",
      "[ACC%] train: 91.81%, val: 50.0%\n",
      "EPOCH: 192\n",
      "[LOSS] train: 7.837, val: 1.9\n",
      "[ACC%] train: 89.57%, val: 54.29%\n",
      "EPOCH: 193\n",
      "[LOSS] train: 7.723, val: 1.944\n",
      "[ACC%] train: 91.65%, val: 51.43%\n",
      "EPOCH: 194\n",
      "[LOSS] train: 7.802, val: 1.988\n",
      "[ACC%] train: 89.89%, val: 48.57%\n",
      "EPOCH: 195\n",
      "[LOSS] train: 7.787, val: 2.04\n",
      "[ACC%] train: 90.37%, val: 42.86%\n",
      "EPOCH: 196\n",
      "[LOSS] train: 7.819, val: 2.138\n",
      "[ACC%] train: 89.41%, val: 31.43%\n",
      "EPOCH: 197\n",
      "[LOSS] train: 7.769, val: 2.205\n",
      "[ACC%] train: 91.01%, val: 25.71%\n",
      "EPOCH: 198\n",
      "[LOSS] train: 7.9, val: 2.136\n",
      "[ACC%] train: 88.28%, val: 32.86%\n",
      "EPOCH: 199\n",
      "[LOSS] train: 7.784, val: 1.935\n",
      "[ACC%] train: 90.37%, val: 52.86%\n",
      "\n",
      "\n",
      "Working on 3th Fold\n",
      "EPOCH: 0\n",
      "[LOSS] train: 7.99, val: 1.492\n",
      "[ACC%] train: 86.7%, val: 97.1%\n",
      "EPOCH: 1\n",
      "[LOSS] train: 7.884, val: 1.53\n",
      "[ACC%] train: 88.46%, val: 92.75%\n",
      "EPOCH: 2\n",
      "[LOSS] train: 7.999, val: 1.564\n",
      "[ACC%] train: 86.22%, val: 88.41%\n",
      "EPOCH: 3\n",
      "[LOSS] train: 8.057, val: 1.49\n",
      "[ACC%] train: 84.78%, val: 97.1%\n",
      "EPOCH: 4\n",
      "[LOSS] train: 7.899, val: 1.49\n",
      "[ACC%] train: 87.98%, val: 97.1%\n",
      "EPOCH: 5\n",
      "[LOSS] train: 7.958, val: 1.49\n",
      "[ACC%] train: 86.38%, val: 97.1%\n",
      "EPOCH: 6\n",
      "[LOSS] train: 7.96, val: 1.554\n",
      "[ACC%] train: 86.38%, val: 91.3%\n",
      "EPOCH: 7\n",
      "[LOSS] train: 7.884, val: 1.496\n",
      "[ACC%] train: 88.94%, val: 97.1%\n",
      "EPOCH: 8\n",
      "[LOSS] train: 7.953, val: 1.49\n",
      "[ACC%] train: 87.34%, val: 97.1%\n",
      "EPOCH: 9\n",
      "[LOSS] train: 7.927, val: 1.486\n",
      "[ACC%] train: 87.82%, val: 97.1%\n",
      "EPOCH: 10\n",
      "[LOSS] train: 7.98, val: 1.505\n",
      "[ACC%] train: 85.9%, val: 95.65%\n",
      "EPOCH: 11\n",
      "[LOSS] train: 7.849, val: 1.673\n",
      "[ACC%] train: 88.78%, val: 78.26%\n",
      "EPOCH: 12\n",
      "[LOSS] train: 7.911, val: 1.82\n",
      "[ACC%] train: 87.82%, val: 63.77%\n",
      "EPOCH: 13\n",
      "[LOSS] train: 7.866, val: 1.567\n",
      "[ACC%] train: 88.78%, val: 88.41%\n",
      "EPOCH: 14\n",
      "[LOSS] train: 7.928, val: 1.51\n",
      "[ACC%] train: 87.5%, val: 95.65%\n",
      "EPOCH: 15\n",
      "[LOSS] train: 7.898, val: 1.577\n",
      "[ACC%] train: 88.14%, val: 86.96%\n",
      "EPOCH: 16\n",
      "[LOSS] train: 7.99, val: 1.57\n",
      "[ACC%] train: 86.22%, val: 88.41%\n",
      "EPOCH: 17\n",
      "[LOSS] train: 7.821, val: 1.561\n",
      "[ACC%] train: 88.94%, val: 88.41%\n",
      "EPOCH: 18\n",
      "[LOSS] train: 7.914, val: 1.548\n",
      "[ACC%] train: 87.5%, val: 91.3%\n",
      "EPOCH: 19\n",
      "[LOSS] train: 7.846, val: 1.59\n",
      "[ACC%] train: 88.78%, val: 86.96%\n",
      "EPOCH: 20\n",
      "[LOSS] train: 7.881, val: 1.588\n",
      "[ACC%] train: 88.3%, val: 86.96%\n",
      "EPOCH: 21\n",
      "[LOSS] train: 7.789, val: 1.506\n",
      "[ACC%] train: 90.22%, val: 95.65%\n",
      "EPOCH: 22\n",
      "[LOSS] train: 7.841, val: 1.509\n",
      "[ACC%] train: 88.94%, val: 94.2%\n",
      "EPOCH: 23\n",
      "[LOSS] train: 7.827, val: 1.502\n",
      "[ACC%] train: 89.42%, val: 95.65%\n",
      "EPOCH: 24\n",
      "[LOSS] train: 7.768, val: 1.506\n",
      "[ACC%] train: 90.87%, val: 95.65%\n",
      "EPOCH: 25\n",
      "[LOSS] train: 7.755, val: 1.491\n",
      "[ACC%] train: 91.35%, val: 97.1%\n",
      "EPOCH: 26\n",
      "[LOSS] train: 7.875, val: 1.481\n",
      "[ACC%] train: 87.82%, val: 98.55%\n",
      "EPOCH: 27\n",
      "[LOSS] train: 7.846, val: 1.488\n",
      "[ACC%] train: 89.26%, val: 97.1%\n",
      "EPOCH: 28\n",
      "[LOSS] train: 7.87, val: 1.489\n",
      "[ACC%] train: 89.42%, val: 97.1%\n",
      "EPOCH: 29\n",
      "[LOSS] train: 7.769, val: 1.523\n",
      "[ACC%] train: 91.19%, val: 94.2%\n",
      "EPOCH: 30\n",
      "[LOSS] train: 7.89, val: 1.553\n",
      "[ACC%] train: 87.98%, val: 89.86%\n",
      "EPOCH: 31\n",
      "[LOSS] train: 7.799, val: 1.614\n",
      "[ACC%] train: 90.22%, val: 84.06%\n",
      "EPOCH: 32\n",
      "[LOSS] train: 7.888, val: 1.517\n",
      "[ACC%] train: 88.62%, val: 94.2%\n",
      "EPOCH: 33\n",
      "[LOSS] train: 7.815, val: 1.503\n",
      "[ACC%] train: 89.26%, val: 95.65%\n",
      "EPOCH: 34\n",
      "[LOSS] train: 7.875, val: 1.521\n",
      "[ACC%] train: 88.3%, val: 94.2%\n",
      "EPOCH: 35\n",
      "[LOSS] train: 7.81, val: 1.513\n",
      "[ACC%] train: 89.74%, val: 95.65%\n",
      "EPOCH: 36\n",
      "[LOSS] train: 7.79, val: 1.55\n",
      "[ACC%] train: 90.38%, val: 91.3%\n",
      "EPOCH: 37\n",
      "[LOSS] train: 7.814, val: 1.637\n",
      "[ACC%] train: 89.74%, val: 81.16%\n",
      "EPOCH: 38\n",
      "[LOSS] train: 7.807, val: 1.585\n",
      "[ACC%] train: 89.74%, val: 88.41%\n",
      "EPOCH: 39\n",
      "[LOSS] train: 7.816, val: 1.515\n",
      "[ACC%] train: 90.06%, val: 95.65%\n",
      "EPOCH: 40\n",
      "[LOSS] train: 7.869, val: 1.52\n",
      "[ACC%] train: 88.46%, val: 94.2%\n",
      "EPOCH: 41\n",
      "[LOSS] train: 7.766, val: 1.517\n",
      "[ACC%] train: 90.38%, val: 94.2%\n",
      "EPOCH: 42\n",
      "[LOSS] train: 7.801, val: 1.523\n",
      "[ACC%] train: 90.22%, val: 94.2%\n",
      "EPOCH: 43\n",
      "[LOSS] train: 7.82, val: 1.529\n",
      "[ACC%] train: 89.1%, val: 94.2%\n",
      "EPOCH: 44\n",
      "[LOSS] train: 7.822, val: 1.565\n",
      "[ACC%] train: 89.74%, val: 88.41%\n",
      "EPOCH: 45\n",
      "[LOSS] train: 7.78, val: 1.548\n",
      "[ACC%] train: 90.87%, val: 91.3%\n",
      "EPOCH: 46\n",
      "[LOSS] train: 7.798, val: 1.52\n",
      "[ACC%] train: 89.9%, val: 94.2%\n",
      "EPOCH: 47\n",
      "[LOSS] train: 7.783, val: 1.505\n",
      "[ACC%] train: 90.38%, val: 95.65%\n",
      "EPOCH: 48\n",
      "[LOSS] train: 7.852, val: 1.504\n",
      "[ACC%] train: 88.78%, val: 95.65%\n",
      "EPOCH: 49\n",
      "[LOSS] train: 7.794, val: 1.507\n",
      "[ACC%] train: 90.22%, val: 95.65%\n",
      "EPOCH: 50\n",
      "[LOSS] train: 7.801, val: 1.556\n",
      "[ACC%] train: 89.58%, val: 89.86%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 51\n",
      "[LOSS] train: 7.778, val: 1.591\n",
      "[ACC%] train: 90.38%, val: 86.96%\n",
      "EPOCH: 52\n",
      "[LOSS] train: 7.833, val: 1.688\n",
      "[ACC%] train: 89.42%, val: 76.81%\n",
      "EPOCH: 53\n",
      "[LOSS] train: 7.783, val: 1.748\n",
      "[ACC%] train: 90.71%, val: 69.57%\n",
      "EPOCH: 54\n",
      "[LOSS] train: 7.742, val: 1.578\n",
      "[ACC%] train: 91.19%, val: 88.41%\n",
      "EPOCH: 55\n",
      "[LOSS] train: 7.877, val: 1.67\n",
      "[ACC%] train: 88.78%, val: 78.26%\n",
      "EPOCH: 56\n",
      "[LOSS] train: 7.846, val: 1.59\n",
      "[ACC%] train: 88.46%, val: 86.96%\n",
      "EPOCH: 57\n",
      "[LOSS] train: 7.74, val: 1.705\n",
      "[ACC%] train: 91.19%, val: 75.36%\n",
      "EPOCH: 58\n",
      "[LOSS] train: 7.884, val: 1.804\n",
      "[ACC%] train: 88.3%, val: 65.22%\n",
      "EPOCH: 59\n",
      "[LOSS] train: 7.8, val: 1.594\n",
      "[ACC%] train: 90.22%, val: 86.96%\n",
      "EPOCH: 60\n",
      "[LOSS] train: 7.922, val: 1.506\n",
      "[ACC%] train: 87.82%, val: 95.65%\n",
      "EPOCH: 61\n",
      "[LOSS] train: 7.744, val: 1.514\n",
      "[ACC%] train: 91.03%, val: 94.2%\n",
      "EPOCH: 62\n",
      "[LOSS] train: 7.776, val: 1.522\n",
      "[ACC%] train: 90.87%, val: 94.2%\n",
      "EPOCH: 63\n",
      "[LOSS] train: 7.808, val: 1.527\n",
      "[ACC%] train: 90.06%, val: 94.2%\n",
      "EPOCH: 64\n",
      "[LOSS] train: 7.808, val: 1.604\n",
      "[ACC%] train: 90.87%, val: 85.51%\n",
      "EPOCH: 65\n",
      "[LOSS] train: 7.772, val: 1.764\n",
      "[ACC%] train: 90.87%, val: 69.57%\n",
      "EPOCH: 66\n",
      "[LOSS] train: 7.786, val: 1.596\n",
      "[ACC%] train: 90.22%, val: 86.96%\n",
      "EPOCH: 67\n",
      "[LOSS] train: 7.891, val: 1.563\n",
      "[ACC%] train: 88.14%, val: 91.3%\n",
      "EPOCH: 68\n",
      "[LOSS] train: 7.7, val: 1.554\n",
      "[ACC%] train: 92.15%, val: 91.3%\n",
      "EPOCH: 69\n",
      "[LOSS] train: 7.789, val: 1.549\n",
      "[ACC%] train: 90.22%, val: 91.3%\n",
      "EPOCH: 70\n",
      "[LOSS] train: 7.73, val: 1.519\n",
      "[ACC%] train: 91.83%, val: 94.2%\n",
      "EPOCH: 71\n",
      "[LOSS] train: 7.74, val: 1.509\n",
      "[ACC%] train: 91.19%, val: 95.65%\n",
      "EPOCH: 72\n",
      "[LOSS] train: 7.743, val: 1.508\n",
      "[ACC%] train: 91.67%, val: 95.65%\n",
      "EPOCH: 73\n",
      "[LOSS] train: 7.818, val: 1.505\n",
      "[ACC%] train: 89.74%, val: 95.65%\n",
      "EPOCH: 74\n",
      "[LOSS] train: 7.767, val: 1.508\n",
      "[ACC%] train: 90.54%, val: 95.65%\n",
      "EPOCH: 75\n",
      "[LOSS] train: 7.76, val: 1.506\n",
      "[ACC%] train: 90.71%, val: 95.65%\n",
      "EPOCH: 76\n",
      "[LOSS] train: 7.807, val: 1.521\n",
      "[ACC%] train: 89.9%, val: 94.2%\n",
      "EPOCH: 77\n",
      "[LOSS] train: 7.818, val: 1.497\n",
      "[ACC%] train: 89.9%, val: 97.1%\n",
      "EPOCH: 78\n",
      "[LOSS] train: 7.737, val: 1.505\n",
      "[ACC%] train: 91.51%, val: 95.65%\n",
      "EPOCH: 79\n",
      "[LOSS] train: 7.722, val: 1.502\n",
      "[ACC%] train: 91.51%, val: 95.65%\n",
      "EPOCH: 80\n",
      "[LOSS] train: 7.747, val: 1.504\n",
      "[ACC%] train: 91.19%, val: 95.65%\n",
      "EPOCH: 81\n",
      "[LOSS] train: 7.759, val: 1.5\n",
      "[ACC%] train: 91.03%, val: 95.65%\n",
      "EPOCH: 82\n",
      "[LOSS] train: 7.73, val: 1.561\n",
      "[ACC%] train: 91.51%, val: 89.86%\n",
      "EPOCH: 83\n",
      "[LOSS] train: 7.803, val: 1.533\n",
      "[ACC%] train: 90.06%, val: 92.75%\n",
      "EPOCH: 84\n",
      "[LOSS] train: 7.672, val: 1.504\n",
      "[ACC%] train: 92.95%, val: 95.65%\n",
      "EPOCH: 85\n",
      "[LOSS] train: 7.695, val: 1.513\n",
      "[ACC%] train: 92.47%, val: 95.65%\n",
      "EPOCH: 86\n",
      "[LOSS] train: 7.748, val: 1.534\n",
      "[ACC%] train: 91.19%, val: 94.2%\n",
      "EPOCH: 87\n",
      "[LOSS] train: 7.843, val: 1.505\n",
      "[ACC%] train: 89.1%, val: 95.65%\n",
      "EPOCH: 88\n",
      "[LOSS] train: 7.74, val: 1.519\n",
      "[ACC%] train: 91.35%, val: 94.2%\n",
      "EPOCH: 89\n",
      "[LOSS] train: 7.687, val: 1.523\n",
      "[ACC%] train: 91.99%, val: 94.2%\n",
      "EPOCH: 90\n",
      "[LOSS] train: 7.706, val: 1.556\n",
      "[ACC%] train: 91.99%, val: 89.86%\n",
      "EPOCH: 91\n",
      "[LOSS] train: 7.776, val: 1.533\n",
      "[ACC%] train: 90.54%, val: 92.75%\n",
      "EPOCH: 92\n",
      "[LOSS] train: 7.69, val: 1.544\n",
      "[ACC%] train: 92.31%, val: 91.3%\n",
      "EPOCH: 93\n",
      "[LOSS] train: 7.7, val: 1.642\n",
      "[ACC%] train: 92.47%, val: 84.06%\n",
      "EPOCH: 94\n",
      "[LOSS] train: 7.692, val: 1.741\n",
      "[ACC%] train: 92.31%, val: 71.01%\n",
      "EPOCH: 95\n",
      "[LOSS] train: 7.735, val: 1.626\n",
      "[ACC%] train: 91.51%, val: 82.61%\n",
      "EPOCH: 96\n",
      "[LOSS] train: 7.685, val: 1.565\n",
      "[ACC%] train: 92.63%, val: 88.41%\n",
      "EPOCH: 97\n",
      "[LOSS] train: 7.736, val: 1.522\n",
      "[ACC%] train: 90.71%, val: 94.2%\n",
      "EPOCH: 98\n",
      "[LOSS] train: 7.775, val: 1.52\n",
      "[ACC%] train: 90.54%, val: 94.2%\n",
      "EPOCH: 99\n",
      "[LOSS] train: 7.685, val: 1.525\n",
      "[ACC%] train: 92.47%, val: 94.2%\n",
      "EPOCH: 100\n",
      "[LOSS] train: 7.748, val: 1.548\n",
      "[ACC%] train: 91.19%, val: 91.3%\n",
      "EPOCH: 101\n",
      "[LOSS] train: 7.755, val: 1.553\n",
      "[ACC%] train: 91.03%, val: 91.3%\n",
      "EPOCH: 102\n",
      "[LOSS] train: 7.708, val: 1.563\n",
      "[ACC%] train: 91.99%, val: 89.86%\n",
      "EPOCH: 103\n",
      "[LOSS] train: 7.729, val: 1.547\n",
      "[ACC%] train: 91.67%, val: 91.3%\n",
      "EPOCH: 104\n",
      "[LOSS] train: 7.74, val: 1.522\n",
      "[ACC%] train: 91.35%, val: 94.2%\n",
      "EPOCH: 105\n",
      "[LOSS] train: 7.717, val: 1.531\n",
      "[ACC%] train: 91.67%, val: 92.75%\n",
      "EPOCH: 106\n",
      "[LOSS] train: 7.72, val: 1.55\n",
      "[ACC%] train: 91.51%, val: 91.3%\n",
      "EPOCH: 107\n",
      "[LOSS] train: 7.696, val: 1.592\n",
      "[ACC%] train: 91.99%, val: 85.51%\n",
      "EPOCH: 108\n",
      "[LOSS] train: 7.624, val: 1.585\n",
      "[ACC%] train: 93.91%, val: 88.41%\n",
      "EPOCH: 109\n",
      "[LOSS] train: 7.666, val: 1.618\n",
      "[ACC%] train: 92.63%, val: 82.61%\n",
      "EPOCH: 110\n",
      "[LOSS] train: 7.704, val: 1.737\n",
      "[ACC%] train: 91.99%, val: 71.01%\n",
      "EPOCH: 111\n",
      "[LOSS] train: 7.76, val: 1.662\n",
      "[ACC%] train: 91.03%, val: 79.71%\n",
      "EPOCH: 112\n",
      "[LOSS] train: 7.721, val: 1.562\n",
      "[ACC%] train: 91.67%, val: 89.86%\n",
      "EPOCH: 113\n",
      "[LOSS] train: 7.746, val: 1.525\n",
      "[ACC%] train: 90.71%, val: 94.2%\n",
      "EPOCH: 114\n",
      "[LOSS] train: 7.702, val: 1.521\n",
      "[ACC%] train: 91.99%, val: 94.2%\n",
      "EPOCH: 115\n",
      "[LOSS] train: 7.754, val: 1.545\n",
      "[ACC%] train: 90.71%, val: 91.3%\n",
      "EPOCH: 116\n",
      "[LOSS] train: 7.732, val: 1.535\n",
      "[ACC%] train: 91.35%, val: 92.75%\n",
      "EPOCH: 117\n",
      "[LOSS] train: 7.71, val: 1.557\n",
      "[ACC%] train: 91.67%, val: 91.3%\n",
      "EPOCH: 118\n",
      "[LOSS] train: 7.787, val: 1.549\n",
      "[ACC%] train: 90.06%, val: 89.86%\n",
      "EPOCH: 119\n",
      "[LOSS] train: 7.788, val: 1.551\n",
      "[ACC%] train: 90.87%, val: 91.3%\n",
      "EPOCH: 120\n",
      "[LOSS] train: 7.792, val: 1.556\n",
      "[ACC%] train: 89.74%, val: 91.3%\n",
      "EPOCH: 121\n",
      "[LOSS] train: 7.786, val: 1.555\n",
      "[ACC%] train: 90.54%, val: 91.3%\n",
      "EPOCH: 122\n",
      "[LOSS] train: 7.705, val: 1.551\n",
      "[ACC%] train: 92.15%, val: 89.86%\n",
      "EPOCH: 123\n",
      "[LOSS] train: 7.819, val: 1.526\n",
      "[ACC%] train: 89.42%, val: 92.75%\n",
      "EPOCH: 124\n",
      "[LOSS] train: 7.712, val: 1.521\n",
      "[ACC%] train: 91.83%, val: 94.2%\n",
      "EPOCH: 125\n",
      "[LOSS] train: 7.679, val: 1.561\n",
      "[ACC%] train: 92.63%, val: 88.41%\n",
      "EPOCH: 126\n",
      "[LOSS] train: 7.702, val: 1.628\n",
      "[ACC%] train: 92.15%, val: 82.61%\n",
      "EPOCH: 127\n",
      "[LOSS] train: 7.759, val: 1.712\n",
      "[ACC%] train: 90.71%, val: 73.91%\n",
      "EPOCH: 128\n",
      "[LOSS] train: 7.765, val: 1.69\n",
      "[ACC%] train: 90.54%, val: 76.81%\n",
      "EPOCH: 129\n",
      "[LOSS] train: 7.715, val: 1.556\n",
      "[ACC%] train: 91.51%, val: 89.86%\n",
      "EPOCH: 130\n",
      "[LOSS] train: 7.76, val: 1.554\n",
      "[ACC%] train: 90.71%, val: 91.3%\n",
      "EPOCH: 131\n",
      "[LOSS] train: 7.654, val: 1.845\n",
      "[ACC%] train: 92.79%, val: 59.42%\n",
      "EPOCH: 132\n",
      "[LOSS] train: 7.698, val: 1.878\n",
      "[ACC%] train: 92.15%, val: 56.52%\n",
      "EPOCH: 133\n",
      "[LOSS] train: 7.677, val: 1.723\n",
      "[ACC%] train: 92.47%, val: 72.46%\n",
      "EPOCH: 134\n",
      "[LOSS] train: 7.762, val: 1.613\n",
      "[ACC%] train: 91.03%, val: 84.06%\n",
      "EPOCH: 135\n",
      "[LOSS] train: 7.713, val: 1.57\n",
      "[ACC%] train: 92.15%, val: 88.41%\n",
      "EPOCH: 136\n",
      "[LOSS] train: 7.69, val: 1.552\n",
      "[ACC%] train: 92.63%, val: 91.3%\n",
      "EPOCH: 137\n",
      "[LOSS] train: 7.707, val: 1.546\n",
      "[ACC%] train: 91.99%, val: 91.3%\n",
      "EPOCH: 138\n",
      "[LOSS] train: 7.685, val: 1.544\n",
      "[ACC%] train: 92.79%, val: 91.3%\n",
      "EPOCH: 139\n",
      "[LOSS] train: 7.646, val: 1.523\n",
      "[ACC%] train: 93.27%, val: 92.75%\n",
      "EPOCH: 140\n",
      "[LOSS] train: 7.648, val: 1.536\n",
      "[ACC%] train: 92.79%, val: 92.75%\n",
      "EPOCH: 141\n",
      "[LOSS] train: 7.69, val: 1.551\n",
      "[ACC%] train: 92.15%, val: 91.3%\n",
      "EPOCH: 142\n",
      "[LOSS] train: 7.691, val: 1.624\n",
      "[ACC%] train: 92.47%, val: 82.61%\n",
      "EPOCH: 143\n",
      "[LOSS] train: 7.686, val: 1.576\n",
      "[ACC%] train: 92.31%, val: 86.96%\n",
      "EPOCH: 144\n",
      "[LOSS] train: 7.701, val: 1.542\n",
      "[ACC%] train: 91.99%, val: 91.3%\n",
      "EPOCH: 145\n",
      "[LOSS] train: 7.682, val: 1.563\n",
      "[ACC%] train: 92.31%, val: 88.41%\n",
      "EPOCH: 146\n",
      "[LOSS] train: 7.686, val: 1.785\n",
      "[ACC%] train: 92.63%, val: 68.12%\n",
      "EPOCH: 147\n",
      "[LOSS] train: 7.64, val: 1.799\n",
      "[ACC%] train: 93.43%, val: 65.22%\n",
      "EPOCH: 148\n",
      "[LOSS] train: 7.721, val: 1.701\n",
      "[ACC%] train: 91.83%, val: 76.81%\n",
      "EPOCH: 149\n",
      "[LOSS] train: 7.607, val: 1.72\n",
      "[ACC%] train: 94.07%, val: 73.91%\n",
      "EPOCH: 150\n",
      "[LOSS] train: 7.675, val: 1.597\n",
      "[ACC%] train: 92.79%, val: 88.41%\n",
      "EPOCH: 151\n",
      "[LOSS] train: 7.789, val: 1.506\n",
      "[ACC%] train: 90.22%, val: 95.65%\n",
      "EPOCH: 152\n",
      "[LOSS] train: 7.702, val: 1.54\n",
      "[ACC%] train: 92.47%, val: 94.2%\n",
      "EPOCH: 153\n",
      "[LOSS] train: 7.693, val: 1.559\n",
      "[ACC%] train: 91.83%, val: 89.86%\n",
      "EPOCH: 154\n",
      "[LOSS] train: 7.662, val: 1.545\n",
      "[ACC%] train: 92.95%, val: 91.3%\n",
      "EPOCH: 155\n",
      "[LOSS] train: 7.678, val: 1.546\n",
      "[ACC%] train: 92.47%, val: 91.3%\n",
      "EPOCH: 156\n",
      "[LOSS] train: 7.721, val: 1.54\n",
      "[ACC%] train: 91.83%, val: 91.3%\n",
      "EPOCH: 157\n",
      "[LOSS] train: 7.633, val: 1.561\n",
      "[ACC%] train: 93.27%, val: 86.96%\n",
      "EPOCH: 158\n",
      "[LOSS] train: 7.674, val: 1.645\n",
      "[ACC%] train: 92.47%, val: 81.16%\n",
      "EPOCH: 159\n",
      "[LOSS] train: 7.74, val: 1.706\n",
      "[ACC%] train: 91.67%, val: 72.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 160\n",
      "[LOSS] train: 7.76, val: 1.615\n",
      "[ACC%] train: 90.87%, val: 84.06%\n",
      "EPOCH: 161\n",
      "[LOSS] train: 7.666, val: 1.525\n",
      "[ACC%] train: 92.79%, val: 94.2%\n",
      "EPOCH: 162\n",
      "[LOSS] train: 7.672, val: 1.649\n",
      "[ACC%] train: 92.63%, val: 79.71%\n",
      "EPOCH: 163\n",
      "[LOSS] train: 7.791, val: 1.597\n",
      "[ACC%] train: 89.9%, val: 88.41%\n",
      "EPOCH: 164\n",
      "[LOSS] train: 7.745, val: 1.622\n",
      "[ACC%] train: 91.51%, val: 82.61%\n",
      "EPOCH: 165\n",
      "[LOSS] train: 7.725, val: 1.566\n",
      "[ACC%] train: 91.83%, val: 88.41%\n",
      "EPOCH: 166\n",
      "[LOSS] train: 7.756, val: 1.589\n",
      "[ACC%] train: 90.71%, val: 88.41%\n",
      "EPOCH: 167\n",
      "[LOSS] train: 7.698, val: 1.591\n",
      "[ACC%] train: 92.15%, val: 86.96%\n",
      "EPOCH: 168\n",
      "[LOSS] train: 7.676, val: 1.632\n",
      "[ACC%] train: 92.63%, val: 82.61%\n",
      "EPOCH: 169\n",
      "[LOSS] train: 7.665, val: 1.609\n",
      "[ACC%] train: 92.63%, val: 85.51%\n",
      "EPOCH: 170\n",
      "[LOSS] train: 7.66, val: 1.654\n",
      "[ACC%] train: 93.11%, val: 81.16%\n",
      "EPOCH: 171\n",
      "[LOSS] train: 7.693, val: 1.611\n",
      "[ACC%] train: 92.15%, val: 84.06%\n",
      "EPOCH: 172\n",
      "[LOSS] train: 7.719, val: 1.611\n",
      "[ACC%] train: 92.15%, val: 85.51%\n",
      "EPOCH: 173\n",
      "[LOSS] train: 7.721, val: 1.607\n",
      "[ACC%] train: 91.67%, val: 85.51%\n",
      "EPOCH: 174\n",
      "[LOSS] train: 7.776, val: 1.613\n",
      "[ACC%] train: 90.71%, val: 85.51%\n",
      "EPOCH: 175\n",
      "[LOSS] train: 7.608, val: 1.706\n",
      "[ACC%] train: 94.07%, val: 73.91%\n",
      "EPOCH: 176\n",
      "[LOSS] train: 7.671, val: 1.73\n",
      "[ACC%] train: 92.15%, val: 71.01%\n",
      "EPOCH: 177\n",
      "[LOSS] train: 7.75, val: 1.648\n",
      "[ACC%] train: 91.03%, val: 81.16%\n",
      "EPOCH: 178\n",
      "[LOSS] train: 7.764, val: 1.515\n",
      "[ACC%] train: 90.87%, val: 95.65%\n",
      "EPOCH: 179\n",
      "[LOSS] train: 7.721, val: 1.521\n",
      "[ACC%] train: 91.51%, val: 94.2%\n",
      "EPOCH: 180\n",
      "[LOSS] train: 7.673, val: 1.537\n",
      "[ACC%] train: 92.63%, val: 92.75%\n",
      "EPOCH: 181\n",
      "[LOSS] train: 7.717, val: 1.653\n",
      "[ACC%] train: 91.83%, val: 81.16%\n",
      "EPOCH: 182\n",
      "[LOSS] train: 7.698, val: 1.73\n",
      "[ACC%] train: 92.63%, val: 72.46%\n",
      "EPOCH: 183\n",
      "[LOSS] train: 7.697, val: 1.828\n",
      "[ACC%] train: 92.31%, val: 62.32%\n",
      "EPOCH: 184\n",
      "[LOSS] train: 7.758, val: 1.813\n",
      "[ACC%] train: 90.71%, val: 63.77%\n",
      "EPOCH: 185\n",
      "[LOSS] train: 7.756, val: 1.726\n",
      "[ACC%] train: 90.87%, val: 72.46%\n",
      "EPOCH: 186\n",
      "[LOSS] train: 7.703, val: 1.658\n",
      "[ACC%] train: 92.15%, val: 78.26%\n",
      "EPOCH: 187\n",
      "[LOSS] train: 7.72, val: 1.686\n",
      "[ACC%] train: 92.15%, val: 75.36%\n",
      "EPOCH: 188\n",
      "[LOSS] train: 7.687, val: 1.647\n",
      "[ACC%] train: 92.31%, val: 81.16%\n",
      "EPOCH: 189\n",
      "[LOSS] train: 7.749, val: 1.665\n",
      "[ACC%] train: 91.19%, val: 79.71%\n",
      "EPOCH: 190\n",
      "[LOSS] train: 7.721, val: 1.656\n",
      "[ACC%] train: 91.51%, val: 79.71%\n",
      "EPOCH: 191\n",
      "[LOSS] train: 7.655, val: 1.64\n",
      "[ACC%] train: 93.11%, val: 81.16%\n",
      "EPOCH: 192\n",
      "[LOSS] train: 7.69, val: 1.611\n",
      "[ACC%] train: 92.47%, val: 84.06%\n",
      "EPOCH: 193\n",
      "[LOSS] train: 7.601, val: 1.573\n",
      "[ACC%] train: 94.07%, val: 88.41%\n",
      "EPOCH: 194\n",
      "[LOSS] train: 7.719, val: 1.591\n",
      "[ACC%] train: 91.51%, val: 86.96%\n",
      "EPOCH: 195\n",
      "[LOSS] train: 7.721, val: 1.624\n",
      "[ACC%] train: 91.51%, val: 84.06%\n",
      "EPOCH: 196\n",
      "[LOSS] train: 7.719, val: 1.615\n",
      "[ACC%] train: 91.51%, val: 84.06%\n",
      "EPOCH: 197\n",
      "[LOSS] train: 7.712, val: 1.648\n",
      "[ACC%] train: 91.99%, val: 79.71%\n",
      "EPOCH: 198\n",
      "[LOSS] train: 7.717, val: 1.619\n",
      "[ACC%] train: 91.51%, val: 84.06%\n",
      "EPOCH: 199\n",
      "[LOSS] train: 7.702, val: 1.597\n",
      "[ACC%] train: 91.83%, val: 85.51%\n",
      "\n",
      "\n",
      "Working on 4th Fold\n",
      "EPOCH: 0\n",
      "[LOSS] train: 7.977, val: 1.461\n",
      "[ACC%] train: 86.06%, val: 100.0%\n",
      "EPOCH: 1\n",
      "[LOSS] train: 7.855, val: 1.485\n",
      "[ACC%] train: 88.78%, val: 97.1%\n",
      "EPOCH: 2\n",
      "[LOSS] train: 7.991, val: 1.488\n",
      "[ACC%] train: 86.38%, val: 97.1%\n",
      "EPOCH: 3\n",
      "[LOSS] train: 7.86, val: 1.49\n",
      "[ACC%] train: 88.62%, val: 97.1%\n",
      "EPOCH: 4\n",
      "[LOSS] train: 7.888, val: 1.575\n",
      "[ACC%] train: 88.3%, val: 88.41%\n",
      "EPOCH: 5\n",
      "[LOSS] train: 7.836, val: 1.471\n",
      "[ACC%] train: 89.42%, val: 98.55%\n",
      "EPOCH: 6\n",
      "[LOSS] train: 7.69, val: 1.465\n",
      "[ACC%] train: 92.63%, val: 100.0%\n",
      "EPOCH: 7\n",
      "[LOSS] train: 7.775, val: 1.462\n",
      "[ACC%] train: 90.87%, val: 100.0%\n",
      "EPOCH: 8\n",
      "[LOSS] train: 7.757, val: 1.534\n",
      "[ACC%] train: 91.19%, val: 92.75%\n",
      "EPOCH: 9\n",
      "[LOSS] train: 7.784, val: 1.742\n",
      "[ACC%] train: 90.54%, val: 72.46%\n",
      "EPOCH: 10\n",
      "[LOSS] train: 7.838, val: 1.596\n",
      "[ACC%] train: 89.42%, val: 85.51%\n",
      "EPOCH: 11\n",
      "[LOSS] train: 7.868, val: 1.461\n",
      "[ACC%] train: 88.62%, val: 100.0%\n",
      "EPOCH: 12\n",
      "[LOSS] train: 7.776, val: 1.461\n",
      "[ACC%] train: 90.54%, val: 100.0%\n",
      "EPOCH: 13\n",
      "[LOSS] train: 7.721, val: 1.468\n",
      "[ACC%] train: 91.99%, val: 100.0%\n",
      "EPOCH: 14\n",
      "[LOSS] train: 7.774, val: 1.471\n",
      "[ACC%] train: 90.71%, val: 98.55%\n",
      "EPOCH: 15\n",
      "[LOSS] train: 7.825, val: 1.465\n",
      "[ACC%] train: 89.58%, val: 100.0%\n",
      "EPOCH: 16\n",
      "[LOSS] train: 7.773, val: 1.472\n",
      "[ACC%] train: 90.38%, val: 98.55%\n",
      "EPOCH: 17\n",
      "[LOSS] train: 7.688, val: 1.474\n",
      "[ACC%] train: 92.47%, val: 98.55%\n",
      "EPOCH: 18\n",
      "[LOSS] train: 7.765, val: 1.508\n",
      "[ACC%] train: 90.71%, val: 95.65%\n",
      "EPOCH: 19\n",
      "[LOSS] train: 7.749, val: 1.582\n",
      "[ACC%] train: 91.35%, val: 88.41%\n",
      "EPOCH: 20\n",
      "[LOSS] train: 7.87, val: 1.798\n",
      "[ACC%] train: 88.46%, val: 59.42%\n",
      "EPOCH: 21\n",
      "[LOSS] train: 7.798, val: 1.819\n",
      "[ACC%] train: 90.06%, val: 63.77%\n",
      "EPOCH: 22\n",
      "[LOSS] train: 7.871, val: 1.462\n",
      "[ACC%] train: 88.62%, val: 100.0%\n",
      "EPOCH: 23\n",
      "[LOSS] train: 7.941, val: 1.469\n",
      "[ACC%] train: 87.98%, val: 98.55%\n",
      "EPOCH: 24\n",
      "[LOSS] train: 7.791, val: 1.548\n",
      "[ACC%] train: 90.22%, val: 89.86%\n",
      "EPOCH: 25\n",
      "[LOSS] train: 7.777, val: 1.492\n",
      "[ACC%] train: 89.74%, val: 97.1%\n",
      "EPOCH: 26\n",
      "[LOSS] train: 7.876, val: 1.464\n",
      "[ACC%] train: 87.82%, val: 100.0%\n",
      "EPOCH: 27\n",
      "[LOSS] train: 7.745, val: 1.472\n",
      "[ACC%] train: 91.67%, val: 98.55%\n",
      "EPOCH: 28\n",
      "[LOSS] train: 7.757, val: 1.473\n",
      "[ACC%] train: 91.03%, val: 98.55%\n",
      "EPOCH: 29\n",
      "[LOSS] train: 7.748, val: 1.461\n",
      "[ACC%] train: 91.35%, val: 100.0%\n",
      "EPOCH: 30\n",
      "[LOSS] train: 7.707, val: 1.499\n",
      "[ACC%] train: 91.99%, val: 95.65%\n",
      "EPOCH: 31\n",
      "[LOSS] train: 7.684, val: 1.58\n",
      "[ACC%] train: 92.47%, val: 86.96%\n",
      "EPOCH: 32\n",
      "[LOSS] train: 7.751, val: 1.558\n",
      "[ACC%] train: 90.87%, val: 89.86%\n",
      "EPOCH: 33\n",
      "[LOSS] train: 7.779, val: 1.525\n",
      "[ACC%] train: 90.38%, val: 94.2%\n",
      "EPOCH: 34\n",
      "[LOSS] train: 7.788, val: 1.488\n",
      "[ACC%] train: 89.74%, val: 97.1%\n",
      "EPOCH: 35\n",
      "[LOSS] train: 7.871, val: 1.497\n",
      "[ACC%] train: 88.78%, val: 95.65%\n",
      "EPOCH: 36\n",
      "[LOSS] train: 7.708, val: 1.557\n",
      "[ACC%] train: 91.99%, val: 89.86%\n",
      "EPOCH: 37\n",
      "[LOSS] train: 7.766, val: 1.625\n",
      "[ACC%] train: 90.87%, val: 82.61%\n",
      "EPOCH: 38\n",
      "[LOSS] train: 7.762, val: 1.607\n",
      "[ACC%] train: 90.54%, val: 84.06%\n",
      "EPOCH: 39\n",
      "[LOSS] train: 7.74, val: 1.793\n",
      "[ACC%] train: 91.35%, val: 65.22%\n",
      "EPOCH: 40\n",
      "[LOSS] train: 7.807, val: 1.909\n",
      "[ACC%] train: 90.06%, val: 52.17%\n",
      "EPOCH: 41\n",
      "[LOSS] train: 7.676, val: 1.683\n",
      "[ACC%] train: 92.79%, val: 75.36%\n",
      "EPOCH: 42\n",
      "[LOSS] train: 7.755, val: 1.665\n",
      "[ACC%] train: 91.03%, val: 76.81%\n",
      "EPOCH: 43\n",
      "[LOSS] train: 7.674, val: 1.6\n",
      "[ACC%] train: 92.63%, val: 85.51%\n",
      "EPOCH: 44\n",
      "[LOSS] train: 7.688, val: 1.47\n",
      "[ACC%] train: 92.31%, val: 100.0%\n",
      "EPOCH: 45\n",
      "[LOSS] train: 7.732, val: 1.486\n",
      "[ACC%] train: 91.51%, val: 97.1%\n",
      "EPOCH: 46\n",
      "[LOSS] train: 7.705, val: 1.513\n",
      "[ACC%] train: 91.67%, val: 94.2%\n",
      "EPOCH: 47\n",
      "[LOSS] train: 7.694, val: 1.504\n",
      "[ACC%] train: 91.99%, val: 95.65%\n",
      "EPOCH: 48\n",
      "[LOSS] train: 7.752, val: 1.481\n",
      "[ACC%] train: 90.71%, val: 98.55%\n",
      "EPOCH: 49\n",
      "[LOSS] train: 7.736, val: 1.484\n",
      "[ACC%] train: 91.19%, val: 98.55%\n",
      "EPOCH: 50\n",
      "[LOSS] train: 7.66, val: 1.783\n",
      "[ACC%] train: 92.95%, val: 66.67%\n",
      "EPOCH: 51\n",
      "[LOSS] train: 7.669, val: 2.012\n",
      "[ACC%] train: 92.95%, val: 43.48%\n",
      "EPOCH: 52\n",
      "[LOSS] train: 7.7, val: 1.76\n",
      "[ACC%] train: 92.15%, val: 69.57%\n",
      "EPOCH: 53\n",
      "[LOSS] train: 7.678, val: 1.461\n",
      "[ACC%] train: 92.47%, val: 100.0%\n",
      "EPOCH: 54\n",
      "[LOSS] train: 7.664, val: 1.461\n",
      "[ACC%] train: 92.95%, val: 100.0%\n",
      "EPOCH: 55\n",
      "[LOSS] train: 7.678, val: 1.461\n",
      "[ACC%] train: 92.31%, val: 100.0%\n",
      "EPOCH: 56\n",
      "[LOSS] train: 7.704, val: 1.461\n",
      "[ACC%] train: 92.15%, val: 100.0%\n",
      "EPOCH: 57\n",
      "[LOSS] train: 7.678, val: 1.462\n",
      "[ACC%] train: 92.47%, val: 100.0%\n",
      "EPOCH: 58\n",
      "[LOSS] train: 7.655, val: 1.462\n",
      "[ACC%] train: 93.11%, val: 100.0%\n",
      "EPOCH: 59\n",
      "[LOSS] train: 7.724, val: 1.496\n",
      "[ACC%] train: 91.83%, val: 94.2%\n",
      "EPOCH: 60\n",
      "[LOSS] train: 7.755, val: 1.69\n",
      "[ACC%] train: 90.71%, val: 73.91%\n",
      "EPOCH: 61\n",
      "[LOSS] train: 7.781, val: 1.807\n",
      "[ACC%] train: 90.38%, val: 62.32%\n",
      "EPOCH: 62\n",
      "[LOSS] train: 7.719, val: 1.831\n",
      "[ACC%] train: 91.51%, val: 60.87%\n",
      "EPOCH: 63\n",
      "[LOSS] train: 7.722, val: 1.476\n",
      "[ACC%] train: 91.67%, val: 98.55%\n",
      "EPOCH: 64\n",
      "[LOSS] train: 7.662, val: 1.461\n",
      "[ACC%] train: 93.11%, val: 100.0%\n",
      "EPOCH: 65\n",
      "[LOSS] train: 7.727, val: 1.461\n",
      "[ACC%] train: 91.51%, val: 100.0%\n",
      "EPOCH: 66\n",
      "[LOSS] train: 7.645, val: 1.461\n",
      "[ACC%] train: 93.11%, val: 100.0%\n",
      "EPOCH: 67\n",
      "[LOSS] train: 7.665, val: 1.468\n",
      "[ACC%] train: 92.95%, val: 98.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 68\n",
      "[LOSS] train: 7.669, val: 1.473\n",
      "[ACC%] train: 92.79%, val: 98.55%\n",
      "EPOCH: 69\n",
      "[LOSS] train: 7.741, val: 1.461\n",
      "[ACC%] train: 91.51%, val: 100.0%\n",
      "EPOCH: 70\n",
      "[LOSS] train: 7.664, val: 1.474\n",
      "[ACC%] train: 92.79%, val: 98.55%\n",
      "EPOCH: 71\n",
      "[LOSS] train: 7.691, val: 1.736\n",
      "[ACC%] train: 92.15%, val: 71.01%\n",
      "EPOCH: 72\n",
      "[LOSS] train: 7.713, val: 1.591\n",
      "[ACC%] train: 91.83%, val: 86.96%\n",
      "EPOCH: 73\n",
      "[LOSS] train: 7.658, val: 1.461\n",
      "[ACC%] train: 92.95%, val: 100.0%\n",
      "EPOCH: 74\n",
      "[LOSS] train: 7.678, val: 1.472\n",
      "[ACC%] train: 92.79%, val: 98.55%\n",
      "EPOCH: 75\n",
      "[LOSS] train: 7.659, val: 1.476\n",
      "[ACC%] train: 93.11%, val: 98.55%\n",
      "EPOCH: 76\n",
      "[LOSS] train: 7.7, val: 1.465\n",
      "[ACC%] train: 91.67%, val: 100.0%\n",
      "EPOCH: 77\n",
      "[LOSS] train: 7.711, val: 1.462\n",
      "[ACC%] train: 91.51%, val: 100.0%\n",
      "EPOCH: 78\n",
      "[LOSS] train: 7.718, val: 1.478\n",
      "[ACC%] train: 91.51%, val: 98.55%\n",
      "EPOCH: 79\n",
      "[LOSS] train: 7.675, val: 1.48\n",
      "[ACC%] train: 92.79%, val: 98.55%\n",
      "EPOCH: 80\n",
      "[LOSS] train: 7.675, val: 1.47\n",
      "[ACC%] train: 92.79%, val: 98.55%\n",
      "EPOCH: 81\n",
      "[LOSS] train: 7.697, val: 1.461\n",
      "[ACC%] train: 91.99%, val: 100.0%\n",
      "EPOCH: 82\n",
      "[LOSS] train: 7.703, val: 1.461\n",
      "[ACC%] train: 91.99%, val: 100.0%\n",
      "EPOCH: 83\n",
      "[LOSS] train: 7.617, val: 1.461\n",
      "[ACC%] train: 93.75%, val: 100.0%\n",
      "EPOCH: 84\n",
      "[LOSS] train: 7.692, val: 1.474\n",
      "[ACC%] train: 92.31%, val: 98.55%\n",
      "EPOCH: 85\n",
      "[LOSS] train: 7.717, val: 1.492\n",
      "[ACC%] train: 91.83%, val: 95.65%\n",
      "EPOCH: 86\n",
      "[LOSS] train: 7.713, val: 1.461\n",
      "[ACC%] train: 91.99%, val: 100.0%\n",
      "EPOCH: 87\n",
      "[LOSS] train: 7.688, val: 1.461\n",
      "[ACC%] train: 91.99%, val: 100.0%\n",
      "EPOCH: 88\n",
      "[LOSS] train: 7.671, val: 1.502\n",
      "[ACC%] train: 92.47%, val: 94.2%\n",
      "EPOCH: 89\n",
      "[LOSS] train: 7.752, val: 1.482\n",
      "[ACC%] train: 91.35%, val: 98.55%\n",
      "EPOCH: 90\n",
      "[LOSS] train: 7.705, val: 1.488\n",
      "[ACC%] train: 91.99%, val: 97.1%\n",
      "EPOCH: 91\n",
      "[LOSS] train: 7.662, val: 1.476\n",
      "[ACC%] train: 92.79%, val: 98.55%\n",
      "EPOCH: 92\n",
      "[LOSS] train: 7.625, val: 1.477\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 93\n",
      "[LOSS] train: 7.66, val: 1.462\n",
      "[ACC%] train: 93.11%, val: 100.0%\n",
      "EPOCH: 94\n",
      "[LOSS] train: 7.639, val: 1.461\n",
      "[ACC%] train: 93.27%, val: 100.0%\n",
      "EPOCH: 95\n",
      "[LOSS] train: 7.673, val: 1.461\n",
      "[ACC%] train: 92.47%, val: 100.0%\n",
      "EPOCH: 96\n",
      "[LOSS] train: 7.717, val: 1.461\n",
      "[ACC%] train: 91.67%, val: 100.0%\n",
      "EPOCH: 97\n",
      "[LOSS] train: 7.711, val: 1.476\n",
      "[ACC%] train: 91.51%, val: 98.55%\n",
      "EPOCH: 98\n",
      "[LOSS] train: 7.656, val: 1.487\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 99\n",
      "[LOSS] train: 7.675, val: 1.462\n",
      "[ACC%] train: 92.47%, val: 100.0%\n",
      "EPOCH: 100\n",
      "[LOSS] train: 7.596, val: 1.461\n",
      "[ACC%] train: 93.91%, val: 100.0%\n",
      "EPOCH: 101\n",
      "[LOSS] train: 7.717, val: 1.461\n",
      "[ACC%] train: 92.31%, val: 100.0%\n",
      "EPOCH: 102\n",
      "[LOSS] train: 7.642, val: 1.461\n",
      "[ACC%] train: 93.27%, val: 100.0%\n",
      "EPOCH: 103\n",
      "[LOSS] train: 7.693, val: 1.462\n",
      "[ACC%] train: 92.15%, val: 100.0%\n",
      "EPOCH: 104\n",
      "[LOSS] train: 7.652, val: 1.472\n",
      "[ACC%] train: 92.79%, val: 98.55%\n",
      "EPOCH: 105\n",
      "[LOSS] train: 7.626, val: 1.462\n",
      "[ACC%] train: 93.59%, val: 100.0%\n",
      "EPOCH: 106\n",
      "[LOSS] train: 7.657, val: 1.462\n",
      "[ACC%] train: 92.95%, val: 100.0%\n",
      "EPOCH: 107\n",
      "[LOSS] train: 7.607, val: 1.477\n",
      "[ACC%] train: 94.39%, val: 98.55%\n",
      "EPOCH: 108\n",
      "[LOSS] train: 7.636, val: 1.467\n",
      "[ACC%] train: 93.27%, val: 100.0%\n",
      "EPOCH: 109\n",
      "[LOSS] train: 7.632, val: 1.461\n",
      "[ACC%] train: 93.27%, val: 100.0%\n",
      "EPOCH: 110\n",
      "[LOSS] train: 7.626, val: 1.462\n",
      "[ACC%] train: 93.43%, val: 100.0%\n",
      "EPOCH: 111\n",
      "[LOSS] train: 7.698, val: 1.474\n",
      "[ACC%] train: 91.99%, val: 98.55%\n",
      "EPOCH: 112\n",
      "[LOSS] train: 7.67, val: 1.48\n",
      "[ACC%] train: 92.31%, val: 98.55%\n",
      "EPOCH: 113\n",
      "[LOSS] train: 7.601, val: 1.463\n",
      "[ACC%] train: 93.91%, val: 100.0%\n",
      "EPOCH: 114\n",
      "[LOSS] train: 7.633, val: 1.475\n",
      "[ACC%] train: 93.59%, val: 98.55%\n",
      "EPOCH: 115\n",
      "[LOSS] train: 7.709, val: 1.669\n",
      "[ACC%] train: 91.35%, val: 76.81%\n",
      "EPOCH: 116\n",
      "[LOSS] train: 7.665, val: 1.631\n",
      "[ACC%] train: 92.79%, val: 82.61%\n",
      "EPOCH: 117\n",
      "[LOSS] train: 7.667, val: 1.493\n",
      "[ACC%] train: 92.47%, val: 97.1%\n",
      "EPOCH: 118\n",
      "[LOSS] train: 7.703, val: 1.887\n",
      "[ACC%] train: 91.99%, val: 55.07%\n",
      "EPOCH: 119\n",
      "[LOSS] train: 7.637, val: 2.161\n",
      "[ACC%] train: 93.43%, val: 28.99%\n",
      "EPOCH: 120\n",
      "[LOSS] train: 7.715, val: 2.163\n",
      "[ACC%] train: 92.15%, val: 28.99%\n",
      "EPOCH: 121\n",
      "[LOSS] train: 7.734, val: 1.466\n",
      "[ACC%] train: 91.35%, val: 100.0%\n",
      "EPOCH: 122\n",
      "[LOSS] train: 7.695, val: 1.486\n",
      "[ACC%] train: 91.99%, val: 97.1%\n",
      "EPOCH: 123\n",
      "[LOSS] train: 7.648, val: 1.461\n",
      "[ACC%] train: 92.95%, val: 100.0%\n",
      "EPOCH: 124\n",
      "[LOSS] train: 7.604, val: 1.461\n",
      "[ACC%] train: 94.23%, val: 100.0%\n",
      "EPOCH: 125\n",
      "[LOSS] train: 7.639, val: 1.467\n",
      "[ACC%] train: 93.43%, val: 100.0%\n",
      "EPOCH: 126\n",
      "[LOSS] train: 7.66, val: 1.514\n",
      "[ACC%] train: 92.95%, val: 94.2%\n",
      "EPOCH: 127\n",
      "[LOSS] train: 7.611, val: 1.536\n",
      "[ACC%] train: 94.07%, val: 92.75%\n",
      "EPOCH: 128\n",
      "[LOSS] train: 7.66, val: 1.628\n",
      "[ACC%] train: 92.79%, val: 82.61%\n",
      "EPOCH: 129\n",
      "[LOSS] train: 7.728, val: 1.669\n",
      "[ACC%] train: 91.19%, val: 78.26%\n",
      "EPOCH: 130\n",
      "[LOSS] train: 7.694, val: 1.644\n",
      "[ACC%] train: 92.31%, val: 79.71%\n",
      "EPOCH: 131\n",
      "[LOSS] train: 7.714, val: 1.504\n",
      "[ACC%] train: 91.67%, val: 95.65%\n",
      "EPOCH: 132\n",
      "[LOSS] train: 7.727, val: 1.479\n",
      "[ACC%] train: 91.51%, val: 98.55%\n",
      "EPOCH: 133\n",
      "[LOSS] train: 7.64, val: 1.478\n",
      "[ACC%] train: 93.27%, val: 98.55%\n",
      "EPOCH: 134\n",
      "[LOSS] train: 7.576, val: 1.538\n",
      "[ACC%] train: 94.87%, val: 91.3%\n",
      "EPOCH: 135\n",
      "[LOSS] train: 7.675, val: 1.774\n",
      "[ACC%] train: 92.63%, val: 65.22%\n",
      "EPOCH: 136\n",
      "[LOSS] train: 7.66, val: 2.149\n",
      "[ACC%] train: 92.95%, val: 30.43%\n",
      "EPOCH: 137\n",
      "[LOSS] train: 7.64, val: 2.191\n",
      "[ACC%] train: 93.11%, val: 26.09%\n",
      "EPOCH: 138\n",
      "[LOSS] train: 7.734, val: 2.161\n",
      "[ACC%] train: 91.35%, val: 28.99%\n",
      "EPOCH: 139\n",
      "[LOSS] train: 7.674, val: 2.074\n",
      "[ACC%] train: 92.47%, val: 36.23%\n",
      "EPOCH: 140\n",
      "[LOSS] train: 7.695, val: 1.738\n",
      "[ACC%] train: 91.99%, val: 69.57%\n",
      "EPOCH: 141\n",
      "[LOSS] train: 7.591, val: 1.638\n",
      "[ACC%] train: 93.91%, val: 78.26%\n",
      "EPOCH: 142\n",
      "[LOSS] train: 7.659, val: 1.564\n",
      "[ACC%] train: 92.79%, val: 88.41%\n",
      "EPOCH: 143\n",
      "[LOSS] train: 7.632, val: 1.529\n",
      "[ACC%] train: 93.43%, val: 91.3%\n",
      "EPOCH: 144\n",
      "[LOSS] train: 7.607, val: 1.486\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 145\n",
      "[LOSS] train: 7.62, val: 1.516\n",
      "[ACC%] train: 93.43%, val: 95.65%\n",
      "EPOCH: 146\n",
      "[LOSS] train: 7.64, val: 1.529\n",
      "[ACC%] train: 93.11%, val: 91.3%\n",
      "EPOCH: 147\n",
      "[LOSS] train: 7.666, val: 1.793\n",
      "[ACC%] train: 92.95%, val: 65.22%\n",
      "EPOCH: 148\n",
      "[LOSS] train: 7.619, val: 1.782\n",
      "[ACC%] train: 93.91%, val: 66.67%\n",
      "EPOCH: 149\n",
      "[LOSS] train: 7.724, val: 1.728\n",
      "[ACC%] train: 91.35%, val: 71.01%\n",
      "EPOCH: 150\n",
      "[LOSS] train: 7.661, val: 1.534\n",
      "[ACC%] train: 92.63%, val: 91.3%\n",
      "EPOCH: 151\n",
      "[LOSS] train: 7.637, val: 1.462\n",
      "[ACC%] train: 93.27%, val: 100.0%\n",
      "EPOCH: 152\n",
      "[LOSS] train: 7.643, val: 1.517\n",
      "[ACC%] train: 93.11%, val: 94.2%\n",
      "EPOCH: 153\n",
      "[LOSS] train: 7.687, val: 1.629\n",
      "[ACC%] train: 92.15%, val: 81.16%\n",
      "EPOCH: 154\n",
      "[LOSS] train: 7.692, val: 1.642\n",
      "[ACC%] train: 92.63%, val: 79.71%\n",
      "EPOCH: 155\n",
      "[LOSS] train: 7.689, val: 1.643\n",
      "[ACC%] train: 92.47%, val: 78.26%\n",
      "EPOCH: 156\n",
      "[LOSS] train: 7.708, val: 1.686\n",
      "[ACC%] train: 91.99%, val: 75.36%\n",
      "EPOCH: 157\n",
      "[LOSS] train: 7.617, val: 1.833\n",
      "[ACC%] train: 93.75%, val: 59.42%\n",
      "EPOCH: 158\n",
      "[LOSS] train: 7.62, val: 1.839\n",
      "[ACC%] train: 93.27%, val: 59.42%\n",
      "EPOCH: 159\n",
      "[LOSS] train: 7.695, val: 1.891\n",
      "[ACC%] train: 92.15%, val: 53.62%\n",
      "EPOCH: 160\n",
      "[LOSS] train: 7.635, val: 1.86\n",
      "[ACC%] train: 93.27%, val: 57.97%\n",
      "EPOCH: 161\n",
      "[LOSS] train: 7.715, val: 1.558\n",
      "[ACC%] train: 91.99%, val: 89.86%\n",
      "EPOCH: 162\n",
      "[LOSS] train: 7.659, val: 1.489\n",
      "[ACC%] train: 92.95%, val: 97.1%\n",
      "EPOCH: 163\n",
      "[LOSS] train: 7.63, val: 1.548\n",
      "[ACC%] train: 93.27%, val: 89.86%\n",
      "EPOCH: 164\n",
      "[LOSS] train: 7.681, val: 1.576\n",
      "[ACC%] train: 92.47%, val: 86.96%\n",
      "EPOCH: 165\n",
      "[LOSS] train: 7.652, val: 1.49\n",
      "[ACC%] train: 92.63%, val: 98.55%\n",
      "EPOCH: 166\n",
      "[LOSS] train: 7.64, val: 1.48\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 167\n",
      "[LOSS] train: 7.67, val: 1.482\n",
      "[ACC%] train: 92.95%, val: 98.55%\n",
      "EPOCH: 168\n",
      "[LOSS] train: 7.688, val: 1.466\n",
      "[ACC%] train: 92.47%, val: 100.0%\n",
      "EPOCH: 169\n",
      "[LOSS] train: 7.599, val: 1.462\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 170\n",
      "[LOSS] train: 7.649, val: 1.462\n",
      "[ACC%] train: 93.27%, val: 100.0%\n",
      "EPOCH: 171\n",
      "[LOSS] train: 7.631, val: 1.461\n",
      "[ACC%] train: 93.59%, val: 100.0%\n",
      "EPOCH: 172\n",
      "[LOSS] train: 7.59, val: 1.467\n",
      "[ACC%] train: 94.23%, val: 100.0%\n",
      "EPOCH: 173\n",
      "[LOSS] train: 7.618, val: 1.484\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 174\n",
      "[LOSS] train: 7.607, val: 1.477\n",
      "[ACC%] train: 93.75%, val: 98.55%\n",
      "EPOCH: 175\n",
      "[LOSS] train: 7.642, val: 1.478\n",
      "[ACC%] train: 93.27%, val: 98.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 176\n",
      "[LOSS] train: 7.615, val: 1.474\n",
      "[ACC%] train: 94.07%, val: 98.55%\n",
      "EPOCH: 177\n",
      "[LOSS] train: 7.622, val: 1.633\n",
      "[ACC%] train: 93.75%, val: 79.71%\n",
      "EPOCH: 178\n",
      "[LOSS] train: 7.681, val: 1.83\n",
      "[ACC%] train: 92.79%, val: 60.87%\n",
      "EPOCH: 179\n",
      "[LOSS] train: 7.682, val: 1.612\n",
      "[ACC%] train: 92.79%, val: 84.06%\n",
      "EPOCH: 180\n",
      "[LOSS] train: 7.665, val: 1.807\n",
      "[ACC%] train: 92.63%, val: 62.32%\n",
      "EPOCH: 181\n",
      "[LOSS] train: 7.678, val: 1.887\n",
      "[ACC%] train: 92.47%, val: 53.62%\n",
      "EPOCH: 182\n",
      "[LOSS] train: 7.694, val: 1.866\n",
      "[ACC%] train: 91.99%, val: 56.52%\n",
      "EPOCH: 183\n",
      "[LOSS] train: 7.688, val: 1.95\n",
      "[ACC%] train: 91.99%, val: 47.83%\n",
      "EPOCH: 184\n",
      "[LOSS] train: 7.666, val: 2.011\n",
      "[ACC%] train: 92.47%, val: 43.48%\n",
      "EPOCH: 185\n",
      "[LOSS] train: 7.675, val: 1.744\n",
      "[ACC%] train: 92.63%, val: 68.12%\n",
      "EPOCH: 186\n",
      "[LOSS] train: 7.674, val: 1.944\n",
      "[ACC%] train: 92.31%, val: 49.28%\n",
      "EPOCH: 187\n",
      "[LOSS] train: 7.689, val: 2.133\n",
      "[ACC%] train: 91.99%, val: 31.88%\n",
      "EPOCH: 188\n",
      "[LOSS] train: 7.647, val: 2.073\n",
      "[ACC%] train: 93.11%, val: 37.68%\n",
      "EPOCH: 189\n",
      "[LOSS] train: 7.667, val: 1.711\n",
      "[ACC%] train: 92.95%, val: 71.01%\n",
      "EPOCH: 190\n",
      "[LOSS] train: 7.653, val: 1.495\n",
      "[ACC%] train: 93.27%, val: 95.65%\n",
      "EPOCH: 191\n",
      "[LOSS] train: 7.655, val: 1.462\n",
      "[ACC%] train: 92.95%, val: 100.0%\n",
      "EPOCH: 192\n",
      "[LOSS] train: 7.61, val: 1.466\n",
      "[ACC%] train: 93.75%, val: 100.0%\n",
      "EPOCH: 193\n",
      "[LOSS] train: 7.695, val: 1.511\n",
      "[ACC%] train: 92.15%, val: 95.65%\n",
      "EPOCH: 194\n",
      "[LOSS] train: 7.614, val: 1.522\n",
      "[ACC%] train: 94.23%, val: 94.2%\n",
      "EPOCH: 195\n",
      "[LOSS] train: 7.57, val: 1.98\n",
      "[ACC%] train: 94.71%, val: 46.38%\n",
      "EPOCH: 196\n",
      "[LOSS] train: 7.661, val: 1.992\n",
      "[ACC%] train: 92.79%, val: 44.93%\n",
      "EPOCH: 197\n",
      "[LOSS] train: 7.656, val: 1.57\n",
      "[ACC%] train: 93.11%, val: 89.86%\n",
      "EPOCH: 198\n",
      "[LOSS] train: 7.628, val: 1.69\n",
      "[ACC%] train: 93.27%, val: 73.91%\n",
      "EPOCH: 199\n",
      "[LOSS] train: 7.695, val: 2.003\n",
      "[ACC%] train: 92.47%, val: 44.93%\n",
      "\n",
      "\n",
      "Working on 5th Fold\n",
      "EPOCH: 0\n",
      "[LOSS] train: 7.676, val: 1.695\n",
      "[ACC%] train: 92.79%, val: 73.91%\n",
      "EPOCH: 1\n",
      "[LOSS] train: 7.742, val: 1.473\n",
      "[ACC%] train: 90.87%, val: 98.55%\n",
      "EPOCH: 2\n",
      "[LOSS] train: 7.744, val: 1.473\n",
      "[ACC%] train: 91.19%, val: 98.55%\n",
      "EPOCH: 3\n",
      "[LOSS] train: 7.784, val: 1.473\n",
      "[ACC%] train: 90.22%, val: 98.55%\n",
      "EPOCH: 4\n",
      "[LOSS] train: 7.773, val: 1.581\n",
      "[ACC%] train: 90.54%, val: 85.51%\n",
      "EPOCH: 5\n",
      "[LOSS] train: 7.722, val: 1.624\n",
      "[ACC%] train: 91.99%, val: 79.71%\n",
      "EPOCH: 6\n",
      "[LOSS] train: 7.686, val: 1.589\n",
      "[ACC%] train: 92.63%, val: 85.51%\n",
      "EPOCH: 7\n",
      "[LOSS] train: 7.799, val: 1.554\n",
      "[ACC%] train: 89.9%, val: 86.96%\n",
      "EPOCH: 8\n",
      "[LOSS] train: 7.715, val: 1.608\n",
      "[ACC%] train: 91.51%, val: 82.61%\n",
      "EPOCH: 9\n",
      "[LOSS] train: 7.848, val: 1.59\n",
      "[ACC%] train: 89.1%, val: 84.06%\n",
      "EPOCH: 10\n",
      "[LOSS] train: 7.801, val: 1.602\n",
      "[ACC%] train: 89.74%, val: 82.61%\n",
      "EPOCH: 11\n",
      "[LOSS] train: 7.797, val: 1.889\n",
      "[ACC%] train: 89.74%, val: 56.52%\n",
      "EPOCH: 12\n",
      "[LOSS] train: 7.737, val: 1.993\n",
      "[ACC%] train: 91.19%, val: 46.38%\n",
      "EPOCH: 13\n",
      "[LOSS] train: 7.756, val: 1.703\n",
      "[ACC%] train: 91.03%, val: 72.46%\n",
      "EPOCH: 14\n",
      "[LOSS] train: 7.713, val: 1.473\n",
      "[ACC%] train: 91.83%, val: 98.55%\n",
      "EPOCH: 15\n",
      "[LOSS] train: 7.742, val: 1.473\n",
      "[ACC%] train: 91.19%, val: 98.55%\n",
      "EPOCH: 16\n",
      "[LOSS] train: 7.692, val: 1.473\n",
      "[ACC%] train: 92.15%, val: 98.55%\n",
      "EPOCH: 17\n",
      "[LOSS] train: 7.67, val: 1.473\n",
      "[ACC%] train: 92.79%, val: 98.55%\n",
      "EPOCH: 18\n",
      "[LOSS] train: 7.721, val: 1.473\n",
      "[ACC%] train: 91.83%, val: 98.55%\n",
      "EPOCH: 19\n",
      "[LOSS] train: 7.729, val: 1.473\n",
      "[ACC%] train: 91.67%, val: 98.55%\n",
      "EPOCH: 20\n",
      "[LOSS] train: 7.703, val: 1.473\n",
      "[ACC%] train: 91.83%, val: 98.55%\n",
      "EPOCH: 21\n",
      "[LOSS] train: 7.662, val: 1.473\n",
      "[ACC%] train: 92.95%, val: 98.55%\n",
      "EPOCH: 22\n",
      "[LOSS] train: 7.69, val: 1.473\n",
      "[ACC%] train: 92.15%, val: 98.55%\n",
      "EPOCH: 23\n",
      "[LOSS] train: 7.651, val: 1.473\n",
      "[ACC%] train: 92.79%, val: 98.55%\n",
      "EPOCH: 24\n",
      "[LOSS] train: 7.701, val: 1.473\n",
      "[ACC%] train: 91.67%, val: 98.55%\n",
      "EPOCH: 25\n",
      "[LOSS] train: 7.609, val: 1.473\n",
      "[ACC%] train: 93.59%, val: 98.55%\n",
      "EPOCH: 26\n",
      "[LOSS] train: 7.671, val: 1.478\n",
      "[ACC%] train: 92.31%, val: 98.55%\n",
      "EPOCH: 27\n",
      "[LOSS] train: 7.695, val: 1.511\n",
      "[ACC%] train: 92.15%, val: 92.75%\n",
      "EPOCH: 28\n",
      "[LOSS] train: 7.646, val: 1.474\n",
      "[ACC%] train: 93.27%, val: 98.55%\n",
      "EPOCH: 29\n",
      "[LOSS] train: 7.716, val: 1.473\n",
      "[ACC%] train: 91.83%, val: 98.55%\n",
      "EPOCH: 30\n",
      "[LOSS] train: 7.725, val: 1.473\n",
      "[ACC%] train: 92.15%, val: 98.55%\n",
      "EPOCH: 31\n",
      "[LOSS] train: 7.689, val: 1.473\n",
      "[ACC%] train: 92.15%, val: 98.55%\n",
      "EPOCH: 32\n",
      "[LOSS] train: 7.681, val: 1.473\n",
      "[ACC%] train: 92.47%, val: 98.55%\n",
      "EPOCH: 33\n",
      "[LOSS] train: 7.643, val: 1.473\n",
      "[ACC%] train: 93.11%, val: 98.55%\n",
      "EPOCH: 34\n",
      "[LOSS] train: 7.678, val: 1.473\n",
      "[ACC%] train: 92.47%, val: 98.55%\n",
      "EPOCH: 35\n",
      "[LOSS] train: 7.617, val: 1.516\n",
      "[ACC%] train: 93.91%, val: 92.75%\n",
      "EPOCH: 36\n",
      "[LOSS] train: 7.683, val: 1.593\n",
      "[ACC%] train: 92.63%, val: 84.06%\n",
      "EPOCH: 37\n",
      "[LOSS] train: 7.643, val: 1.616\n",
      "[ACC%] train: 92.95%, val: 81.16%\n",
      "EPOCH: 38\n",
      "[LOSS] train: 7.678, val: 1.611\n",
      "[ACC%] train: 92.63%, val: 82.61%\n",
      "EPOCH: 39\n",
      "[LOSS] train: 7.722, val: 1.665\n",
      "[ACC%] train: 91.67%, val: 76.81%\n",
      "EPOCH: 40\n",
      "[LOSS] train: 7.66, val: 1.756\n",
      "[ACC%] train: 92.95%, val: 68.12%\n",
      "EPOCH: 41\n",
      "[LOSS] train: 7.655, val: 1.772\n",
      "[ACC%] train: 93.75%, val: 66.67%\n",
      "EPOCH: 42\n",
      "[LOSS] train: 7.721, val: 1.59\n",
      "[ACC%] train: 91.83%, val: 85.51%\n",
      "EPOCH: 43\n",
      "[LOSS] train: 7.67, val: 1.596\n",
      "[ACC%] train: 92.79%, val: 84.06%\n",
      "EPOCH: 44\n",
      "[LOSS] train: 7.751, val: 1.614\n",
      "[ACC%] train: 90.71%, val: 82.61%\n",
      "EPOCH: 45\n",
      "[LOSS] train: 7.738, val: 1.537\n",
      "[ACC%] train: 91.35%, val: 91.3%\n",
      "EPOCH: 46\n",
      "[LOSS] train: 7.682, val: 1.557\n",
      "[ACC%] train: 92.47%, val: 88.41%\n",
      "EPOCH: 47\n",
      "[LOSS] train: 7.674, val: 1.558\n",
      "[ACC%] train: 92.79%, val: 88.41%\n",
      "EPOCH: 48\n",
      "[LOSS] train: 7.697, val: 1.556\n",
      "[ACC%] train: 91.99%, val: 88.41%\n",
      "EPOCH: 49\n",
      "[LOSS] train: 7.609, val: 1.523\n",
      "[ACC%] train: 94.23%, val: 91.3%\n",
      "EPOCH: 50\n",
      "[LOSS] train: 7.604, val: 1.542\n",
      "[ACC%] train: 94.07%, val: 89.86%\n",
      "EPOCH: 51\n",
      "[LOSS] train: 7.681, val: 1.497\n",
      "[ACC%] train: 92.31%, val: 95.65%\n",
      "EPOCH: 52\n",
      "[LOSS] train: 7.671, val: 1.497\n",
      "[ACC%] train: 92.31%, val: 95.65%\n",
      "EPOCH: 53\n",
      "[LOSS] train: 7.708, val: 1.508\n",
      "[ACC%] train: 91.51%, val: 94.2%\n",
      "EPOCH: 54\n",
      "[LOSS] train: 7.626, val: 1.498\n",
      "[ACC%] train: 93.59%, val: 95.65%\n",
      "EPOCH: 55\n",
      "[LOSS] train: 7.633, val: 1.5\n",
      "[ACC%] train: 93.43%, val: 95.65%\n",
      "EPOCH: 56\n",
      "[LOSS] train: 7.63, val: 1.512\n",
      "[ACC%] train: 93.11%, val: 94.2%\n",
      "EPOCH: 57\n",
      "[LOSS] train: 7.69, val: 1.519\n",
      "[ACC%] train: 92.47%, val: 92.75%\n",
      "EPOCH: 58\n",
      "[LOSS] train: 7.66, val: 1.513\n",
      "[ACC%] train: 92.79%, val: 94.2%\n",
      "EPOCH: 59\n",
      "[LOSS] train: 7.632, val: 1.497\n",
      "[ACC%] train: 93.59%, val: 95.65%\n",
      "EPOCH: 60\n",
      "[LOSS] train: 7.633, val: 1.484\n",
      "[ACC%] train: 93.27%, val: 97.1%\n",
      "EPOCH: 61\n",
      "[LOSS] train: 7.673, val: 1.477\n",
      "[ACC%] train: 92.47%, val: 98.55%\n",
      "EPOCH: 62\n",
      "[LOSS] train: 7.661, val: 1.474\n",
      "[ACC%] train: 92.79%, val: 98.55%\n",
      "EPOCH: 63\n",
      "[LOSS] train: 7.62, val: 1.473\n",
      "[ACC%] train: 93.91%, val: 98.55%\n",
      "EPOCH: 64\n",
      "[LOSS] train: 7.6, val: 1.473\n",
      "[ACC%] train: 94.07%, val: 98.55%\n",
      "EPOCH: 65\n",
      "[LOSS] train: 7.647, val: 1.473\n",
      "[ACC%] train: 93.27%, val: 98.55%\n",
      "EPOCH: 66\n",
      "[LOSS] train: 7.638, val: 1.475\n",
      "[ACC%] train: 93.11%, val: 98.55%\n",
      "EPOCH: 67\n",
      "[LOSS] train: 7.701, val: 1.492\n",
      "[ACC%] train: 91.83%, val: 97.1%\n",
      "EPOCH: 68\n",
      "[LOSS] train: 7.691, val: 1.495\n",
      "[ACC%] train: 92.47%, val: 97.1%\n",
      "EPOCH: 69\n",
      "[LOSS] train: 7.666, val: 1.474\n",
      "[ACC%] train: 92.79%, val: 98.55%\n",
      "EPOCH: 70\n",
      "[LOSS] train: 7.611, val: 1.473\n",
      "[ACC%] train: 94.07%, val: 98.55%\n",
      "EPOCH: 71\n",
      "[LOSS] train: 7.67, val: 1.473\n",
      "[ACC%] train: 92.95%, val: 98.55%\n",
      "EPOCH: 72\n",
      "[LOSS] train: 7.62, val: 1.474\n",
      "[ACC%] train: 94.07%, val: 98.55%\n",
      "EPOCH: 73\n",
      "[LOSS] train: 7.574, val: 1.484\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 74\n",
      "[LOSS] train: 7.626, val: 1.489\n",
      "[ACC%] train: 93.43%, val: 97.1%\n",
      "EPOCH: 75\n",
      "[LOSS] train: 7.606, val: 1.502\n",
      "[ACC%] train: 93.91%, val: 95.65%\n",
      "EPOCH: 76\n",
      "[LOSS] train: 7.659, val: 1.499\n",
      "[ACC%] train: 92.47%, val: 95.65%\n",
      "EPOCH: 77\n",
      "[LOSS] train: 7.654, val: 1.488\n",
      "[ACC%] train: 92.63%, val: 97.1%\n",
      "EPOCH: 78\n",
      "[LOSS] train: 7.653, val: 1.492\n",
      "[ACC%] train: 93.11%, val: 95.65%\n",
      "EPOCH: 79\n",
      "[LOSS] train: 7.634, val: 1.521\n",
      "[ACC%] train: 93.59%, val: 92.75%\n",
      "EPOCH: 80\n",
      "[LOSS] train: 7.722, val: 1.509\n",
      "[ACC%] train: 91.51%, val: 94.2%\n",
      "EPOCH: 81\n",
      "[LOSS] train: 7.751, val: 1.5\n",
      "[ACC%] train: 90.71%, val: 95.65%\n",
      "EPOCH: 82\n",
      "[LOSS] train: 7.679, val: 1.507\n",
      "[ACC%] train: 92.47%, val: 94.2%\n",
      "EPOCH: 83\n",
      "[LOSS] train: 7.674, val: 1.507\n",
      "[ACC%] train: 92.79%, val: 94.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 84\n",
      "[LOSS] train: 7.691, val: 1.587\n",
      "[ACC%] train: 92.15%, val: 85.51%\n",
      "EPOCH: 85\n",
      "[LOSS] train: 7.649, val: 1.579\n",
      "[ACC%] train: 93.11%, val: 86.96%\n",
      "EPOCH: 86\n",
      "[LOSS] train: 7.673, val: 1.544\n",
      "[ACC%] train: 92.63%, val: 89.86%\n",
      "EPOCH: 87\n",
      "[LOSS] train: 7.675, val: 1.548\n",
      "[ACC%] train: 92.63%, val: 89.86%\n",
      "EPOCH: 88\n",
      "[LOSS] train: 7.627, val: 1.572\n",
      "[ACC%] train: 93.43%, val: 86.96%\n",
      "EPOCH: 89\n",
      "[LOSS] train: 7.606, val: 1.591\n",
      "[ACC%] train: 93.75%, val: 84.06%\n",
      "EPOCH: 90\n",
      "[LOSS] train: 7.662, val: 1.559\n",
      "[ACC%] train: 92.63%, val: 88.41%\n",
      "EPOCH: 91\n",
      "[LOSS] train: 7.581, val: 1.572\n",
      "[ACC%] train: 94.39%, val: 86.96%\n",
      "EPOCH: 92\n",
      "[LOSS] train: 7.62, val: 1.564\n",
      "[ACC%] train: 93.43%, val: 88.41%\n",
      "EPOCH: 93\n",
      "[LOSS] train: 7.575, val: 1.618\n",
      "[ACC%] train: 94.55%, val: 82.61%\n",
      "EPOCH: 94\n",
      "[LOSS] train: 7.729, val: 1.684\n",
      "[ACC%] train: 90.87%, val: 75.36%\n",
      "EPOCH: 95\n",
      "[LOSS] train: 7.65, val: 1.687\n",
      "[ACC%] train: 92.95%, val: 73.91%\n",
      "EPOCH: 96\n",
      "[LOSS] train: 7.658, val: 1.615\n",
      "[ACC%] train: 93.11%, val: 81.16%\n",
      "EPOCH: 97\n",
      "[LOSS] train: 7.621, val: 1.614\n",
      "[ACC%] train: 93.91%, val: 82.61%\n",
      "EPOCH: 98\n",
      "[LOSS] train: 7.623, val: 1.618\n",
      "[ACC%] train: 93.91%, val: 82.61%\n",
      "EPOCH: 99\n",
      "[LOSS] train: 7.665, val: 1.63\n",
      "[ACC%] train: 92.47%, val: 79.71%\n",
      "EPOCH: 100\n",
      "[LOSS] train: 7.623, val: 1.671\n",
      "[ACC%] train: 93.75%, val: 75.36%\n",
      "EPOCH: 101\n",
      "[LOSS] train: 7.6, val: 1.696\n",
      "[ACC%] train: 93.75%, val: 73.91%\n",
      "EPOCH: 102\n",
      "[LOSS] train: 7.693, val: 1.701\n",
      "[ACC%] train: 91.83%, val: 73.91%\n",
      "EPOCH: 103\n",
      "[LOSS] train: 7.7, val: 1.692\n",
      "[ACC%] train: 92.15%, val: 75.36%\n",
      "EPOCH: 104\n",
      "[LOSS] train: 7.702, val: 1.648\n",
      "[ACC%] train: 91.99%, val: 78.26%\n",
      "EPOCH: 105\n",
      "[LOSS] train: 7.697, val: 1.66\n",
      "[ACC%] train: 92.15%, val: 76.81%\n",
      "EPOCH: 106\n",
      "[LOSS] train: 7.619, val: 1.785\n",
      "[ACC%] train: 93.91%, val: 66.67%\n",
      "EPOCH: 107\n",
      "[LOSS] train: 7.661, val: 1.78\n",
      "[ACC%] train: 92.63%, val: 66.67%\n",
      "EPOCH: 108\n",
      "[LOSS] train: 7.618, val: 1.785\n",
      "[ACC%] train: 93.75%, val: 65.22%\n",
      "EPOCH: 109\n",
      "[LOSS] train: 7.688, val: 1.776\n",
      "[ACC%] train: 91.99%, val: 66.67%\n",
      "EPOCH: 110\n",
      "[LOSS] train: 7.675, val: 1.756\n",
      "[ACC%] train: 92.63%, val: 68.12%\n",
      "EPOCH: 111\n",
      "[LOSS] train: 7.633, val: 1.727\n",
      "[ACC%] train: 93.43%, val: 71.01%\n",
      "EPOCH: 112\n",
      "[LOSS] train: 7.619, val: 1.666\n",
      "[ACC%] train: 93.59%, val: 76.81%\n",
      "EPOCH: 113\n",
      "[LOSS] train: 7.799, val: 1.522\n",
      "[ACC%] train: 90.38%, val: 92.75%\n",
      "EPOCH: 114\n",
      "[LOSS] train: 7.711, val: 1.528\n",
      "[ACC%] train: 91.51%, val: 92.75%\n",
      "EPOCH: 115\n",
      "[LOSS] train: 7.6, val: 1.547\n",
      "[ACC%] train: 94.23%, val: 89.86%\n",
      "EPOCH: 116\n",
      "[LOSS] train: 7.648, val: 1.552\n",
      "[ACC%] train: 93.27%, val: 89.86%\n",
      "EPOCH: 117\n",
      "[LOSS] train: 7.601, val: 1.517\n",
      "[ACC%] train: 94.07%, val: 94.2%\n",
      "EPOCH: 118\n",
      "[LOSS] train: 7.706, val: 1.597\n",
      "[ACC%] train: 91.51%, val: 84.06%\n",
      "EPOCH: 119\n",
      "[LOSS] train: 7.619, val: 1.641\n",
      "[ACC%] train: 93.75%, val: 79.71%\n",
      "EPOCH: 120\n",
      "[LOSS] train: 7.676, val: 1.641\n",
      "[ACC%] train: 92.15%, val: 79.71%\n",
      "EPOCH: 121\n",
      "[LOSS] train: 7.655, val: 1.617\n",
      "[ACC%] train: 92.79%, val: 82.61%\n",
      "EPOCH: 122\n",
      "[LOSS] train: 7.659, val: 1.546\n",
      "[ACC%] train: 92.79%, val: 89.86%\n",
      "EPOCH: 123\n",
      "[LOSS] train: 7.636, val: 1.485\n",
      "[ACC%] train: 93.27%, val: 97.1%\n",
      "EPOCH: 124\n",
      "[LOSS] train: 7.636, val: 1.485\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 125\n",
      "[LOSS] train: 7.602, val: 1.484\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 126\n",
      "[LOSS] train: 7.606, val: 1.473\n",
      "[ACC%] train: 94.07%, val: 98.55%\n",
      "EPOCH: 127\n",
      "[LOSS] train: 7.687, val: 1.487\n",
      "[ACC%] train: 92.47%, val: 97.1%\n",
      "EPOCH: 128\n",
      "[LOSS] train: 7.673, val: 1.488\n",
      "[ACC%] train: 92.63%, val: 97.1%\n",
      "EPOCH: 129\n",
      "[LOSS] train: 7.59, val: 1.474\n",
      "[ACC%] train: 94.23%, val: 98.55%\n",
      "EPOCH: 130\n",
      "[LOSS] train: 7.565, val: 1.474\n",
      "[ACC%] train: 95.35%, val: 98.55%\n",
      "EPOCH: 131\n",
      "[LOSS] train: 7.607, val: 1.49\n",
      "[ACC%] train: 94.23%, val: 97.1%\n",
      "EPOCH: 132\n",
      "[LOSS] train: 7.64, val: 1.49\n",
      "[ACC%] train: 93.27%, val: 97.1%\n",
      "EPOCH: 133\n",
      "[LOSS] train: 7.6, val: 1.501\n",
      "[ACC%] train: 94.07%, val: 95.65%\n",
      "EPOCH: 134\n",
      "[LOSS] train: 7.624, val: 1.532\n",
      "[ACC%] train: 93.75%, val: 92.75%\n",
      "EPOCH: 135\n",
      "[LOSS] train: 7.626, val: 1.569\n",
      "[ACC%] train: 93.11%, val: 88.41%\n",
      "EPOCH: 136\n",
      "[LOSS] train: 7.694, val: 1.56\n",
      "[ACC%] train: 91.99%, val: 89.86%\n",
      "EPOCH: 137\n",
      "[LOSS] train: 7.668, val: 1.546\n",
      "[ACC%] train: 92.63%, val: 91.3%\n",
      "EPOCH: 138\n",
      "[LOSS] train: 7.695, val: 1.521\n",
      "[ACC%] train: 92.47%, val: 94.2%\n",
      "EPOCH: 139\n",
      "[LOSS] train: 7.679, val: 1.5\n",
      "[ACC%] train: 92.31%, val: 95.65%\n",
      "EPOCH: 140\n",
      "[LOSS] train: 7.704, val: 1.503\n",
      "[ACC%] train: 92.15%, val: 95.65%\n",
      "EPOCH: 141\n",
      "[LOSS] train: 7.692, val: 1.488\n",
      "[ACC%] train: 92.15%, val: 97.1%\n",
      "EPOCH: 142\n",
      "[LOSS] train: 7.687, val: 1.485\n",
      "[ACC%] train: 92.15%, val: 97.1%\n",
      "EPOCH: 143\n",
      "[LOSS] train: 7.66, val: 1.516\n",
      "[ACC%] train: 92.63%, val: 94.2%\n",
      "EPOCH: 144\n",
      "[LOSS] train: 7.65, val: 1.476\n",
      "[ACC%] train: 92.79%, val: 98.55%\n",
      "EPOCH: 145\n",
      "[LOSS] train: 7.701, val: 1.518\n",
      "[ACC%] train: 92.15%, val: 94.2%\n",
      "EPOCH: 146\n",
      "[LOSS] train: 7.629, val: 1.53\n",
      "[ACC%] train: 94.07%, val: 92.75%\n",
      "EPOCH: 147\n",
      "[LOSS] train: 7.633, val: 1.551\n",
      "[ACC%] train: 93.27%, val: 91.3%\n",
      "EPOCH: 148\n",
      "[LOSS] train: 7.617, val: 1.562\n",
      "[ACC%] train: 93.75%, val: 89.86%\n",
      "EPOCH: 149\n",
      "[LOSS] train: 7.602, val: 1.515\n",
      "[ACC%] train: 94.07%, val: 94.2%\n",
      "EPOCH: 150\n",
      "[LOSS] train: 7.639, val: 1.474\n",
      "[ACC%] train: 93.59%, val: 98.55%\n",
      "EPOCH: 151\n",
      "[LOSS] train: 7.627, val: 1.473\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 152\n",
      "[LOSS] train: 7.577, val: 1.482\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 153\n",
      "[LOSS] train: 7.618, val: 1.479\n",
      "[ACC%] train: 93.91%, val: 98.55%\n",
      "EPOCH: 154\n",
      "[LOSS] train: 7.724, val: 1.503\n",
      "[ACC%] train: 91.19%, val: 95.65%\n",
      "EPOCH: 155\n",
      "[LOSS] train: 7.586, val: 1.565\n",
      "[ACC%] train: 94.55%, val: 88.41%\n",
      "EPOCH: 156\n",
      "[LOSS] train: 7.678, val: 1.554\n",
      "[ACC%] train: 92.15%, val: 91.3%\n",
      "EPOCH: 157\n",
      "[LOSS] train: 7.588, val: 1.519\n",
      "[ACC%] train: 94.55%, val: 94.2%\n",
      "EPOCH: 158\n",
      "[LOSS] train: 7.666, val: 1.516\n",
      "[ACC%] train: 92.95%, val: 94.2%\n",
      "EPOCH: 159\n",
      "[LOSS] train: 7.676, val: 1.513\n",
      "[ACC%] train: 92.63%, val: 94.2%\n",
      "EPOCH: 160\n",
      "[LOSS] train: 7.61, val: 1.505\n",
      "[ACC%] train: 94.07%, val: 95.65%\n",
      "EPOCH: 161\n",
      "[LOSS] train: 7.614, val: 1.492\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 162\n",
      "[LOSS] train: 7.631, val: 1.498\n",
      "[ACC%] train: 92.95%, val: 95.65%\n",
      "EPOCH: 163\n",
      "[LOSS] train: 7.601, val: 1.498\n",
      "[ACC%] train: 94.07%, val: 95.65%\n",
      "EPOCH: 164\n",
      "[LOSS] train: 7.697, val: 1.493\n",
      "[ACC%] train: 92.63%, val: 97.1%\n",
      "EPOCH: 165\n",
      "[LOSS] train: 7.673, val: 1.48\n",
      "[ACC%] train: 92.47%, val: 98.55%\n",
      "EPOCH: 166\n",
      "[LOSS] train: 7.643, val: 1.48\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 167\n",
      "[LOSS] train: 7.667, val: 1.503\n",
      "[ACC%] train: 92.47%, val: 95.65%\n",
      "EPOCH: 168\n",
      "[LOSS] train: 7.581, val: 1.489\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 169\n",
      "[LOSS] train: 7.675, val: 1.489\n",
      "[ACC%] train: 92.47%, val: 97.1%\n",
      "EPOCH: 170\n",
      "[LOSS] train: 7.608, val: 1.594\n",
      "[ACC%] train: 93.59%, val: 84.06%\n",
      "EPOCH: 171\n",
      "[LOSS] train: 7.628, val: 1.684\n",
      "[ACC%] train: 93.59%, val: 73.91%\n",
      "EPOCH: 172\n",
      "[LOSS] train: 7.645, val: 1.554\n",
      "[ACC%] train: 93.11%, val: 89.86%\n",
      "EPOCH: 173\n",
      "[LOSS] train: 7.662, val: 1.528\n",
      "[ACC%] train: 92.79%, val: 92.75%\n",
      "EPOCH: 174\n",
      "[LOSS] train: 7.691, val: 1.498\n",
      "[ACC%] train: 92.15%, val: 95.65%\n",
      "EPOCH: 175\n",
      "[LOSS] train: 7.605, val: 1.506\n",
      "[ACC%] train: 94.39%, val: 95.65%\n",
      "EPOCH: 176\n",
      "[LOSS] train: 7.63, val: 1.507\n",
      "[ACC%] train: 93.43%, val: 94.2%\n",
      "EPOCH: 177\n",
      "[LOSS] train: 7.622, val: 1.5\n",
      "[ACC%] train: 93.75%, val: 95.65%\n",
      "EPOCH: 178\n",
      "[LOSS] train: 7.638, val: 1.501\n",
      "[ACC%] train: 93.43%, val: 95.65%\n",
      "EPOCH: 179\n",
      "[LOSS] train: 7.681, val: 1.512\n",
      "[ACC%] train: 92.31%, val: 94.2%\n",
      "EPOCH: 180\n",
      "[LOSS] train: 7.609, val: 1.518\n",
      "[ACC%] train: 93.59%, val: 94.2%\n",
      "EPOCH: 181\n",
      "[LOSS] train: 7.591, val: 1.539\n",
      "[ACC%] train: 94.23%, val: 91.3%\n",
      "EPOCH: 182\n",
      "[LOSS] train: 7.646, val: 1.539\n",
      "[ACC%] train: 93.59%, val: 92.75%\n",
      "EPOCH: 183\n",
      "[LOSS] train: 7.597, val: 1.564\n",
      "[ACC%] train: 94.55%, val: 89.86%\n",
      "EPOCH: 184\n",
      "[LOSS] train: 7.614, val: 1.516\n",
      "[ACC%] train: 93.75%, val: 94.2%\n",
      "EPOCH: 185\n",
      "[LOSS] train: 7.651, val: 1.544\n",
      "[ACC%] train: 92.79%, val: 91.3%\n",
      "EPOCH: 186\n",
      "[LOSS] train: 7.657, val: 1.543\n",
      "[ACC%] train: 92.79%, val: 89.86%\n",
      "EPOCH: 187\n",
      "[LOSS] train: 7.682, val: 1.534\n",
      "[ACC%] train: 91.99%, val: 92.75%\n",
      "EPOCH: 188\n",
      "[LOSS] train: 7.626, val: 1.5\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 189\n",
      "[LOSS] train: 7.652, val: 1.496\n",
      "[ACC%] train: 93.27%, val: 95.65%\n",
      "EPOCH: 190\n",
      "[LOSS] train: 7.669, val: 1.523\n",
      "[ACC%] train: 92.79%, val: 92.75%\n",
      "EPOCH: 191\n",
      "[LOSS] train: 7.624, val: 1.542\n",
      "[ACC%] train: 93.75%, val: 91.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 192\n",
      "[LOSS] train: 7.596, val: 1.544\n",
      "[ACC%] train: 94.23%, val: 91.3%\n",
      "EPOCH: 193\n",
      "[LOSS] train: 7.651, val: 1.541\n",
      "[ACC%] train: 92.95%, val: 91.3%\n",
      "EPOCH: 194\n",
      "[LOSS] train: 7.666, val: 1.537\n",
      "[ACC%] train: 92.79%, val: 92.75%\n",
      "EPOCH: 195\n",
      "[LOSS] train: 7.584, val: 1.524\n",
      "[ACC%] train: 94.23%, val: 94.2%\n",
      "EPOCH: 196\n",
      "[LOSS] train: 7.597, val: 1.516\n",
      "[ACC%] train: 94.39%, val: 94.2%\n",
      "EPOCH: 197\n",
      "[LOSS] train: 7.605, val: 1.504\n",
      "[ACC%] train: 94.07%, val: 95.65%\n",
      "EPOCH: 198\n",
      "[LOSS] train: 7.61, val: 1.489\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 199\n",
      "[LOSS] train: 7.567, val: 1.496\n",
      "[ACC%] train: 94.87%, val: 95.65%\n",
      "\n",
      "\n",
      "Working on 6th Fold\n",
      "EPOCH: 0\n",
      "[LOSS] train: 7.713, val: 1.492\n",
      "[ACC%] train: 91.51%, val: 97.1%\n",
      "EPOCH: 1\n",
      "[LOSS] train: 7.686, val: 1.492\n",
      "[ACC%] train: 92.15%, val: 97.1%\n",
      "EPOCH: 2\n",
      "[LOSS] train: 7.756, val: 1.492\n",
      "[ACC%] train: 90.87%, val: 97.1%\n",
      "EPOCH: 3\n",
      "[LOSS] train: 7.643, val: 1.492\n",
      "[ACC%] train: 93.27%, val: 97.1%\n",
      "EPOCH: 4\n",
      "[LOSS] train: 7.671, val: 1.492\n",
      "[ACC%] train: 92.47%, val: 97.1%\n",
      "EPOCH: 5\n",
      "[LOSS] train: 7.681, val: 1.492\n",
      "[ACC%] train: 92.15%, val: 97.1%\n",
      "EPOCH: 6\n",
      "[LOSS] train: 7.64, val: 1.492\n",
      "[ACC%] train: 93.11%, val: 97.1%\n",
      "EPOCH: 7\n",
      "[LOSS] train: 7.699, val: 1.492\n",
      "[ACC%] train: 91.83%, val: 97.1%\n",
      "EPOCH: 8\n",
      "[LOSS] train: 7.67, val: 1.491\n",
      "[ACC%] train: 92.31%, val: 97.1%\n",
      "EPOCH: 9\n",
      "[LOSS] train: 7.696, val: 1.492\n",
      "[ACC%] train: 91.99%, val: 97.1%\n",
      "EPOCH: 10\n",
      "[LOSS] train: 7.668, val: 1.492\n",
      "[ACC%] train: 92.95%, val: 97.1%\n",
      "EPOCH: 11\n",
      "[LOSS] train: 7.694, val: 1.492\n",
      "[ACC%] train: 91.99%, val: 97.1%\n",
      "EPOCH: 12\n",
      "[LOSS] train: 7.633, val: 1.492\n",
      "[ACC%] train: 93.75%, val: 97.1%\n",
      "EPOCH: 13\n",
      "[LOSS] train: 7.686, val: 1.492\n",
      "[ACC%] train: 92.47%, val: 97.1%\n",
      "EPOCH: 14\n",
      "[LOSS] train: 7.64, val: 1.492\n",
      "[ACC%] train: 93.11%, val: 97.1%\n",
      "EPOCH: 15\n",
      "[LOSS] train: 7.641, val: 1.492\n",
      "[ACC%] train: 92.95%, val: 97.1%\n",
      "EPOCH: 16\n",
      "[LOSS] train: 7.649, val: 1.492\n",
      "[ACC%] train: 93.27%, val: 97.1%\n",
      "EPOCH: 17\n",
      "[LOSS] train: 7.653, val: 1.491\n",
      "[ACC%] train: 93.11%, val: 97.1%\n",
      "EPOCH: 18\n",
      "[LOSS] train: 7.646, val: 1.491\n",
      "[ACC%] train: 93.43%, val: 97.1%\n",
      "EPOCH: 19\n",
      "[LOSS] train: 7.629, val: 1.492\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 20\n",
      "[LOSS] train: 7.648, val: 1.492\n",
      "[ACC%] train: 92.79%, val: 97.1%\n",
      "EPOCH: 21\n",
      "[LOSS] train: 7.685, val: 1.492\n",
      "[ACC%] train: 92.15%, val: 97.1%\n",
      "EPOCH: 22\n",
      "[LOSS] train: 7.68, val: 1.492\n",
      "[ACC%] train: 92.47%, val: 97.1%\n",
      "EPOCH: 23\n",
      "[LOSS] train: 7.664, val: 1.492\n",
      "[ACC%] train: 92.47%, val: 97.1%\n",
      "EPOCH: 24\n",
      "[LOSS] train: 7.643, val: 1.492\n",
      "[ACC%] train: 92.63%, val: 97.1%\n",
      "EPOCH: 25\n",
      "[LOSS] train: 7.682, val: 1.492\n",
      "[ACC%] train: 92.31%, val: 97.1%\n",
      "EPOCH: 26\n",
      "[LOSS] train: 7.654, val: 1.492\n",
      "[ACC%] train: 92.95%, val: 97.1%\n",
      "EPOCH: 27\n",
      "[LOSS] train: 7.625, val: 1.492\n",
      "[ACC%] train: 93.43%, val: 97.1%\n",
      "EPOCH: 28\n",
      "[LOSS] train: 7.641, val: 1.492\n",
      "[ACC%] train: 93.11%, val: 97.1%\n",
      "EPOCH: 29\n",
      "[LOSS] train: 7.685, val: 1.491\n",
      "[ACC%] train: 92.47%, val: 97.1%\n",
      "EPOCH: 30\n",
      "[LOSS] train: 7.619, val: 1.491\n",
      "[ACC%] train: 93.43%, val: 97.1%\n",
      "EPOCH: 31\n",
      "[LOSS] train: 7.611, val: 1.492\n",
      "[ACC%] train: 93.75%, val: 97.1%\n",
      "EPOCH: 32\n",
      "[LOSS] train: 7.645, val: 1.492\n",
      "[ACC%] train: 93.43%, val: 97.1%\n",
      "EPOCH: 33\n",
      "[LOSS] train: 7.646, val: 1.504\n",
      "[ACC%] train: 92.95%, val: 95.65%\n",
      "EPOCH: 34\n",
      "[LOSS] train: 7.67, val: 1.505\n",
      "[ACC%] train: 92.31%, val: 95.65%\n",
      "EPOCH: 35\n",
      "[LOSS] train: 7.676, val: 1.496\n",
      "[ACC%] train: 92.31%, val: 97.1%\n",
      "EPOCH: 36\n",
      "[LOSS] train: 7.654, val: 1.491\n",
      "[ACC%] train: 92.95%, val: 97.1%\n",
      "EPOCH: 37\n",
      "[LOSS] train: 7.632, val: 1.492\n",
      "[ACC%] train: 93.27%, val: 97.1%\n",
      "EPOCH: 38\n",
      "[LOSS] train: 7.626, val: 1.492\n",
      "[ACC%] train: 93.43%, val: 97.1%\n",
      "EPOCH: 39\n",
      "[LOSS] train: 7.647, val: 1.491\n",
      "[ACC%] train: 93.27%, val: 97.1%\n",
      "EPOCH: 40\n",
      "[LOSS] train: 7.669, val: 1.491\n",
      "[ACC%] train: 92.63%, val: 97.1%\n",
      "EPOCH: 41\n",
      "[LOSS] train: 7.646, val: 1.492\n",
      "[ACC%] train: 92.79%, val: 97.1%\n",
      "EPOCH: 42\n",
      "[LOSS] train: 7.621, val: 1.491\n",
      "[ACC%] train: 93.43%, val: 97.1%\n",
      "EPOCH: 43\n",
      "[LOSS] train: 7.613, val: 1.492\n",
      "[ACC%] train: 93.75%, val: 97.1%\n",
      "EPOCH: 44\n",
      "[LOSS] train: 7.7, val: 1.491\n",
      "[ACC%] train: 91.83%, val: 97.1%\n",
      "EPOCH: 45\n",
      "[LOSS] train: 7.639, val: 1.492\n",
      "[ACC%] train: 93.27%, val: 97.1%\n",
      "EPOCH: 46\n",
      "[LOSS] train: 7.575, val: 1.491\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 47\n",
      "[LOSS] train: 7.635, val: 1.491\n",
      "[ACC%] train: 93.27%, val: 97.1%\n",
      "EPOCH: 48\n",
      "[LOSS] train: 7.6, val: 1.491\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 49\n",
      "[LOSS] train: 7.692, val: 1.492\n",
      "[ACC%] train: 92.31%, val: 97.1%\n",
      "EPOCH: 50\n",
      "[LOSS] train: 7.689, val: 1.509\n",
      "[ACC%] train: 91.83%, val: 95.65%\n",
      "EPOCH: 51\n",
      "[LOSS] train: 7.626, val: 1.516\n",
      "[ACC%] train: 93.43%, val: 94.2%\n",
      "EPOCH: 52\n",
      "[LOSS] train: 7.693, val: 1.491\n",
      "[ACC%] train: 92.31%, val: 97.1%\n",
      "EPOCH: 53\n",
      "[LOSS] train: 7.588, val: 1.491\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 54\n",
      "[LOSS] train: 7.648, val: 1.491\n",
      "[ACC%] train: 92.95%, val: 97.1%\n",
      "EPOCH: 55\n",
      "[LOSS] train: 7.637, val: 1.49\n",
      "[ACC%] train: 92.95%, val: 97.1%\n",
      "EPOCH: 56\n",
      "[LOSS] train: 7.609, val: 1.492\n",
      "[ACC%] train: 93.75%, val: 97.1%\n",
      "EPOCH: 57\n",
      "[LOSS] train: 7.665, val: 1.492\n",
      "[ACC%] train: 92.95%, val: 97.1%\n",
      "EPOCH: 58\n",
      "[LOSS] train: 7.61, val: 1.491\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 59\n",
      "[LOSS] train: 7.615, val: 1.491\n",
      "[ACC%] train: 93.75%, val: 97.1%\n",
      "EPOCH: 60\n",
      "[LOSS] train: 7.593, val: 1.492\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 61\n",
      "[LOSS] train: 7.608, val: 1.492\n",
      "[ACC%] train: 93.75%, val: 97.1%\n",
      "EPOCH: 62\n",
      "[LOSS] train: 7.613, val: 1.492\n",
      "[ACC%] train: 93.43%, val: 97.1%\n",
      "EPOCH: 63\n",
      "[LOSS] train: 7.566, val: 1.492\n",
      "[ACC%] train: 94.71%, val: 97.1%\n",
      "EPOCH: 64\n",
      "[LOSS] train: 7.597, val: 1.492\n",
      "[ACC%] train: 93.75%, val: 97.1%\n",
      "EPOCH: 65\n",
      "[LOSS] train: 7.567, val: 1.492\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 66\n",
      "[LOSS] train: 7.565, val: 1.492\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 67\n",
      "[LOSS] train: 7.524, val: 1.492\n",
      "[ACC%] train: 95.51%, val: 97.1%\n",
      "EPOCH: 68\n",
      "[LOSS] train: 7.57, val: 1.492\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 69\n",
      "[LOSS] train: 7.594, val: 1.491\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 70\n",
      "[LOSS] train: 7.631, val: 1.491\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 71\n",
      "[LOSS] train: 7.577, val: 1.492\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 72\n",
      "[LOSS] train: 7.613, val: 1.491\n",
      "[ACC%] train: 93.27%, val: 97.1%\n",
      "EPOCH: 73\n",
      "[LOSS] train: 7.607, val: 1.491\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 74\n",
      "[LOSS] train: 7.639, val: 1.491\n",
      "[ACC%] train: 93.27%, val: 97.1%\n",
      "EPOCH: 75\n",
      "[LOSS] train: 7.529, val: 1.492\n",
      "[ACC%] train: 95.51%, val: 97.1%\n",
      "EPOCH: 76\n",
      "[LOSS] train: 7.602, val: 1.492\n",
      "[ACC%] train: 93.75%, val: 97.1%\n",
      "EPOCH: 77\n",
      "[LOSS] train: 7.651, val: 1.491\n",
      "[ACC%] train: 93.27%, val: 97.1%\n",
      "EPOCH: 78\n",
      "[LOSS] train: 7.604, val: 1.491\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 79\n",
      "[LOSS] train: 7.685, val: 1.492\n",
      "[ACC%] train: 91.83%, val: 97.1%\n",
      "EPOCH: 80\n",
      "[LOSS] train: 7.615, val: 1.492\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 81\n",
      "[LOSS] train: 7.638, val: 1.497\n",
      "[ACC%] train: 93.11%, val: 97.1%\n",
      "EPOCH: 82\n",
      "[LOSS] train: 7.552, val: 1.491\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 83\n",
      "[LOSS] train: 7.567, val: 1.492\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 84\n",
      "[LOSS] train: 7.632, val: 1.492\n",
      "[ACC%] train: 93.27%, val: 97.1%\n",
      "EPOCH: 85\n",
      "[LOSS] train: 7.734, val: 1.492\n",
      "[ACC%] train: 91.35%, val: 97.1%\n",
      "EPOCH: 86\n",
      "[LOSS] train: 7.613, val: 1.492\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 87\n",
      "[LOSS] train: 7.706, val: 1.491\n",
      "[ACC%] train: 91.99%, val: 97.1%\n",
      "EPOCH: 88\n",
      "[LOSS] train: 7.59, val: 1.491\n",
      "[ACC%] train: 94.23%, val: 97.1%\n",
      "EPOCH: 89\n",
      "[LOSS] train: 7.562, val: 1.491\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 90\n",
      "[LOSS] train: 7.631, val: 1.491\n",
      "[ACC%] train: 93.43%, val: 97.1%\n",
      "EPOCH: 91\n",
      "[LOSS] train: 7.575, val: 1.492\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 92\n",
      "[LOSS] train: 7.662, val: 1.492\n",
      "[ACC%] train: 92.63%, val: 97.1%\n",
      "EPOCH: 93\n",
      "[LOSS] train: 7.604, val: 1.492\n",
      "[ACC%] train: 93.75%, val: 97.1%\n",
      "EPOCH: 94\n",
      "[LOSS] train: 7.607, val: 1.492\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 95\n",
      "[LOSS] train: 7.684, val: 1.492\n",
      "[ACC%] train: 92.31%, val: 97.1%\n",
      "EPOCH: 96\n",
      "[LOSS] train: 7.636, val: 1.492\n",
      "[ACC%] train: 93.27%, val: 97.1%\n",
      "EPOCH: 97\n",
      "[LOSS] train: 7.63, val: 1.491\n",
      "[ACC%] train: 93.75%, val: 97.1%\n",
      "EPOCH: 98\n",
      "[LOSS] train: 7.595, val: 1.501\n",
      "[ACC%] train: 94.07%, val: 95.65%\n",
      "EPOCH: 99\n",
      "[LOSS] train: 7.652, val: 1.493\n",
      "[ACC%] train: 92.31%, val: 97.1%\n",
      "EPOCH: 100\n",
      "[LOSS] train: 7.651, val: 1.492\n",
      "[ACC%] train: 92.79%, val: 97.1%\n",
      "EPOCH: 101\n",
      "[LOSS] train: 7.634, val: 1.492\n",
      "[ACC%] train: 93.27%, val: 97.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 102\n",
      "[LOSS] train: 7.622, val: 1.492\n",
      "[ACC%] train: 93.43%, val: 97.1%\n",
      "EPOCH: 103\n",
      "[LOSS] train: 7.543, val: 1.5\n",
      "[ACC%] train: 95.03%, val: 95.65%\n",
      "EPOCH: 104\n",
      "[LOSS] train: 7.622, val: 1.502\n",
      "[ACC%] train: 93.91%, val: 95.65%\n",
      "EPOCH: 105\n",
      "[LOSS] train: 7.62, val: 1.508\n",
      "[ACC%] train: 93.59%, val: 95.65%\n",
      "EPOCH: 106\n",
      "[LOSS] train: 7.69, val: 1.504\n",
      "[ACC%] train: 92.31%, val: 95.65%\n",
      "EPOCH: 107\n",
      "[LOSS] train: 7.657, val: 1.497\n",
      "[ACC%] train: 92.79%, val: 97.1%\n",
      "EPOCH: 108\n",
      "[LOSS] train: 7.671, val: 1.492\n",
      "[ACC%] train: 92.47%, val: 97.1%\n",
      "EPOCH: 109\n",
      "[LOSS] train: 7.593, val: 1.492\n",
      "[ACC%] train: 94.23%, val: 97.1%\n",
      "EPOCH: 110\n",
      "[LOSS] train: 7.58, val: 1.502\n",
      "[ACC%] train: 94.23%, val: 95.65%\n",
      "EPOCH: 111\n",
      "[LOSS] train: 7.524, val: 1.506\n",
      "[ACC%] train: 95.35%, val: 95.65%\n",
      "EPOCH: 112\n",
      "[LOSS] train: 7.605, val: 1.492\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 113\n",
      "[LOSS] train: 7.572, val: 1.492\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 114\n",
      "[LOSS] train: 7.605, val: 1.501\n",
      "[ACC%] train: 93.59%, val: 95.65%\n",
      "EPOCH: 115\n",
      "[LOSS] train: 7.577, val: 1.506\n",
      "[ACC%] train: 94.39%, val: 95.65%\n",
      "EPOCH: 116\n",
      "[LOSS] train: 7.56, val: 1.523\n",
      "[ACC%] train: 94.87%, val: 94.2%\n",
      "EPOCH: 117\n",
      "[LOSS] train: 7.63, val: 1.506\n",
      "[ACC%] train: 93.43%, val: 95.65%\n",
      "EPOCH: 118\n",
      "[LOSS] train: 7.609, val: 1.506\n",
      "[ACC%] train: 93.75%, val: 95.65%\n",
      "EPOCH: 119\n",
      "[LOSS] train: 7.611, val: 1.491\n",
      "[ACC%] train: 93.43%, val: 97.1%\n",
      "EPOCH: 120\n",
      "[LOSS] train: 7.581, val: 1.491\n",
      "[ACC%] train: 94.23%, val: 97.1%\n",
      "EPOCH: 121\n",
      "[LOSS] train: 7.627, val: 1.492\n",
      "[ACC%] train: 93.75%, val: 97.1%\n",
      "EPOCH: 122\n",
      "[LOSS] train: 7.607, val: 1.492\n",
      "[ACC%] train: 93.75%, val: 97.1%\n",
      "EPOCH: 123\n",
      "[LOSS] train: 7.624, val: 1.492\n",
      "[ACC%] train: 93.43%, val: 97.1%\n",
      "EPOCH: 124\n",
      "[LOSS] train: 7.605, val: 1.492\n",
      "[ACC%] train: 94.23%, val: 97.1%\n",
      "EPOCH: 125\n",
      "[LOSS] train: 7.586, val: 1.491\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 126\n",
      "[LOSS] train: 7.525, val: 1.491\n",
      "[ACC%] train: 95.51%, val: 97.1%\n",
      "EPOCH: 127\n",
      "[LOSS] train: 7.555, val: 1.492\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 128\n",
      "[LOSS] train: 7.548, val: 1.492\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 129\n",
      "[LOSS] train: 7.531, val: 1.492\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 130\n",
      "[LOSS] train: 7.565, val: 1.5\n",
      "[ACC%] train: 94.71%, val: 95.65%\n",
      "EPOCH: 131\n",
      "[LOSS] train: 7.555, val: 1.502\n",
      "[ACC%] train: 94.71%, val: 95.65%\n",
      "EPOCH: 132\n",
      "[LOSS] train: 7.664, val: 1.503\n",
      "[ACC%] train: 92.79%, val: 95.65%\n",
      "EPOCH: 133\n",
      "[LOSS] train: 7.588, val: 1.526\n",
      "[ACC%] train: 94.07%, val: 92.75%\n",
      "EPOCH: 134\n",
      "[LOSS] train: 7.624, val: 1.52\n",
      "[ACC%] train: 93.75%, val: 92.75%\n",
      "EPOCH: 135\n",
      "[LOSS] train: 7.588, val: 1.503\n",
      "[ACC%] train: 94.39%, val: 95.65%\n",
      "EPOCH: 136\n",
      "[LOSS] train: 7.61, val: 1.493\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 137\n",
      "[LOSS] train: 7.615, val: 1.492\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 138\n",
      "[LOSS] train: 7.535, val: 1.493\n",
      "[ACC%] train: 95.19%, val: 97.1%\n",
      "EPOCH: 139\n",
      "[LOSS] train: 7.589, val: 1.492\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 140\n",
      "[LOSS] train: 7.558, val: 1.492\n",
      "[ACC%] train: 94.71%, val: 97.1%\n",
      "EPOCH: 141\n",
      "[LOSS] train: 7.601, val: 1.491\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 142\n",
      "[LOSS] train: 7.588, val: 1.491\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 143\n",
      "[LOSS] train: 7.591, val: 1.492\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 144\n",
      "[LOSS] train: 7.566, val: 1.497\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 145\n",
      "[LOSS] train: 7.603, val: 1.493\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 146\n",
      "[LOSS] train: 7.496, val: 1.504\n",
      "[ACC%] train: 96.15%, val: 95.65%\n",
      "EPOCH: 147\n",
      "[LOSS] train: 7.621, val: 1.504\n",
      "[ACC%] train: 93.27%, val: 95.65%\n",
      "EPOCH: 148\n",
      "[LOSS] train: 7.564, val: 1.492\n",
      "[ACC%] train: 94.71%, val: 97.1%\n",
      "EPOCH: 149\n",
      "[LOSS] train: 7.536, val: 1.491\n",
      "[ACC%] train: 95.19%, val: 97.1%\n",
      "EPOCH: 150\n",
      "[LOSS] train: 7.561, val: 1.492\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 151\n",
      "[LOSS] train: 7.617, val: 1.492\n",
      "[ACC%] train: 93.75%, val: 97.1%\n",
      "EPOCH: 152\n",
      "[LOSS] train: 7.579, val: 1.491\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 153\n",
      "[LOSS] train: 7.587, val: 1.491\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 154\n",
      "[LOSS] train: 7.598, val: 1.495\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 155\n",
      "[LOSS] train: 7.55, val: 1.495\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 156\n",
      "[LOSS] train: 7.581, val: 1.507\n",
      "[ACC%] train: 94.39%, val: 95.65%\n",
      "EPOCH: 157\n",
      "[LOSS] train: 7.545, val: 1.493\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 158\n",
      "[LOSS] train: 7.614, val: 1.492\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 159\n",
      "[LOSS] train: 7.562, val: 1.491\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 160\n",
      "[LOSS] train: 7.605, val: 1.492\n",
      "[ACC%] train: 94.23%, val: 97.1%\n",
      "EPOCH: 161\n",
      "[LOSS] train: 7.527, val: 1.492\n",
      "[ACC%] train: 95.67%, val: 97.1%\n",
      "EPOCH: 162\n",
      "[LOSS] train: 7.565, val: 1.491\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 163\n",
      "[LOSS] train: 7.538, val: 1.492\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 164\n",
      "[LOSS] train: 7.586, val: 1.491\n",
      "[ACC%] train: 94.71%, val: 97.1%\n",
      "EPOCH: 165\n",
      "[LOSS] train: 7.609, val: 1.505\n",
      "[ACC%] train: 93.91%, val: 95.65%\n",
      "EPOCH: 166\n",
      "[LOSS] train: 7.585, val: 1.516\n",
      "[ACC%] train: 94.39%, val: 94.2%\n",
      "EPOCH: 167\n",
      "[LOSS] train: 7.604, val: 1.515\n",
      "[ACC%] train: 93.75%, val: 94.2%\n",
      "EPOCH: 168\n",
      "[LOSS] train: 7.586, val: 1.515\n",
      "[ACC%] train: 94.39%, val: 94.2%\n",
      "EPOCH: 169\n",
      "[LOSS] train: 7.622, val: 1.492\n",
      "[ACC%] train: 93.43%, val: 97.1%\n",
      "EPOCH: 170\n",
      "[LOSS] train: 7.646, val: 1.492\n",
      "[ACC%] train: 93.11%, val: 97.1%\n",
      "EPOCH: 171\n",
      "[LOSS] train: 7.557, val: 1.492\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 172\n",
      "[LOSS] train: 7.581, val: 1.5\n",
      "[ACC%] train: 94.39%, val: 95.65%\n",
      "EPOCH: 173\n",
      "[LOSS] train: 7.634, val: 1.503\n",
      "[ACC%] train: 93.27%, val: 95.65%\n",
      "EPOCH: 174\n",
      "[LOSS] train: 7.655, val: 1.503\n",
      "[ACC%] train: 92.79%, val: 95.65%\n",
      "EPOCH: 175\n",
      "[LOSS] train: 7.643, val: 1.514\n",
      "[ACC%] train: 92.79%, val: 94.2%\n",
      "EPOCH: 176\n",
      "[LOSS] train: 7.65, val: 1.515\n",
      "[ACC%] train: 92.47%, val: 94.2%\n",
      "EPOCH: 177\n",
      "[LOSS] train: 7.511, val: 1.498\n",
      "[ACC%] train: 95.83%, val: 95.65%\n",
      "EPOCH: 178\n",
      "[LOSS] train: 7.567, val: 1.503\n",
      "[ACC%] train: 94.71%, val: 95.65%\n",
      "EPOCH: 179\n",
      "[LOSS] train: 7.619, val: 1.51\n",
      "[ACC%] train: 93.59%, val: 94.2%\n",
      "EPOCH: 180\n",
      "[LOSS] train: 7.543, val: 1.514\n",
      "[ACC%] train: 95.03%, val: 94.2%\n",
      "EPOCH: 181\n",
      "[LOSS] train: 7.587, val: 1.513\n",
      "[ACC%] train: 94.39%, val: 94.2%\n",
      "EPOCH: 182\n",
      "[LOSS] train: 7.57, val: 1.516\n",
      "[ACC%] train: 94.71%, val: 94.2%\n",
      "EPOCH: 183\n",
      "[LOSS] train: 7.572, val: 1.5\n",
      "[ACC%] train: 94.39%, val: 95.65%\n",
      "EPOCH: 184\n",
      "[LOSS] train: 7.572, val: 1.491\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 185\n",
      "[LOSS] train: 7.595, val: 1.492\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 186\n",
      "[LOSS] train: 7.532, val: 1.492\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 187\n",
      "[LOSS] train: 7.525, val: 1.492\n",
      "[ACC%] train: 95.19%, val: 97.1%\n",
      "EPOCH: 188\n",
      "[LOSS] train: 7.526, val: 1.492\n",
      "[ACC%] train: 95.51%, val: 97.1%\n",
      "EPOCH: 189\n",
      "[LOSS] train: 7.524, val: 1.493\n",
      "[ACC%] train: 95.51%, val: 97.1%\n",
      "EPOCH: 190\n",
      "[LOSS] train: 7.579, val: 1.493\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 191\n",
      "[LOSS] train: 7.527, val: 1.492\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 192\n",
      "[LOSS] train: 7.576, val: 1.492\n",
      "[ACC%] train: 94.71%, val: 97.1%\n",
      "EPOCH: 193\n",
      "[LOSS] train: 7.532, val: 1.492\n",
      "[ACC%] train: 95.19%, val: 97.1%\n",
      "EPOCH: 194\n",
      "[LOSS] train: 7.566, val: 1.492\n",
      "[ACC%] train: 94.71%, val: 97.1%\n",
      "EPOCH: 195\n",
      "[LOSS] train: 7.489, val: 1.492\n",
      "[ACC%] train: 96.31%, val: 97.1%\n",
      "EPOCH: 196\n",
      "[LOSS] train: 7.564, val: 1.492\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 197\n",
      "[LOSS] train: 7.514, val: 1.492\n",
      "[ACC%] train: 95.51%, val: 97.1%\n",
      "EPOCH: 198\n",
      "[LOSS] train: 7.553, val: 1.517\n",
      "[ACC%] train: 95.03%, val: 94.2%\n",
      "EPOCH: 199\n",
      "[LOSS] train: 7.464, val: 1.518\n",
      "[ACC%] train: 96.79%, val: 94.2%\n",
      "\n",
      "\n",
      "Working on 7th Fold\n",
      "EPOCH: 0\n",
      "[LOSS] train: 7.571, val: 1.478\n",
      "[ACC%] train: 94.71%, val: 98.55%\n",
      "EPOCH: 1\n",
      "[LOSS] train: 7.699, val: 1.477\n",
      "[ACC%] train: 92.63%, val: 98.55%\n",
      "EPOCH: 2\n",
      "[LOSS] train: 7.669, val: 1.477\n",
      "[ACC%] train: 92.79%, val: 98.55%\n",
      "EPOCH: 3\n",
      "[LOSS] train: 7.547, val: 1.477\n",
      "[ACC%] train: 94.87%, val: 98.55%\n",
      "EPOCH: 4\n",
      "[LOSS] train: 7.607, val: 1.477\n",
      "[ACC%] train: 94.07%, val: 98.55%\n",
      "EPOCH: 5\n",
      "[LOSS] train: 7.606, val: 1.478\n",
      "[ACC%] train: 93.91%, val: 98.55%\n",
      "EPOCH: 6\n",
      "[LOSS] train: 7.606, val: 1.478\n",
      "[ACC%] train: 94.07%, val: 98.55%\n",
      "EPOCH: 7\n",
      "[LOSS] train: 7.599, val: 1.478\n",
      "[ACC%] train: 93.75%, val: 98.55%\n",
      "EPOCH: 8\n",
      "[LOSS] train: 7.628, val: 1.478\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 9\n",
      "[LOSS] train: 7.607, val: 1.477\n",
      "[ACC%] train: 93.43%, val: 98.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 10\n",
      "[LOSS] train: 7.585, val: 1.477\n",
      "[ACC%] train: 94.07%, val: 98.55%\n",
      "EPOCH: 11\n",
      "[LOSS] train: 7.573, val: 1.477\n",
      "[ACC%] train: 94.71%, val: 98.55%\n",
      "EPOCH: 12\n",
      "[LOSS] train: 7.612, val: 1.477\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 13\n",
      "[LOSS] train: 7.663, val: 1.477\n",
      "[ACC%] train: 92.63%, val: 98.55%\n",
      "EPOCH: 14\n",
      "[LOSS] train: 7.646, val: 1.477\n",
      "[ACC%] train: 92.95%, val: 98.55%\n",
      "EPOCH: 15\n",
      "[LOSS] train: 7.622, val: 1.477\n",
      "[ACC%] train: 93.59%, val: 98.55%\n",
      "EPOCH: 16\n",
      "[LOSS] train: 7.634, val: 1.477\n",
      "[ACC%] train: 93.11%, val: 98.55%\n",
      "EPOCH: 17\n",
      "[LOSS] train: 7.625, val: 1.478\n",
      "[ACC%] train: 93.75%, val: 98.55%\n",
      "EPOCH: 18\n",
      "[LOSS] train: 7.6, val: 1.478\n",
      "[ACC%] train: 93.91%, val: 98.55%\n",
      "EPOCH: 19\n",
      "[LOSS] train: 7.652, val: 1.478\n",
      "[ACC%] train: 92.79%, val: 98.55%\n",
      "EPOCH: 20\n",
      "[LOSS] train: 7.64, val: 1.478\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 21\n",
      "[LOSS] train: 7.614, val: 1.478\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 22\n",
      "[LOSS] train: 7.631, val: 1.478\n",
      "[ACC%] train: 93.75%, val: 98.55%\n",
      "EPOCH: 23\n",
      "[LOSS] train: 7.612, val: 1.478\n",
      "[ACC%] train: 93.75%, val: 98.55%\n",
      "EPOCH: 24\n",
      "[LOSS] train: 7.639, val: 1.478\n",
      "[ACC%] train: 93.27%, val: 98.55%\n",
      "EPOCH: 25\n",
      "[LOSS] train: 7.561, val: 1.478\n",
      "[ACC%] train: 94.87%, val: 98.55%\n",
      "EPOCH: 26\n",
      "[LOSS] train: 7.538, val: 1.478\n",
      "[ACC%] train: 95.35%, val: 98.55%\n",
      "EPOCH: 27\n",
      "[LOSS] train: 7.558, val: 1.504\n",
      "[ACC%] train: 94.87%, val: 95.65%\n",
      "EPOCH: 28\n",
      "[LOSS] train: 7.606, val: 1.497\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 29\n",
      "[LOSS] train: 7.578, val: 1.478\n",
      "[ACC%] train: 94.23%, val: 98.55%\n",
      "EPOCH: 30\n",
      "[LOSS] train: 7.687, val: 1.478\n",
      "[ACC%] train: 92.31%, val: 98.55%\n",
      "EPOCH: 31\n",
      "[LOSS] train: 7.616, val: 1.478\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 32\n",
      "[LOSS] train: 7.557, val: 1.478\n",
      "[ACC%] train: 95.03%, val: 98.55%\n",
      "EPOCH: 33\n",
      "[LOSS] train: 7.578, val: 1.477\n",
      "[ACC%] train: 94.39%, val: 98.55%\n",
      "EPOCH: 34\n",
      "[LOSS] train: 7.69, val: 1.478\n",
      "[ACC%] train: 92.31%, val: 98.55%\n",
      "EPOCH: 35\n",
      "[LOSS] train: 7.586, val: 1.478\n",
      "[ACC%] train: 94.39%, val: 98.55%\n",
      "EPOCH: 36\n",
      "[LOSS] train: 7.69, val: 1.478\n",
      "[ACC%] train: 91.67%, val: 98.55%\n",
      "EPOCH: 37\n",
      "[LOSS] train: 7.64, val: 1.478\n",
      "[ACC%] train: 92.95%, val: 98.55%\n",
      "EPOCH: 38\n",
      "[LOSS] train: 7.629, val: 1.478\n",
      "[ACC%] train: 93.59%, val: 98.55%\n",
      "EPOCH: 39\n",
      "[LOSS] train: 7.696, val: 1.478\n",
      "[ACC%] train: 91.99%, val: 98.55%\n",
      "EPOCH: 40\n",
      "[LOSS] train: 7.654, val: 1.478\n",
      "[ACC%] train: 93.11%, val: 98.55%\n",
      "EPOCH: 41\n",
      "[LOSS] train: 7.584, val: 1.477\n",
      "[ACC%] train: 94.23%, val: 98.55%\n",
      "EPOCH: 42\n",
      "[LOSS] train: 7.622, val: 1.478\n",
      "[ACC%] train: 93.59%, val: 98.55%\n",
      "EPOCH: 43\n",
      "[LOSS] train: 7.62, val: 1.478\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 44\n",
      "[LOSS] train: 7.668, val: 1.477\n",
      "[ACC%] train: 92.63%, val: 98.55%\n",
      "EPOCH: 45\n",
      "[LOSS] train: 7.576, val: 1.477\n",
      "[ACC%] train: 94.55%, val: 98.55%\n",
      "EPOCH: 46\n",
      "[LOSS] train: 7.597, val: 1.478\n",
      "[ACC%] train: 93.59%, val: 98.55%\n",
      "EPOCH: 47\n",
      "[LOSS] train: 7.617, val: 1.477\n",
      "[ACC%] train: 93.75%, val: 98.55%\n",
      "EPOCH: 48\n",
      "[LOSS] train: 7.57, val: 1.478\n",
      "[ACC%] train: 94.71%, val: 98.55%\n",
      "EPOCH: 49\n",
      "[LOSS] train: 7.696, val: 1.48\n",
      "[ACC%] train: 92.15%, val: 98.55%\n",
      "EPOCH: 50\n",
      "[LOSS] train: 7.632, val: 1.478\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 51\n",
      "[LOSS] train: 7.648, val: 1.477\n",
      "[ACC%] train: 92.95%, val: 98.55%\n",
      "EPOCH: 52\n",
      "[LOSS] train: 7.603, val: 1.478\n",
      "[ACC%] train: 93.91%, val: 98.55%\n",
      "EPOCH: 53\n",
      "[LOSS] train: 7.606, val: 1.478\n",
      "[ACC%] train: 93.91%, val: 98.55%\n",
      "EPOCH: 54\n",
      "[LOSS] train: 7.614, val: 1.48\n",
      "[ACC%] train: 93.59%, val: 98.55%\n",
      "EPOCH: 55\n",
      "[LOSS] train: 7.61, val: 1.478\n",
      "[ACC%] train: 93.75%, val: 98.55%\n",
      "EPOCH: 56\n",
      "[LOSS] train: 7.602, val: 1.478\n",
      "[ACC%] train: 93.75%, val: 98.55%\n",
      "EPOCH: 57\n",
      "[LOSS] train: 7.531, val: 1.477\n",
      "[ACC%] train: 95.35%, val: 98.55%\n",
      "EPOCH: 58\n",
      "[LOSS] train: 7.673, val: 1.478\n",
      "[ACC%] train: 92.47%, val: 98.55%\n",
      "EPOCH: 59\n",
      "[LOSS] train: 7.576, val: 1.477\n",
      "[ACC%] train: 94.55%, val: 98.55%\n",
      "EPOCH: 60\n",
      "[LOSS] train: 7.562, val: 1.478\n",
      "[ACC%] train: 94.87%, val: 98.55%\n",
      "EPOCH: 61\n",
      "[LOSS] train: 7.628, val: 1.486\n",
      "[ACC%] train: 93.43%, val: 97.1%\n",
      "EPOCH: 62\n",
      "[LOSS] train: 7.567, val: 1.49\n",
      "[ACC%] train: 95.19%, val: 97.1%\n",
      "EPOCH: 63\n",
      "[LOSS] train: 7.605, val: 1.486\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 64\n",
      "[LOSS] train: 7.57, val: 1.478\n",
      "[ACC%] train: 94.39%, val: 98.55%\n",
      "EPOCH: 65\n",
      "[LOSS] train: 7.594, val: 1.477\n",
      "[ACC%] train: 94.23%, val: 98.55%\n",
      "EPOCH: 66\n",
      "[LOSS] train: 7.586, val: 1.478\n",
      "[ACC%] train: 94.23%, val: 98.55%\n",
      "EPOCH: 67\n",
      "[LOSS] train: 7.591, val: 1.478\n",
      "[ACC%] train: 94.07%, val: 98.55%\n",
      "EPOCH: 68\n",
      "[LOSS] train: 7.531, val: 1.501\n",
      "[ACC%] train: 95.67%, val: 95.65%\n",
      "EPOCH: 69\n",
      "[LOSS] train: 7.589, val: 1.49\n",
      "[ACC%] train: 94.23%, val: 97.1%\n",
      "EPOCH: 70\n",
      "[LOSS] train: 7.587, val: 1.478\n",
      "[ACC%] train: 94.55%, val: 98.55%\n",
      "EPOCH: 71\n",
      "[LOSS] train: 7.546, val: 1.497\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 72\n",
      "[LOSS] train: 7.536, val: 1.479\n",
      "[ACC%] train: 95.19%, val: 98.55%\n",
      "EPOCH: 73\n",
      "[LOSS] train: 7.526, val: 1.478\n",
      "[ACC%] train: 95.51%, val: 98.55%\n",
      "EPOCH: 74\n",
      "[LOSS] train: 7.526, val: 1.477\n",
      "[ACC%] train: 95.51%, val: 98.55%\n",
      "EPOCH: 75\n",
      "[LOSS] train: 7.548, val: 1.477\n",
      "[ACC%] train: 95.03%, val: 98.55%\n",
      "EPOCH: 76\n",
      "[LOSS] train: 7.547, val: 1.478\n",
      "[ACC%] train: 95.19%, val: 98.55%\n",
      "EPOCH: 77\n",
      "[LOSS] train: 7.611, val: 1.482\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 78\n",
      "[LOSS] train: 7.619, val: 1.477\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 79\n",
      "[LOSS] train: 7.591, val: 1.477\n",
      "[ACC%] train: 93.75%, val: 98.55%\n",
      "EPOCH: 80\n",
      "[LOSS] train: 7.539, val: 1.48\n",
      "[ACC%] train: 95.35%, val: 98.55%\n",
      "EPOCH: 81\n",
      "[LOSS] train: 7.592, val: 1.478\n",
      "[ACC%] train: 93.59%, val: 98.55%\n",
      "EPOCH: 82\n",
      "[LOSS] train: 7.626, val: 1.478\n",
      "[ACC%] train: 93.59%, val: 98.55%\n",
      "EPOCH: 83\n",
      "[LOSS] train: 7.559, val: 1.478\n",
      "[ACC%] train: 94.87%, val: 98.55%\n",
      "EPOCH: 84\n",
      "[LOSS] train: 7.565, val: 1.477\n",
      "[ACC%] train: 94.71%, val: 98.55%\n",
      "EPOCH: 85\n",
      "[LOSS] train: 7.553, val: 1.478\n",
      "[ACC%] train: 94.87%, val: 98.55%\n",
      "EPOCH: 86\n",
      "[LOSS] train: 7.593, val: 1.478\n",
      "[ACC%] train: 93.91%, val: 98.55%\n",
      "EPOCH: 87\n",
      "[LOSS] train: 7.637, val: 1.478\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 88\n",
      "[LOSS] train: 7.547, val: 1.478\n",
      "[ACC%] train: 95.03%, val: 98.55%\n",
      "EPOCH: 89\n",
      "[LOSS] train: 7.627, val: 1.478\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 90\n",
      "[LOSS] train: 7.619, val: 1.478\n",
      "[ACC%] train: 93.59%, val: 98.55%\n",
      "EPOCH: 91\n",
      "[LOSS] train: 7.589, val: 1.489\n",
      "[ACC%] train: 94.23%, val: 97.1%\n",
      "EPOCH: 92\n",
      "[LOSS] train: 7.592, val: 1.482\n",
      "[ACC%] train: 94.07%, val: 98.55%\n",
      "EPOCH: 93\n",
      "[LOSS] train: 7.646, val: 1.489\n",
      "[ACC%] train: 93.11%, val: 97.1%\n",
      "EPOCH: 94\n",
      "[LOSS] train: 7.643, val: 1.482\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 95\n",
      "[LOSS] train: 7.681, val: 1.478\n",
      "[ACC%] train: 92.31%, val: 98.55%\n",
      "EPOCH: 96\n",
      "[LOSS] train: 7.53, val: 1.478\n",
      "[ACC%] train: 95.35%, val: 98.55%\n",
      "EPOCH: 97\n",
      "[LOSS] train: 7.573, val: 1.478\n",
      "[ACC%] train: 94.55%, val: 98.55%\n",
      "EPOCH: 98\n",
      "[LOSS] train: 7.629, val: 1.478\n",
      "[ACC%] train: 93.27%, val: 98.55%\n",
      "EPOCH: 99\n",
      "[LOSS] train: 7.669, val: 1.478\n",
      "[ACC%] train: 92.63%, val: 98.55%\n",
      "EPOCH: 100\n",
      "[LOSS] train: 7.61, val: 1.478\n",
      "[ACC%] train: 93.59%, val: 98.55%\n",
      "EPOCH: 101\n",
      "[LOSS] train: 7.545, val: 1.478\n",
      "[ACC%] train: 95.19%, val: 98.55%\n",
      "EPOCH: 102\n",
      "[LOSS] train: 7.571, val: 1.484\n",
      "[ACC%] train: 94.71%, val: 98.55%\n",
      "EPOCH: 103\n",
      "[LOSS] train: 7.663, val: 1.478\n",
      "[ACC%] train: 92.79%, val: 98.55%\n",
      "EPOCH: 104\n",
      "[LOSS] train: 7.585, val: 1.477\n",
      "[ACC%] train: 94.23%, val: 98.55%\n",
      "EPOCH: 105\n",
      "[LOSS] train: 7.635, val: 1.478\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 106\n",
      "[LOSS] train: 7.591, val: 1.478\n",
      "[ACC%] train: 94.23%, val: 98.55%\n",
      "EPOCH: 107\n",
      "[LOSS] train: 7.569, val: 1.477\n",
      "[ACC%] train: 94.71%, val: 98.55%\n",
      "EPOCH: 108\n",
      "[LOSS] train: 7.513, val: 1.479\n",
      "[ACC%] train: 95.99%, val: 98.55%\n",
      "EPOCH: 109\n",
      "[LOSS] train: 7.577, val: 1.503\n",
      "[ACC%] train: 94.39%, val: 95.65%\n",
      "EPOCH: 110\n",
      "[LOSS] train: 7.629, val: 1.504\n",
      "[ACC%] train: 93.43%, val: 95.65%\n",
      "EPOCH: 111\n",
      "[LOSS] train: 7.55, val: 1.478\n",
      "[ACC%] train: 95.19%, val: 98.55%\n",
      "EPOCH: 112\n",
      "[LOSS] train: 7.65, val: 1.478\n",
      "[ACC%] train: 92.95%, val: 98.55%\n",
      "EPOCH: 113\n",
      "[LOSS] train: 7.565, val: 1.478\n",
      "[ACC%] train: 94.55%, val: 98.55%\n",
      "EPOCH: 114\n",
      "[LOSS] train: 7.561, val: 1.478\n",
      "[ACC%] train: 94.71%, val: 98.55%\n",
      "EPOCH: 115\n",
      "[LOSS] train: 7.557, val: 1.478\n",
      "[ACC%] train: 94.87%, val: 98.55%\n",
      "EPOCH: 116\n",
      "[LOSS] train: 7.59, val: 1.478\n",
      "[ACC%] train: 94.55%, val: 98.55%\n",
      "EPOCH: 117\n",
      "[LOSS] train: 7.58, val: 1.478\n",
      "[ACC%] train: 94.23%, val: 98.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 118\n",
      "[LOSS] train: 7.624, val: 1.489\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 119\n",
      "[LOSS] train: 7.613, val: 1.489\n",
      "[ACC%] train: 93.75%, val: 97.1%\n",
      "EPOCH: 120\n",
      "[LOSS] train: 7.61, val: 1.489\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 121\n",
      "[LOSS] train: 7.598, val: 1.489\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 122\n",
      "[LOSS] train: 7.562, val: 1.487\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 123\n",
      "[LOSS] train: 7.639, val: 1.478\n",
      "[ACC%] train: 93.11%, val: 98.55%\n",
      "EPOCH: 124\n",
      "[LOSS] train: 7.529, val: 1.478\n",
      "[ACC%] train: 95.35%, val: 98.55%\n",
      "EPOCH: 125\n",
      "[LOSS] train: 7.56, val: 1.478\n",
      "[ACC%] train: 94.71%, val: 98.55%\n",
      "EPOCH: 126\n",
      "[LOSS] train: 7.556, val: 1.478\n",
      "[ACC%] train: 94.71%, val: 98.55%\n",
      "EPOCH: 127\n",
      "[LOSS] train: 7.593, val: 1.478\n",
      "[ACC%] train: 93.91%, val: 98.55%\n",
      "EPOCH: 128\n",
      "[LOSS] train: 7.596, val: 1.478\n",
      "[ACC%] train: 93.75%, val: 98.55%\n",
      "EPOCH: 129\n",
      "[LOSS] train: 7.589, val: 1.478\n",
      "[ACC%] train: 94.07%, val: 98.55%\n",
      "EPOCH: 130\n",
      "[LOSS] train: 7.651, val: 1.477\n",
      "[ACC%] train: 92.63%, val: 98.55%\n",
      "EPOCH: 131\n",
      "[LOSS] train: 7.639, val: 1.478\n",
      "[ACC%] train: 93.27%, val: 98.55%\n",
      "EPOCH: 132\n",
      "[LOSS] train: 7.614, val: 1.479\n",
      "[ACC%] train: 93.91%, val: 98.55%\n",
      "EPOCH: 133\n",
      "[LOSS] train: 7.578, val: 1.48\n",
      "[ACC%] train: 94.39%, val: 98.55%\n",
      "EPOCH: 134\n",
      "[LOSS] train: 7.648, val: 1.509\n",
      "[ACC%] train: 92.95%, val: 94.2%\n",
      "EPOCH: 135\n",
      "[LOSS] train: 7.643, val: 1.506\n",
      "[ACC%] train: 93.27%, val: 95.65%\n",
      "EPOCH: 136\n",
      "[LOSS] train: 7.689, val: 1.512\n",
      "[ACC%] train: 92.15%, val: 95.65%\n",
      "EPOCH: 137\n",
      "[LOSS] train: 7.6, val: 1.505\n",
      "[ACC%] train: 94.07%, val: 95.65%\n",
      "EPOCH: 138\n",
      "[LOSS] train: 7.568, val: 1.491\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 139\n",
      "[LOSS] train: 7.655, val: 1.479\n",
      "[ACC%] train: 92.63%, val: 98.55%\n",
      "EPOCH: 140\n",
      "[LOSS] train: 7.587, val: 1.478\n",
      "[ACC%] train: 94.23%, val: 98.55%\n",
      "EPOCH: 141\n",
      "[LOSS] train: 7.648, val: 1.477\n",
      "[ACC%] train: 92.95%, val: 98.55%\n",
      "EPOCH: 142\n",
      "[LOSS] train: 7.715, val: 1.49\n",
      "[ACC%] train: 91.83%, val: 97.1%\n",
      "EPOCH: 143\n",
      "[LOSS] train: 7.569, val: 1.492\n",
      "[ACC%] train: 94.23%, val: 97.1%\n",
      "EPOCH: 144\n",
      "[LOSS] train: 7.591, val: 1.491\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 145\n",
      "[LOSS] train: 7.586, val: 1.486\n",
      "[ACC%] train: 94.23%, val: 97.1%\n",
      "EPOCH: 146\n",
      "[LOSS] train: 7.563, val: 1.478\n",
      "[ACC%] train: 94.71%, val: 98.55%\n",
      "EPOCH: 147\n",
      "[LOSS] train: 7.614, val: 1.481\n",
      "[ACC%] train: 93.27%, val: 98.55%\n",
      "EPOCH: 148\n",
      "[LOSS] train: 7.656, val: 1.495\n",
      "[ACC%] train: 92.95%, val: 97.1%\n",
      "EPOCH: 149\n",
      "[LOSS] train: 7.616, val: 1.479\n",
      "[ACC%] train: 93.91%, val: 98.55%\n",
      "EPOCH: 150\n",
      "[LOSS] train: 7.565, val: 1.478\n",
      "[ACC%] train: 94.71%, val: 98.55%\n",
      "EPOCH: 151\n",
      "[LOSS] train: 7.554, val: 1.482\n",
      "[ACC%] train: 94.87%, val: 98.55%\n",
      "EPOCH: 152\n",
      "[LOSS] train: 7.56, val: 1.478\n",
      "[ACC%] train: 94.55%, val: 98.55%\n",
      "EPOCH: 153\n",
      "[LOSS] train: 7.549, val: 1.478\n",
      "[ACC%] train: 95.19%, val: 98.55%\n",
      "EPOCH: 154\n",
      "[LOSS] train: 7.567, val: 1.478\n",
      "[ACC%] train: 94.71%, val: 98.55%\n",
      "EPOCH: 155\n",
      "[LOSS] train: 7.587, val: 1.478\n",
      "[ACC%] train: 94.39%, val: 98.55%\n",
      "EPOCH: 156\n",
      "[LOSS] train: 7.568, val: 1.509\n",
      "[ACC%] train: 94.55%, val: 95.65%\n",
      "EPOCH: 157\n",
      "[LOSS] train: 7.626, val: 1.515\n",
      "[ACC%] train: 93.43%, val: 94.2%\n",
      "EPOCH: 158\n",
      "[LOSS] train: 7.548, val: 1.493\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 159\n",
      "[LOSS] train: 7.559, val: 1.496\n",
      "[ACC%] train: 94.71%, val: 97.1%\n",
      "EPOCH: 160\n",
      "[LOSS] train: 7.58, val: 1.493\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 161\n",
      "[LOSS] train: 7.56, val: 1.484\n",
      "[ACC%] train: 94.87%, val: 98.55%\n",
      "EPOCH: 162\n",
      "[LOSS] train: 7.583, val: 1.478\n",
      "[ACC%] train: 94.39%, val: 98.55%\n",
      "EPOCH: 163\n",
      "[LOSS] train: 7.542, val: 1.478\n",
      "[ACC%] train: 95.19%, val: 98.55%\n",
      "EPOCH: 164\n",
      "[LOSS] train: 7.598, val: 1.477\n",
      "[ACC%] train: 94.07%, val: 98.55%\n",
      "EPOCH: 165\n",
      "[LOSS] train: 7.549, val: 1.478\n",
      "[ACC%] train: 95.03%, val: 98.55%\n",
      "EPOCH: 166\n",
      "[LOSS] train: 7.537, val: 1.481\n",
      "[ACC%] train: 95.19%, val: 98.55%\n",
      "EPOCH: 167\n",
      "[LOSS] train: 7.526, val: 1.491\n",
      "[ACC%] train: 95.67%, val: 97.1%\n",
      "EPOCH: 168\n",
      "[LOSS] train: 7.579, val: 1.486\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 169\n",
      "[LOSS] train: 7.518, val: 1.485\n",
      "[ACC%] train: 95.51%, val: 97.1%\n",
      "EPOCH: 170\n",
      "[LOSS] train: 7.552, val: 1.477\n",
      "[ACC%] train: 95.19%, val: 98.55%\n",
      "EPOCH: 171\n",
      "[LOSS] train: 7.571, val: 1.477\n",
      "[ACC%] train: 94.55%, val: 98.55%\n",
      "EPOCH: 172\n",
      "[LOSS] train: 7.594, val: 1.477\n",
      "[ACC%] train: 94.07%, val: 98.55%\n",
      "EPOCH: 173\n",
      "[LOSS] train: 7.55, val: 1.483\n",
      "[ACC%] train: 95.19%, val: 98.55%\n",
      "EPOCH: 174\n",
      "[LOSS] train: 7.561, val: 1.478\n",
      "[ACC%] train: 94.87%, val: 98.55%\n",
      "EPOCH: 175\n",
      "[LOSS] train: 7.567, val: 1.478\n",
      "[ACC%] train: 94.71%, val: 98.55%\n",
      "EPOCH: 176\n",
      "[LOSS] train: 7.583, val: 1.477\n",
      "[ACC%] train: 94.23%, val: 98.55%\n",
      "EPOCH: 177\n",
      "[LOSS] train: 7.567, val: 1.491\n",
      "[ACC%] train: 94.71%, val: 97.1%\n",
      "EPOCH: 178\n",
      "[LOSS] train: 7.58, val: 1.493\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 179\n",
      "[LOSS] train: 7.565, val: 1.492\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 180\n",
      "[LOSS] train: 7.592, val: 1.499\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 181\n",
      "[LOSS] train: 7.598, val: 1.492\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 182\n",
      "[LOSS] train: 7.596, val: 1.478\n",
      "[ACC%] train: 94.23%, val: 98.55%\n",
      "EPOCH: 183\n",
      "[LOSS] train: 7.584, val: 1.478\n",
      "[ACC%] train: 94.23%, val: 98.55%\n",
      "EPOCH: 184\n",
      "[LOSS] train: 7.594, val: 1.478\n",
      "[ACC%] train: 93.91%, val: 98.55%\n",
      "EPOCH: 185\n",
      "[LOSS] train: 7.509, val: 1.478\n",
      "[ACC%] train: 95.67%, val: 98.55%\n",
      "EPOCH: 186\n",
      "[LOSS] train: 7.574, val: 1.478\n",
      "[ACC%] train: 94.55%, val: 98.55%\n",
      "EPOCH: 187\n",
      "[LOSS] train: 7.611, val: 1.493\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 188\n",
      "[LOSS] train: 7.596, val: 1.493\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 189\n",
      "[LOSS] train: 7.591, val: 1.492\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 190\n",
      "[LOSS] train: 7.563, val: 1.478\n",
      "[ACC%] train: 94.87%, val: 98.55%\n",
      "EPOCH: 191\n",
      "[LOSS] train: 7.621, val: 1.478\n",
      "[ACC%] train: 93.75%, val: 98.55%\n",
      "EPOCH: 192\n",
      "[LOSS] train: 7.563, val: 1.477\n",
      "[ACC%] train: 94.71%, val: 98.55%\n",
      "EPOCH: 193\n",
      "[LOSS] train: 7.541, val: 1.483\n",
      "[ACC%] train: 95.35%, val: 98.55%\n",
      "EPOCH: 194\n",
      "[LOSS] train: 7.599, val: 1.492\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 195\n",
      "[LOSS] train: 7.526, val: 1.492\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 196\n",
      "[LOSS] train: 7.571, val: 1.493\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 197\n",
      "[LOSS] train: 7.575, val: 1.487\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 198\n",
      "[LOSS] train: 7.59, val: 1.481\n",
      "[ACC%] train: 93.91%, val: 98.55%\n",
      "EPOCH: 199\n",
      "[LOSS] train: 7.574, val: 1.493\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "\n",
      "\n",
      "Working on 8th Fold\n",
      "EPOCH: 0\n",
      "[LOSS] train: 7.666, val: 1.461\n",
      "[ACC%] train: 92.31%, val: 100.0%\n",
      "EPOCH: 1\n",
      "[LOSS] train: 7.578, val: 1.461\n",
      "[ACC%] train: 94.55%, val: 100.0%\n",
      "EPOCH: 2\n",
      "[LOSS] train: 7.62, val: 1.461\n",
      "[ACC%] train: 93.59%, val: 100.0%\n",
      "EPOCH: 3\n",
      "[LOSS] train: 7.67, val: 1.461\n",
      "[ACC%] train: 92.95%, val: 100.0%\n",
      "EPOCH: 4\n",
      "[LOSS] train: 7.647, val: 1.461\n",
      "[ACC%] train: 93.27%, val: 100.0%\n",
      "EPOCH: 5\n",
      "[LOSS] train: 7.655, val: 1.615\n",
      "[ACC%] train: 92.79%, val: 84.06%\n",
      "EPOCH: 6\n",
      "[LOSS] train: 7.613, val: 1.679\n",
      "[ACC%] train: 94.07%, val: 76.81%\n",
      "EPOCH: 7\n",
      "[LOSS] train: 7.673, val: 1.676\n",
      "[ACC%] train: 92.31%, val: 76.81%\n",
      "EPOCH: 8\n",
      "[LOSS] train: 7.554, val: 1.461\n",
      "[ACC%] train: 95.03%, val: 100.0%\n",
      "EPOCH: 9\n",
      "[LOSS] train: 7.585, val: 1.461\n",
      "[ACC%] train: 94.23%, val: 100.0%\n",
      "EPOCH: 10\n",
      "[LOSS] train: 7.605, val: 1.461\n",
      "[ACC%] train: 94.23%, val: 100.0%\n",
      "EPOCH: 11\n",
      "[LOSS] train: 7.6, val: 1.473\n",
      "[ACC%] train: 93.91%, val: 98.55%\n",
      "EPOCH: 12\n",
      "[LOSS] train: 7.623, val: 1.464\n",
      "[ACC%] train: 93.27%, val: 100.0%\n",
      "EPOCH: 13\n",
      "[LOSS] train: 7.61, val: 1.461\n",
      "[ACC%] train: 93.59%, val: 100.0%\n",
      "EPOCH: 14\n",
      "[LOSS] train: 7.661, val: 1.461\n",
      "[ACC%] train: 92.95%, val: 100.0%\n",
      "EPOCH: 15\n",
      "[LOSS] train: 7.641, val: 1.461\n",
      "[ACC%] train: 93.27%, val: 100.0%\n",
      "EPOCH: 16\n",
      "[LOSS] train: 7.612, val: 1.461\n",
      "[ACC%] train: 93.75%, val: 100.0%\n",
      "EPOCH: 17\n",
      "[LOSS] train: 7.626, val: 1.461\n",
      "[ACC%] train: 93.43%, val: 100.0%\n",
      "EPOCH: 18\n",
      "[LOSS] train: 7.651, val: 1.461\n",
      "[ACC%] train: 92.63%, val: 100.0%\n",
      "EPOCH: 19\n",
      "[LOSS] train: 7.589, val: 1.461\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 20\n",
      "[LOSS] train: 7.615, val: 1.461\n",
      "[ACC%] train: 93.59%, val: 100.0%\n",
      "EPOCH: 21\n",
      "[LOSS] train: 7.568, val: 1.461\n",
      "[ACC%] train: 94.71%, val: 100.0%\n",
      "EPOCH: 22\n",
      "[LOSS] train: 7.665, val: 1.461\n",
      "[ACC%] train: 92.95%, val: 100.0%\n",
      "EPOCH: 23\n",
      "[LOSS] train: 7.66, val: 1.556\n",
      "[ACC%] train: 92.95%, val: 91.3%\n",
      "EPOCH: 24\n",
      "[LOSS] train: 7.638, val: 1.538\n",
      "[ACC%] train: 93.11%, val: 92.75%\n",
      "EPOCH: 25\n",
      "[LOSS] train: 7.613, val: 1.473\n",
      "[ACC%] train: 93.59%, val: 98.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 26\n",
      "[LOSS] train: 7.562, val: 1.461\n",
      "[ACC%] train: 94.87%, val: 100.0%\n",
      "EPOCH: 27\n",
      "[LOSS] train: 7.569, val: 1.461\n",
      "[ACC%] train: 94.71%, val: 100.0%\n",
      "EPOCH: 28\n",
      "[LOSS] train: 7.562, val: 1.461\n",
      "[ACC%] train: 94.87%, val: 100.0%\n",
      "EPOCH: 29\n",
      "[LOSS] train: 7.652, val: 1.461\n",
      "[ACC%] train: 92.79%, val: 100.0%\n",
      "EPOCH: 30\n",
      "[LOSS] train: 7.59, val: 1.461\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 31\n",
      "[LOSS] train: 7.645, val: 1.461\n",
      "[ACC%] train: 92.95%, val: 100.0%\n",
      "EPOCH: 32\n",
      "[LOSS] train: 7.571, val: 1.461\n",
      "[ACC%] train: 94.71%, val: 100.0%\n",
      "EPOCH: 33\n",
      "[LOSS] train: 7.646, val: 1.461\n",
      "[ACC%] train: 92.95%, val: 100.0%\n",
      "EPOCH: 34\n",
      "[LOSS] train: 7.624, val: 1.471\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 35\n",
      "[LOSS] train: 7.644, val: 1.47\n",
      "[ACC%] train: 92.95%, val: 98.55%\n",
      "EPOCH: 36\n",
      "[LOSS] train: 7.657, val: 1.472\n",
      "[ACC%] train: 93.11%, val: 98.55%\n",
      "EPOCH: 37\n",
      "[LOSS] train: 7.571, val: 1.461\n",
      "[ACC%] train: 94.55%, val: 100.0%\n",
      "EPOCH: 38\n",
      "[LOSS] train: 7.578, val: 1.461\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 39\n",
      "[LOSS] train: 7.613, val: 1.461\n",
      "[ACC%] train: 94.07%, val: 100.0%\n",
      "EPOCH: 40\n",
      "[LOSS] train: 7.638, val: 1.472\n",
      "[ACC%] train: 93.11%, val: 98.55%\n",
      "EPOCH: 41\n",
      "[LOSS] train: 7.54, val: 1.474\n",
      "[ACC%] train: 95.35%, val: 98.55%\n",
      "EPOCH: 42\n",
      "[LOSS] train: 7.622, val: 1.474\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 43\n",
      "[LOSS] train: 7.636, val: 1.476\n",
      "[ACC%] train: 93.11%, val: 98.55%\n",
      "EPOCH: 44\n",
      "[LOSS] train: 7.57, val: 1.474\n",
      "[ACC%] train: 94.55%, val: 98.55%\n",
      "EPOCH: 45\n",
      "[LOSS] train: 7.613, val: 1.473\n",
      "[ACC%] train: 93.91%, val: 98.55%\n",
      "EPOCH: 46\n",
      "[LOSS] train: 7.585, val: 1.462\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 47\n",
      "[LOSS] train: 7.554, val: 1.481\n",
      "[ACC%] train: 94.71%, val: 98.55%\n",
      "EPOCH: 48\n",
      "[LOSS] train: 7.63, val: 1.632\n",
      "[ACC%] train: 93.75%, val: 82.61%\n",
      "EPOCH: 49\n",
      "[LOSS] train: 7.564, val: 1.506\n",
      "[ACC%] train: 94.71%, val: 95.65%\n",
      "EPOCH: 50\n",
      "[LOSS] train: 7.581, val: 1.461\n",
      "[ACC%] train: 94.23%, val: 100.0%\n",
      "EPOCH: 51\n",
      "[LOSS] train: 7.616, val: 1.541\n",
      "[ACC%] train: 93.91%, val: 91.3%\n",
      "EPOCH: 52\n",
      "[LOSS] train: 7.631, val: 1.636\n",
      "[ACC%] train: 93.27%, val: 81.16%\n",
      "EPOCH: 53\n",
      "[LOSS] train: 7.594, val: 1.514\n",
      "[ACC%] train: 94.23%, val: 95.65%\n",
      "EPOCH: 54\n",
      "[LOSS] train: 7.55, val: 1.468\n",
      "[ACC%] train: 95.19%, val: 100.0%\n",
      "EPOCH: 55\n",
      "[LOSS] train: 7.617, val: 1.482\n",
      "[ACC%] train: 93.75%, val: 98.55%\n",
      "EPOCH: 56\n",
      "[LOSS] train: 7.606, val: 1.462\n",
      "[ACC%] train: 94.07%, val: 100.0%\n",
      "EPOCH: 57\n",
      "[LOSS] train: 7.599, val: 1.461\n",
      "[ACC%] train: 94.23%, val: 100.0%\n",
      "EPOCH: 58\n",
      "[LOSS] train: 7.566, val: 1.461\n",
      "[ACC%] train: 94.71%, val: 100.0%\n",
      "EPOCH: 59\n",
      "[LOSS] train: 7.613, val: 1.461\n",
      "[ACC%] train: 93.75%, val: 100.0%\n",
      "EPOCH: 60\n",
      "[LOSS] train: 7.578, val: 1.461\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 61\n",
      "[LOSS] train: 7.585, val: 1.461\n",
      "[ACC%] train: 94.07%, val: 100.0%\n",
      "EPOCH: 62\n",
      "[LOSS] train: 7.567, val: 1.461\n",
      "[ACC%] train: 94.71%, val: 100.0%\n",
      "EPOCH: 63\n",
      "[LOSS] train: 7.54, val: 1.461\n",
      "[ACC%] train: 95.19%, val: 100.0%\n",
      "EPOCH: 64\n",
      "[LOSS] train: 7.622, val: 1.461\n",
      "[ACC%] train: 93.43%, val: 100.0%\n",
      "EPOCH: 65\n",
      "[LOSS] train: 7.561, val: 1.461\n",
      "[ACC%] train: 95.03%, val: 100.0%\n",
      "EPOCH: 66\n",
      "[LOSS] train: 7.555, val: 1.461\n",
      "[ACC%] train: 94.71%, val: 100.0%\n",
      "EPOCH: 67\n",
      "[LOSS] train: 7.525, val: 1.461\n",
      "[ACC%] train: 95.51%, val: 100.0%\n",
      "EPOCH: 68\n",
      "[LOSS] train: 7.567, val: 1.461\n",
      "[ACC%] train: 94.71%, val: 100.0%\n",
      "EPOCH: 69\n",
      "[LOSS] train: 7.624, val: 1.461\n",
      "[ACC%] train: 93.59%, val: 100.0%\n",
      "EPOCH: 70\n",
      "[LOSS] train: 7.615, val: 1.461\n",
      "[ACC%] train: 93.91%, val: 100.0%\n",
      "EPOCH: 71\n",
      "[LOSS] train: 7.621, val: 1.461\n",
      "[ACC%] train: 93.91%, val: 100.0%\n",
      "EPOCH: 72\n",
      "[LOSS] train: 7.631, val: 1.461\n",
      "[ACC%] train: 93.59%, val: 100.0%\n",
      "EPOCH: 73\n",
      "[LOSS] train: 7.573, val: 1.555\n",
      "[ACC%] train: 94.55%, val: 89.86%\n",
      "EPOCH: 74\n",
      "[LOSS] train: 7.644, val: 1.461\n",
      "[ACC%] train: 92.95%, val: 100.0%\n",
      "EPOCH: 75\n",
      "[LOSS] train: 7.581, val: 1.461\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 76\n",
      "[LOSS] train: 7.592, val: 1.461\n",
      "[ACC%] train: 93.91%, val: 100.0%\n",
      "EPOCH: 77\n",
      "[LOSS] train: 7.562, val: 1.461\n",
      "[ACC%] train: 94.55%, val: 100.0%\n",
      "EPOCH: 78\n",
      "[LOSS] train: 7.582, val: 1.461\n",
      "[ACC%] train: 94.71%, val: 100.0%\n",
      "EPOCH: 79\n",
      "[LOSS] train: 7.602, val: 1.461\n",
      "[ACC%] train: 93.75%, val: 100.0%\n",
      "EPOCH: 80\n",
      "[LOSS] train: 7.669, val: 1.461\n",
      "[ACC%] train: 92.63%, val: 100.0%\n",
      "EPOCH: 81\n",
      "[LOSS] train: 7.511, val: 1.461\n",
      "[ACC%] train: 95.67%, val: 100.0%\n",
      "EPOCH: 82\n",
      "[LOSS] train: 7.606, val: 1.461\n",
      "[ACC%] train: 93.91%, val: 100.0%\n",
      "EPOCH: 83\n",
      "[LOSS] train: 7.589, val: 1.461\n",
      "[ACC%] train: 94.23%, val: 100.0%\n",
      "EPOCH: 84\n",
      "[LOSS] train: 7.562, val: 1.461\n",
      "[ACC%] train: 94.87%, val: 100.0%\n",
      "EPOCH: 85\n",
      "[LOSS] train: 7.58, val: 1.461\n",
      "[ACC%] train: 94.23%, val: 100.0%\n",
      "EPOCH: 86\n",
      "[LOSS] train: 7.491, val: 1.461\n",
      "[ACC%] train: 96.15%, val: 100.0%\n",
      "EPOCH: 87\n",
      "[LOSS] train: 7.559, val: 1.461\n",
      "[ACC%] train: 94.87%, val: 100.0%\n",
      "EPOCH: 88\n",
      "[LOSS] train: 7.579, val: 1.461\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 89\n",
      "[LOSS] train: 7.571, val: 1.461\n",
      "[ACC%] train: 94.55%, val: 100.0%\n",
      "EPOCH: 90\n",
      "[LOSS] train: 7.612, val: 1.461\n",
      "[ACC%] train: 93.59%, val: 100.0%\n",
      "EPOCH: 91\n",
      "[LOSS] train: 7.564, val: 1.461\n",
      "[ACC%] train: 94.87%, val: 100.0%\n",
      "EPOCH: 92\n",
      "[LOSS] train: 7.537, val: 1.461\n",
      "[ACC%] train: 95.35%, val: 100.0%\n",
      "EPOCH: 93\n",
      "[LOSS] train: 7.573, val: 1.461\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 94\n",
      "[LOSS] train: 7.575, val: 1.461\n",
      "[ACC%] train: 94.55%, val: 100.0%\n",
      "EPOCH: 95\n",
      "[LOSS] train: 7.608, val: 1.461\n",
      "[ACC%] train: 94.07%, val: 100.0%\n",
      "EPOCH: 96\n",
      "[LOSS] train: 7.57, val: 1.461\n",
      "[ACC%] train: 94.23%, val: 100.0%\n",
      "EPOCH: 97\n",
      "[LOSS] train: 7.578, val: 1.461\n",
      "[ACC%] train: 94.71%, val: 100.0%\n",
      "EPOCH: 98\n",
      "[LOSS] train: 7.617, val: 1.461\n",
      "[ACC%] train: 93.75%, val: 100.0%\n",
      "EPOCH: 99\n",
      "[LOSS] train: 7.614, val: 1.461\n",
      "[ACC%] train: 93.75%, val: 100.0%\n",
      "EPOCH: 100\n",
      "[LOSS] train: 7.578, val: 1.461\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 101\n",
      "[LOSS] train: 7.561, val: 1.461\n",
      "[ACC%] train: 95.03%, val: 100.0%\n",
      "EPOCH: 102\n",
      "[LOSS] train: 7.6, val: 1.461\n",
      "[ACC%] train: 94.07%, val: 100.0%\n",
      "EPOCH: 103\n",
      "[LOSS] train: 7.582, val: 1.465\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 104\n",
      "[LOSS] train: 7.533, val: 1.477\n",
      "[ACC%] train: 95.35%, val: 98.55%\n",
      "EPOCH: 105\n",
      "[LOSS] train: 7.655, val: 1.461\n",
      "[ACC%] train: 92.79%, val: 100.0%\n",
      "EPOCH: 106\n",
      "[LOSS] train: 7.599, val: 1.461\n",
      "[ACC%] train: 94.07%, val: 100.0%\n",
      "EPOCH: 107\n",
      "[LOSS] train: 7.535, val: 1.461\n",
      "[ACC%] train: 95.51%, val: 100.0%\n",
      "EPOCH: 108\n",
      "[LOSS] train: 7.612, val: 1.461\n",
      "[ACC%] train: 93.75%, val: 100.0%\n",
      "EPOCH: 109\n",
      "[LOSS] train: 7.58, val: 1.461\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 110\n",
      "[LOSS] train: 7.543, val: 1.461\n",
      "[ACC%] train: 95.19%, val: 100.0%\n",
      "EPOCH: 111\n",
      "[LOSS] train: 7.567, val: 1.461\n",
      "[ACC%] train: 95.19%, val: 100.0%\n",
      "EPOCH: 112\n",
      "[LOSS] train: 7.551, val: 1.461\n",
      "[ACC%] train: 95.03%, val: 100.0%\n",
      "EPOCH: 113\n",
      "[LOSS] train: 7.534, val: 1.461\n",
      "[ACC%] train: 95.35%, val: 100.0%\n",
      "EPOCH: 114\n",
      "[LOSS] train: 7.585, val: 1.461\n",
      "[ACC%] train: 93.91%, val: 100.0%\n",
      "EPOCH: 115\n",
      "[LOSS] train: 7.634, val: 1.461\n",
      "[ACC%] train: 93.11%, val: 100.0%\n",
      "EPOCH: 116\n",
      "[LOSS] train: 7.577, val: 1.461\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 117\n",
      "[LOSS] train: 7.623, val: 1.461\n",
      "[ACC%] train: 93.75%, val: 100.0%\n",
      "EPOCH: 118\n",
      "[LOSS] train: 7.614, val: 1.461\n",
      "[ACC%] train: 93.75%, val: 100.0%\n",
      "EPOCH: 119\n",
      "[LOSS] train: 7.647, val: 1.461\n",
      "[ACC%] train: 93.27%, val: 100.0%\n",
      "EPOCH: 120\n",
      "[LOSS] train: 7.56, val: 1.461\n",
      "[ACC%] train: 94.71%, val: 100.0%\n",
      "EPOCH: 121\n",
      "[LOSS] train: 7.569, val: 1.461\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 122\n",
      "[LOSS] train: 7.57, val: 1.461\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 123\n",
      "[LOSS] train: 7.646, val: 1.464\n",
      "[ACC%] train: 92.79%, val: 100.0%\n",
      "EPOCH: 124\n",
      "[LOSS] train: 7.624, val: 1.49\n",
      "[ACC%] train: 93.43%, val: 97.1%\n",
      "EPOCH: 125\n",
      "[LOSS] train: 7.657, val: 1.476\n",
      "[ACC%] train: 92.63%, val: 98.55%\n",
      "EPOCH: 126\n",
      "[LOSS] train: 7.613, val: 1.47\n",
      "[ACC%] train: 93.59%, val: 98.55%\n",
      "EPOCH: 127\n",
      "[LOSS] train: 7.538, val: 1.461\n",
      "[ACC%] train: 95.35%, val: 100.0%\n",
      "EPOCH: 128\n",
      "[LOSS] train: 7.56, val: 1.461\n",
      "[ACC%] train: 94.87%, val: 100.0%\n",
      "EPOCH: 129\n",
      "[LOSS] train: 7.498, val: 1.461\n",
      "[ACC%] train: 96.15%, val: 100.0%\n",
      "EPOCH: 130\n",
      "[LOSS] train: 7.525, val: 1.461\n",
      "[ACC%] train: 95.51%, val: 100.0%\n",
      "EPOCH: 131\n",
      "[LOSS] train: 7.584, val: 1.461\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 132\n",
      "[LOSS] train: 7.562, val: 1.461\n",
      "[ACC%] train: 94.87%, val: 100.0%\n",
      "EPOCH: 133\n",
      "[LOSS] train: 7.533, val: 1.461\n",
      "[ACC%] train: 95.67%, val: 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 134\n",
      "[LOSS] train: 7.538, val: 1.461\n",
      "[ACC%] train: 95.19%, val: 100.0%\n",
      "EPOCH: 135\n",
      "[LOSS] train: 7.551, val: 1.461\n",
      "[ACC%] train: 94.87%, val: 100.0%\n",
      "EPOCH: 136\n",
      "[LOSS] train: 7.55, val: 1.461\n",
      "[ACC%] train: 95.03%, val: 100.0%\n",
      "EPOCH: 137\n",
      "[LOSS] train: 7.546, val: 1.461\n",
      "[ACC%] train: 95.19%, val: 100.0%\n",
      "EPOCH: 138\n",
      "[LOSS] train: 7.566, val: 1.497\n",
      "[ACC%] train: 94.71%, val: 95.65%\n",
      "EPOCH: 139\n",
      "[LOSS] train: 7.521, val: 1.501\n",
      "[ACC%] train: 95.67%, val: 95.65%\n",
      "EPOCH: 140\n",
      "[LOSS] train: 7.553, val: 1.491\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 141\n",
      "[LOSS] train: 7.612, val: 1.484\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 142\n",
      "[LOSS] train: 7.556, val: 1.461\n",
      "[ACC%] train: 94.55%, val: 100.0%\n",
      "EPOCH: 143\n",
      "[LOSS] train: 7.607, val: 1.461\n",
      "[ACC%] train: 93.91%, val: 100.0%\n",
      "EPOCH: 144\n",
      "[LOSS] train: 7.546, val: 1.461\n",
      "[ACC%] train: 94.87%, val: 100.0%\n",
      "EPOCH: 145\n",
      "[LOSS] train: 7.592, val: 1.461\n",
      "[ACC%] train: 94.07%, val: 100.0%\n",
      "EPOCH: 146\n",
      "[LOSS] train: 7.582, val: 1.461\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 147\n",
      "[LOSS] train: 7.614, val: 1.461\n",
      "[ACC%] train: 93.91%, val: 100.0%\n",
      "EPOCH: 148\n",
      "[LOSS] train: 7.64, val: 1.461\n",
      "[ACC%] train: 93.43%, val: 100.0%\n",
      "EPOCH: 149\n",
      "[LOSS] train: 7.583, val: 1.461\n",
      "[ACC%] train: 94.23%, val: 100.0%\n",
      "EPOCH: 150\n",
      "[LOSS] train: 7.572, val: 1.478\n",
      "[ACC%] train: 94.71%, val: 98.55%\n",
      "EPOCH: 151\n",
      "[LOSS] train: 7.575, val: 1.477\n",
      "[ACC%] train: 94.39%, val: 98.55%\n",
      "EPOCH: 152\n",
      "[LOSS] train: 7.564, val: 1.466\n",
      "[ACC%] train: 94.55%, val: 100.0%\n",
      "EPOCH: 153\n",
      "[LOSS] train: 7.534, val: 1.472\n",
      "[ACC%] train: 95.19%, val: 98.55%\n",
      "EPOCH: 154\n",
      "[LOSS] train: 7.606, val: 1.48\n",
      "[ACC%] train: 93.43%, val: 98.55%\n",
      "EPOCH: 155\n",
      "[LOSS] train: 7.598, val: 1.475\n",
      "[ACC%] train: 94.07%, val: 98.55%\n",
      "EPOCH: 156\n",
      "[LOSS] train: 7.568, val: 1.461\n",
      "[ACC%] train: 94.71%, val: 100.0%\n",
      "EPOCH: 157\n",
      "[LOSS] train: 7.614, val: 1.461\n",
      "[ACC%] train: 93.59%, val: 100.0%\n",
      "EPOCH: 158\n",
      "[LOSS] train: 7.571, val: 1.48\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 159\n",
      "[LOSS] train: 7.559, val: 1.485\n",
      "[ACC%] train: 94.71%, val: 97.1%\n",
      "EPOCH: 160\n",
      "[LOSS] train: 7.589, val: 1.47\n",
      "[ACC%] train: 94.39%, val: 98.55%\n",
      "EPOCH: 161\n",
      "[LOSS] train: 7.588, val: 1.463\n",
      "[ACC%] train: 94.07%, val: 100.0%\n",
      "EPOCH: 162\n",
      "[LOSS] train: 7.589, val: 1.461\n",
      "[ACC%] train: 94.23%, val: 100.0%\n",
      "EPOCH: 163\n",
      "[LOSS] train: 7.559, val: 1.461\n",
      "[ACC%] train: 94.71%, val: 100.0%\n",
      "EPOCH: 164\n",
      "[LOSS] train: 7.496, val: 1.472\n",
      "[ACC%] train: 96.15%, val: 98.55%\n",
      "EPOCH: 165\n",
      "[LOSS] train: 7.58, val: 1.468\n",
      "[ACC%] train: 94.39%, val: 98.55%\n",
      "EPOCH: 166\n",
      "[LOSS] train: 7.631, val: 1.475\n",
      "[ACC%] train: 93.27%, val: 98.55%\n",
      "EPOCH: 167\n",
      "[LOSS] train: 7.625, val: 1.461\n",
      "[ACC%] train: 92.95%, val: 100.0%\n",
      "EPOCH: 168\n",
      "[LOSS] train: 7.544, val: 1.461\n",
      "[ACC%] train: 95.03%, val: 100.0%\n",
      "EPOCH: 169\n",
      "[LOSS] train: 7.591, val: 1.476\n",
      "[ACC%] train: 94.39%, val: 98.55%\n",
      "EPOCH: 170\n",
      "[LOSS] train: 7.559, val: 1.477\n",
      "[ACC%] train: 94.39%, val: 98.55%\n",
      "EPOCH: 171\n",
      "[LOSS] train: 7.529, val: 1.519\n",
      "[ACC%] train: 95.19%, val: 92.75%\n",
      "EPOCH: 172\n",
      "[LOSS] train: 7.552, val: 1.476\n",
      "[ACC%] train: 94.71%, val: 98.55%\n",
      "EPOCH: 173\n",
      "[LOSS] train: 7.546, val: 1.461\n",
      "[ACC%] train: 95.03%, val: 100.0%\n",
      "EPOCH: 174\n",
      "[LOSS] train: 7.507, val: 1.461\n",
      "[ACC%] train: 95.83%, val: 100.0%\n",
      "EPOCH: 175\n",
      "[LOSS] train: 7.58, val: 1.461\n",
      "[ACC%] train: 94.55%, val: 100.0%\n",
      "EPOCH: 176\n",
      "[LOSS] train: 7.511, val: 1.49\n",
      "[ACC%] train: 96.15%, val: 97.1%\n",
      "EPOCH: 177\n",
      "[LOSS] train: 7.586, val: 1.508\n",
      "[ACC%] train: 94.23%, val: 95.65%\n",
      "EPOCH: 178\n",
      "[LOSS] train: 7.547, val: 1.498\n",
      "[ACC%] train: 94.87%, val: 95.65%\n",
      "EPOCH: 179\n",
      "[LOSS] train: 7.55, val: 1.47\n",
      "[ACC%] train: 95.35%, val: 100.0%\n",
      "EPOCH: 180\n",
      "[LOSS] train: 7.592, val: 1.461\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 181\n",
      "[LOSS] train: 7.532, val: 1.461\n",
      "[ACC%] train: 95.67%, val: 100.0%\n",
      "EPOCH: 182\n",
      "[LOSS] train: 7.592, val: 1.461\n",
      "[ACC%] train: 94.07%, val: 100.0%\n",
      "EPOCH: 183\n",
      "[LOSS] train: 7.54, val: 1.461\n",
      "[ACC%] train: 95.19%, val: 100.0%\n",
      "EPOCH: 184\n",
      "[LOSS] train: 7.584, val: 1.461\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 185\n",
      "[LOSS] train: 7.557, val: 1.461\n",
      "[ACC%] train: 94.87%, val: 100.0%\n",
      "EPOCH: 186\n",
      "[LOSS] train: 7.535, val: 1.461\n",
      "[ACC%] train: 95.03%, val: 100.0%\n",
      "EPOCH: 187\n",
      "[LOSS] train: 7.532, val: 1.461\n",
      "[ACC%] train: 95.67%, val: 100.0%\n",
      "EPOCH: 188\n",
      "[LOSS] train: 7.568, val: 1.461\n",
      "[ACC%] train: 94.71%, val: 100.0%\n",
      "EPOCH: 189\n",
      "[LOSS] train: 7.511, val: 1.463\n",
      "[ACC%] train: 95.51%, val: 100.0%\n",
      "EPOCH: 190\n",
      "[LOSS] train: 7.507, val: 1.461\n",
      "[ACC%] train: 95.83%, val: 100.0%\n",
      "EPOCH: 191\n",
      "[LOSS] train: 7.565, val: 1.461\n",
      "[ACC%] train: 94.55%, val: 100.0%\n",
      "EPOCH: 192\n",
      "[LOSS] train: 7.58, val: 1.461\n",
      "[ACC%] train: 94.23%, val: 100.0%\n",
      "EPOCH: 193\n",
      "[LOSS] train: 7.568, val: 1.461\n",
      "[ACC%] train: 94.87%, val: 100.0%\n",
      "EPOCH: 194\n",
      "[LOSS] train: 7.565, val: 1.461\n",
      "[ACC%] train: 94.39%, val: 100.0%\n",
      "EPOCH: 195\n",
      "[LOSS] train: 7.542, val: 1.461\n",
      "[ACC%] train: 95.03%, val: 100.0%\n",
      "EPOCH: 196\n",
      "[LOSS] train: 7.566, val: 1.461\n",
      "[ACC%] train: 94.87%, val: 100.0%\n",
      "EPOCH: 197\n",
      "[LOSS] train: 7.5, val: 1.461\n",
      "[ACC%] train: 96.15%, val: 100.0%\n",
      "EPOCH: 198\n",
      "[LOSS] train: 7.584, val: 1.461\n",
      "[ACC%] train: 94.07%, val: 100.0%\n",
      "EPOCH: 199\n",
      "[LOSS] train: 7.584, val: 1.474\n",
      "[ACC%] train: 94.23%, val: 98.55%\n",
      "\n",
      "\n",
      "Working on 9th Fold\n",
      "EPOCH: 0\n",
      "[LOSS] train: 7.611, val: 1.489\n",
      "[ACC%] train: 93.11%, val: 97.1%\n",
      "EPOCH: 1\n",
      "[LOSS] train: 7.666, val: 1.489\n",
      "[ACC%] train: 92.95%, val: 97.1%\n",
      "EPOCH: 2\n",
      "[LOSS] train: 7.573, val: 1.488\n",
      "[ACC%] train: 94.71%, val: 97.1%\n",
      "EPOCH: 3\n",
      "[LOSS] train: 7.615, val: 1.489\n",
      "[ACC%] train: 93.75%, val: 97.1%\n",
      "EPOCH: 4\n",
      "[LOSS] train: 7.57, val: 1.489\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 5\n",
      "[LOSS] train: 7.554, val: 1.489\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 6\n",
      "[LOSS] train: 7.633, val: 1.489\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 7\n",
      "[LOSS] train: 7.575, val: 1.489\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 8\n",
      "[LOSS] train: 7.583, val: 1.489\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 9\n",
      "[LOSS] train: 7.619, val: 1.489\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 10\n",
      "[LOSS] train: 7.534, val: 1.489\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 11\n",
      "[LOSS] train: 7.628, val: 1.488\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 12\n",
      "[LOSS] train: 7.559, val: 1.489\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 13\n",
      "[LOSS] train: 7.601, val: 1.488\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 14\n",
      "[LOSS] train: 7.549, val: 1.489\n",
      "[ACC%] train: 95.19%, val: 97.1%\n",
      "EPOCH: 15\n",
      "[LOSS] train: 7.643, val: 1.489\n",
      "[ACC%] train: 93.27%, val: 97.1%\n",
      "EPOCH: 16\n",
      "[LOSS] train: 7.583, val: 1.489\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 17\n",
      "[LOSS] train: 7.567, val: 1.489\n",
      "[ACC%] train: 94.71%, val: 97.1%\n",
      "EPOCH: 18\n",
      "[LOSS] train: 7.596, val: 1.489\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 19\n",
      "[LOSS] train: 7.542, val: 1.489\n",
      "[ACC%] train: 95.19%, val: 97.1%\n",
      "EPOCH: 20\n",
      "[LOSS] train: 7.654, val: 1.489\n",
      "[ACC%] train: 93.27%, val: 97.1%\n",
      "EPOCH: 21\n",
      "[LOSS] train: 7.607, val: 1.488\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 22\n",
      "[LOSS] train: 7.614, val: 1.488\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 23\n",
      "[LOSS] train: 7.555, val: 1.489\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 24\n",
      "[LOSS] train: 7.716, val: 1.488\n",
      "[ACC%] train: 91.83%, val: 97.1%\n",
      "EPOCH: 25\n",
      "[LOSS] train: 7.62, val: 1.488\n",
      "[ACC%] train: 92.95%, val: 97.1%\n",
      "EPOCH: 26\n",
      "[LOSS] train: 7.599, val: 1.488\n",
      "[ACC%] train: 94.23%, val: 97.1%\n",
      "EPOCH: 27\n",
      "[LOSS] train: 7.58, val: 1.488\n",
      "[ACC%] train: 94.23%, val: 97.1%\n",
      "EPOCH: 28\n",
      "[LOSS] train: 7.524, val: 1.488\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 29\n",
      "[LOSS] train: 7.557, val: 1.488\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 30\n",
      "[LOSS] train: 7.569, val: 1.488\n",
      "[ACC%] train: 94.71%, val: 97.1%\n",
      "EPOCH: 31\n",
      "[LOSS] train: 7.566, val: 1.489\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 32\n",
      "[LOSS] train: 7.516, val: 1.489\n",
      "[ACC%] train: 95.83%, val: 97.1%\n",
      "EPOCH: 33\n",
      "[LOSS] train: 7.497, val: 1.489\n",
      "[ACC%] train: 96.31%, val: 97.1%\n",
      "EPOCH: 34\n",
      "[LOSS] train: 7.559, val: 1.489\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 35\n",
      "[LOSS] train: 7.531, val: 1.489\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 36\n",
      "[LOSS] train: 7.541, val: 1.489\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 37\n",
      "[LOSS] train: 7.523, val: 1.489\n",
      "[ACC%] train: 95.51%, val: 97.1%\n",
      "EPOCH: 38\n",
      "[LOSS] train: 7.558, val: 1.489\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 39\n",
      "[LOSS] train: 7.572, val: 1.489\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 40\n",
      "[LOSS] train: 7.568, val: 1.489\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 41\n",
      "[LOSS] train: 7.559, val: 1.489\n",
      "[ACC%] train: 94.71%, val: 97.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 42\n",
      "[LOSS] train: 7.56, val: 1.489\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 43\n",
      "[LOSS] train: 7.557, val: 1.489\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 44\n",
      "[LOSS] train: 7.58, val: 1.489\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 45\n",
      "[LOSS] train: 7.51, val: 1.488\n",
      "[ACC%] train: 95.83%, val: 97.1%\n",
      "EPOCH: 46\n",
      "[LOSS] train: 7.546, val: 1.489\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 47\n",
      "[LOSS] train: 7.62, val: 1.488\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 48\n",
      "[LOSS] train: 7.598, val: 1.488\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 49\n",
      "[LOSS] train: 7.583, val: 1.489\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 50\n",
      "[LOSS] train: 7.611, val: 1.488\n",
      "[ACC%] train: 93.75%, val: 97.1%\n",
      "EPOCH: 51\n",
      "[LOSS] train: 7.558, val: 1.489\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 52\n",
      "[LOSS] train: 7.511, val: 1.5\n",
      "[ACC%] train: 95.99%, val: 95.65%\n",
      "EPOCH: 53\n",
      "[LOSS] train: 7.521, val: 1.501\n",
      "[ACC%] train: 95.67%, val: 95.65%\n",
      "EPOCH: 54\n",
      "[LOSS] train: 7.543, val: 1.497\n",
      "[ACC%] train: 95.19%, val: 95.65%\n",
      "EPOCH: 55\n",
      "[LOSS] train: 7.586, val: 1.49\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 56\n",
      "[LOSS] train: 7.573, val: 1.488\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 57\n",
      "[LOSS] train: 7.547, val: 1.489\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 58\n",
      "[LOSS] train: 7.544, val: 1.488\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 59\n",
      "[LOSS] train: 7.558, val: 1.489\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 60\n",
      "[LOSS] train: 7.548, val: 1.489\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 61\n",
      "[LOSS] train: 7.597, val: 1.489\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 62\n",
      "[LOSS] train: 7.548, val: 1.489\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 63\n",
      "[LOSS] train: 7.569, val: 1.489\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 64\n",
      "[LOSS] train: 7.559, val: 1.489\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 65\n",
      "[LOSS] train: 7.54, val: 1.488\n",
      "[ACC%] train: 95.51%, val: 97.1%\n",
      "EPOCH: 66\n",
      "[LOSS] train: 7.573, val: 1.489\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 67\n",
      "[LOSS] train: 7.563, val: 1.501\n",
      "[ACC%] train: 94.87%, val: 95.65%\n",
      "EPOCH: 68\n",
      "[LOSS] train: 7.546, val: 1.489\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 69\n",
      "[LOSS] train: 7.591, val: 1.489\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 70\n",
      "[LOSS] train: 7.593, val: 1.488\n",
      "[ACC%] train: 94.23%, val: 97.1%\n",
      "EPOCH: 71\n",
      "[LOSS] train: 7.566, val: 1.488\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 72\n",
      "[LOSS] train: 7.558, val: 1.488\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 73\n",
      "[LOSS] train: 7.571, val: 1.488\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 74\n",
      "[LOSS] train: 7.481, val: 1.49\n",
      "[ACC%] train: 96.63%, val: 97.1%\n",
      "EPOCH: 75\n",
      "[LOSS] train: 7.502, val: 1.503\n",
      "[ACC%] train: 96.15%, val: 95.65%\n",
      "EPOCH: 76\n",
      "[LOSS] train: 7.629, val: 1.503\n",
      "[ACC%] train: 93.59%, val: 95.65%\n",
      "EPOCH: 77\n",
      "[LOSS] train: 7.513, val: 1.489\n",
      "[ACC%] train: 95.99%, val: 97.1%\n",
      "EPOCH: 78\n",
      "[LOSS] train: 7.513, val: 1.488\n",
      "[ACC%] train: 95.83%, val: 97.1%\n",
      "EPOCH: 79\n",
      "[LOSS] train: 7.505, val: 1.488\n",
      "[ACC%] train: 95.83%, val: 97.1%\n",
      "EPOCH: 80\n",
      "[LOSS] train: 7.487, val: 1.489\n",
      "[ACC%] train: 96.31%, val: 97.1%\n",
      "EPOCH: 81\n",
      "[LOSS] train: 7.574, val: 1.489\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 82\n",
      "[LOSS] train: 7.531, val: 1.489\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 83\n",
      "[LOSS] train: 7.579, val: 1.489\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 84\n",
      "[LOSS] train: 7.532, val: 1.499\n",
      "[ACC%] train: 95.51%, val: 95.65%\n",
      "EPOCH: 85\n",
      "[LOSS] train: 7.534, val: 1.503\n",
      "[ACC%] train: 95.51%, val: 95.65%\n",
      "EPOCH: 86\n",
      "[LOSS] train: 7.529, val: 1.503\n",
      "[ACC%] train: 95.67%, val: 95.65%\n",
      "EPOCH: 87\n",
      "[LOSS] train: 7.528, val: 1.503\n",
      "[ACC%] train: 95.83%, val: 95.65%\n",
      "EPOCH: 88\n",
      "[LOSS] train: 7.505, val: 1.502\n",
      "[ACC%] train: 95.83%, val: 95.65%\n",
      "EPOCH: 89\n",
      "[LOSS] train: 7.557, val: 1.489\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 90\n",
      "[LOSS] train: 7.551, val: 1.488\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 91\n",
      "[LOSS] train: 7.603, val: 1.524\n",
      "[ACC%] train: 93.91%, val: 92.75%\n",
      "EPOCH: 92\n",
      "[LOSS] train: 7.595, val: 1.515\n",
      "[ACC%] train: 93.91%, val: 94.2%\n",
      "EPOCH: 93\n",
      "[LOSS] train: 7.589, val: 1.568\n",
      "[ACC%] train: 94.39%, val: 88.41%\n",
      "EPOCH: 94\n",
      "[LOSS] train: 7.574, val: 1.592\n",
      "[ACC%] train: 94.55%, val: 85.51%\n",
      "EPOCH: 95\n",
      "[LOSS] train: 7.522, val: 1.628\n",
      "[ACC%] train: 95.35%, val: 82.61%\n",
      "EPOCH: 96\n",
      "[LOSS] train: 7.53, val: 1.504\n",
      "[ACC%] train: 95.19%, val: 95.65%\n",
      "EPOCH: 97\n",
      "[LOSS] train: 7.563, val: 1.488\n",
      "[ACC%] train: 94.71%, val: 97.1%\n",
      "EPOCH: 98\n",
      "[LOSS] train: 7.617, val: 1.488\n",
      "[ACC%] train: 93.59%, val: 97.1%\n",
      "EPOCH: 99\n",
      "[LOSS] train: 7.576, val: 1.488\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 100\n",
      "[LOSS] train: 7.605, val: 1.488\n",
      "[ACC%] train: 93.75%, val: 97.1%\n",
      "EPOCH: 101\n",
      "[LOSS] train: 7.554, val: 1.488\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 102\n",
      "[LOSS] train: 7.516, val: 1.493\n",
      "[ACC%] train: 95.83%, val: 97.1%\n",
      "EPOCH: 103\n",
      "[LOSS] train: 7.569, val: 1.489\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 104\n",
      "[LOSS] train: 7.559, val: 1.507\n",
      "[ACC%] train: 95.03%, val: 95.65%\n",
      "EPOCH: 105\n",
      "[LOSS] train: 7.565, val: 1.488\n",
      "[ACC%] train: 94.71%, val: 97.1%\n",
      "EPOCH: 106\n",
      "[LOSS] train: 7.526, val: 1.489\n",
      "[ACC%] train: 95.51%, val: 97.1%\n",
      "EPOCH: 107\n",
      "[LOSS] train: 7.481, val: 1.501\n",
      "[ACC%] train: 96.63%, val: 95.65%\n",
      "EPOCH: 108\n",
      "[LOSS] train: 7.595, val: 1.488\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 109\n",
      "[LOSS] train: 7.551, val: 1.493\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 110\n",
      "[LOSS] train: 7.551, val: 1.501\n",
      "[ACC%] train: 94.87%, val: 95.65%\n",
      "EPOCH: 111\n",
      "[LOSS] train: 7.528, val: 1.492\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 112\n",
      "[LOSS] train: 7.534, val: 1.488\n",
      "[ACC%] train: 95.67%, val: 97.1%\n",
      "EPOCH: 113\n",
      "[LOSS] train: 7.585, val: 1.488\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 114\n",
      "[LOSS] train: 7.591, val: 1.514\n",
      "[ACC%] train: 94.07%, val: 94.2%\n",
      "EPOCH: 115\n",
      "[LOSS] train: 7.615, val: 1.515\n",
      "[ACC%] train: 93.59%, val: 94.2%\n",
      "EPOCH: 116\n",
      "[LOSS] train: 7.582, val: 1.53\n",
      "[ACC%] train: 94.23%, val: 92.75%\n",
      "EPOCH: 117\n",
      "[LOSS] train: 7.59, val: 1.538\n",
      "[ACC%] train: 94.23%, val: 92.75%\n",
      "EPOCH: 118\n",
      "[LOSS] train: 7.585, val: 1.56\n",
      "[ACC%] train: 94.39%, val: 88.41%\n",
      "EPOCH: 119\n",
      "[LOSS] train: 7.585, val: 1.515\n",
      "[ACC%] train: 94.55%, val: 94.2%\n",
      "EPOCH: 120\n",
      "[LOSS] train: 7.543, val: 1.498\n",
      "[ACC%] train: 95.03%, val: 95.65%\n",
      "EPOCH: 121\n",
      "[LOSS] train: 7.536, val: 1.489\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 122\n",
      "[LOSS] train: 7.589, val: 1.489\n",
      "[ACC%] train: 94.71%, val: 97.1%\n",
      "EPOCH: 123\n",
      "[LOSS] train: 7.525, val: 1.516\n",
      "[ACC%] train: 95.67%, val: 94.2%\n",
      "EPOCH: 124\n",
      "[LOSS] train: 7.553, val: 1.501\n",
      "[ACC%] train: 94.71%, val: 95.65%\n",
      "EPOCH: 125\n",
      "[LOSS] train: 7.617, val: 1.488\n",
      "[ACC%] train: 93.75%, val: 97.1%\n",
      "EPOCH: 126\n",
      "[LOSS] train: 7.581, val: 1.488\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 127\n",
      "[LOSS] train: 7.571, val: 1.489\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 128\n",
      "[LOSS] train: 7.58, val: 1.488\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 129\n",
      "[LOSS] train: 7.537, val: 1.489\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 130\n",
      "[LOSS] train: 7.514, val: 1.508\n",
      "[ACC%] train: 95.83%, val: 95.65%\n",
      "EPOCH: 131\n",
      "[LOSS] train: 7.498, val: 1.503\n",
      "[ACC%] train: 96.15%, val: 95.65%\n",
      "EPOCH: 132\n",
      "[LOSS] train: 7.584, val: 1.503\n",
      "[ACC%] train: 94.55%, val: 95.65%\n",
      "EPOCH: 133\n",
      "[LOSS] train: 7.534, val: 1.504\n",
      "[ACC%] train: 95.35%, val: 95.65%\n",
      "EPOCH: 134\n",
      "[LOSS] train: 7.541, val: 1.492\n",
      "[ACC%] train: 95.19%, val: 97.1%\n",
      "EPOCH: 135\n",
      "[LOSS] train: 7.565, val: 1.515\n",
      "[ACC%] train: 94.87%, val: 94.2%\n",
      "EPOCH: 136\n",
      "[LOSS] train: 7.52, val: 1.507\n",
      "[ACC%] train: 95.51%, val: 95.65%\n",
      "EPOCH: 137\n",
      "[LOSS] train: 7.509, val: 1.488\n",
      "[ACC%] train: 95.67%, val: 97.1%\n",
      "EPOCH: 138\n",
      "[LOSS] train: 7.507, val: 1.489\n",
      "[ACC%] train: 95.99%, val: 97.1%\n",
      "EPOCH: 139\n",
      "[LOSS] train: 7.494, val: 1.489\n",
      "[ACC%] train: 96.15%, val: 97.1%\n",
      "EPOCH: 140\n",
      "[LOSS] train: 7.534, val: 1.488\n",
      "[ACC%] train: 95.51%, val: 97.1%\n",
      "EPOCH: 141\n",
      "[LOSS] train: 7.533, val: 1.489\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 142\n",
      "[LOSS] train: 7.46, val: 1.493\n",
      "[ACC%] train: 96.96%, val: 97.1%\n",
      "EPOCH: 143\n",
      "[LOSS] train: 7.563, val: 1.489\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 144\n",
      "[LOSS] train: 7.528, val: 1.488\n",
      "[ACC%] train: 95.51%, val: 97.1%\n",
      "EPOCH: 145\n",
      "[LOSS] train: 7.611, val: 1.488\n",
      "[ACC%] train: 93.91%, val: 97.1%\n",
      "EPOCH: 146\n",
      "[LOSS] train: 7.533, val: 1.488\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 147\n",
      "[LOSS] train: 7.56, val: 1.488\n",
      "[ACC%] train: 94.71%, val: 97.1%\n",
      "EPOCH: 148\n",
      "[LOSS] train: 7.547, val: 1.489\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 149\n",
      "[LOSS] train: 7.552, val: 1.489\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 150\n",
      "[LOSS] train: 7.468, val: 1.489\n",
      "[ACC%] train: 96.47%, val: 97.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 151\n",
      "[LOSS] train: 7.514, val: 1.489\n",
      "[ACC%] train: 95.67%, val: 97.1%\n",
      "EPOCH: 152\n",
      "[LOSS] train: 7.504, val: 1.488\n",
      "[ACC%] train: 95.99%, val: 97.1%\n",
      "EPOCH: 153\n",
      "[LOSS] train: 7.557, val: 1.488\n",
      "[ACC%] train: 94.71%, val: 97.1%\n",
      "EPOCH: 154\n",
      "[LOSS] train: 7.528, val: 1.489\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 155\n",
      "[LOSS] train: 7.544, val: 1.489\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 156\n",
      "[LOSS] train: 7.556, val: 1.499\n",
      "[ACC%] train: 94.87%, val: 95.65%\n",
      "EPOCH: 157\n",
      "[LOSS] train: 7.543, val: 1.489\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 158\n",
      "[LOSS] train: 7.496, val: 1.503\n",
      "[ACC%] train: 95.99%, val: 95.65%\n",
      "EPOCH: 159\n",
      "[LOSS] train: 7.483, val: 1.544\n",
      "[ACC%] train: 96.47%, val: 91.3%\n",
      "EPOCH: 160\n",
      "[LOSS] train: 7.567, val: 1.556\n",
      "[ACC%] train: 94.39%, val: 89.86%\n",
      "EPOCH: 161\n",
      "[LOSS] train: 7.543, val: 1.57\n",
      "[ACC%] train: 95.19%, val: 86.96%\n",
      "EPOCH: 162\n",
      "[LOSS] train: 7.537, val: 1.517\n",
      "[ACC%] train: 95.35%, val: 94.2%\n",
      "EPOCH: 163\n",
      "[LOSS] train: 7.543, val: 1.489\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 164\n",
      "[LOSS] train: 7.53, val: 1.495\n",
      "[ACC%] train: 95.35%, val: 95.65%\n",
      "EPOCH: 165\n",
      "[LOSS] train: 7.475, val: 1.489\n",
      "[ACC%] train: 96.63%, val: 97.1%\n",
      "EPOCH: 166\n",
      "[LOSS] train: 7.589, val: 1.489\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 167\n",
      "[LOSS] train: 7.54, val: 1.488\n",
      "[ACC%] train: 95.19%, val: 97.1%\n",
      "EPOCH: 168\n",
      "[LOSS] train: 7.525, val: 1.488\n",
      "[ACC%] train: 95.35%, val: 97.1%\n",
      "EPOCH: 169\n",
      "[LOSS] train: 7.57, val: 1.489\n",
      "[ACC%] train: 94.39%, val: 97.1%\n",
      "EPOCH: 170\n",
      "[LOSS] train: 7.557, val: 1.489\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 171\n",
      "[LOSS] train: 7.543, val: 1.489\n",
      "[ACC%] train: 95.19%, val: 97.1%\n",
      "EPOCH: 172\n",
      "[LOSS] train: 7.553, val: 1.488\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 173\n",
      "[LOSS] train: 7.585, val: 1.489\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 174\n",
      "[LOSS] train: 7.501, val: 1.488\n",
      "[ACC%] train: 95.99%, val: 97.1%\n",
      "EPOCH: 175\n",
      "[LOSS] train: 7.572, val: 1.489\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 176\n",
      "[LOSS] train: 7.567, val: 1.489\n",
      "[ACC%] train: 94.71%, val: 97.1%\n",
      "EPOCH: 177\n",
      "[LOSS] train: 7.492, val: 1.488\n",
      "[ACC%] train: 96.15%, val: 97.1%\n",
      "EPOCH: 178\n",
      "[LOSS] train: 7.487, val: 1.488\n",
      "[ACC%] train: 96.63%, val: 97.1%\n",
      "EPOCH: 179\n",
      "[LOSS] train: 7.586, val: 1.488\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 180\n",
      "[LOSS] train: 7.604, val: 1.489\n",
      "[ACC%] train: 94.07%, val: 97.1%\n",
      "EPOCH: 181\n",
      "[LOSS] train: 7.587, val: 1.488\n",
      "[ACC%] train: 94.55%, val: 97.1%\n",
      "EPOCH: 182\n",
      "[LOSS] train: 7.555, val: 1.488\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 183\n",
      "[LOSS] train: 7.552, val: 1.489\n",
      "[ACC%] train: 94.87%, val: 97.1%\n",
      "EPOCH: 184\n",
      "[LOSS] train: 7.553, val: 1.489\n",
      "[ACC%] train: 95.19%, val: 97.1%\n",
      "EPOCH: 185\n",
      "[LOSS] train: 7.502, val: 1.491\n",
      "[ACC%] train: 95.99%, val: 97.1%\n",
      "EPOCH: 186\n",
      "[LOSS] train: 7.516, val: 1.501\n",
      "[ACC%] train: 95.67%, val: 95.65%\n",
      "EPOCH: 187\n",
      "[LOSS] train: 7.509, val: 1.499\n",
      "[ACC%] train: 95.83%, val: 95.65%\n",
      "EPOCH: 188\n",
      "[LOSS] train: 7.496, val: 1.49\n",
      "[ACC%] train: 95.99%, val: 97.1%\n",
      "EPOCH: 189\n",
      "[LOSS] train: 7.511, val: 1.498\n",
      "[ACC%] train: 95.99%, val: 95.65%\n",
      "EPOCH: 190\n",
      "[LOSS] train: 7.518, val: 1.488\n",
      "[ACC%] train: 95.51%, val: 97.1%\n",
      "EPOCH: 191\n",
      "[LOSS] train: 7.561, val: 1.489\n",
      "[ACC%] train: 95.03%, val: 97.1%\n",
      "EPOCH: 192\n",
      "[LOSS] train: 7.539, val: 1.489\n",
      "[ACC%] train: 95.19%, val: 97.1%\n",
      "EPOCH: 193\n",
      "[LOSS] train: 7.522, val: 1.489\n",
      "[ACC%] train: 95.99%, val: 97.1%\n",
      "EPOCH: 194\n",
      "[LOSS] train: 7.516, val: 1.489\n",
      "[ACC%] train: 95.67%, val: 97.1%\n",
      "EPOCH: 195\n",
      "[LOSS] train: 7.538, val: 1.489\n",
      "[ACC%] train: 95.19%, val: 97.1%\n",
      "EPOCH: 196\n",
      "[LOSS] train: 7.545, val: 1.495\n",
      "[ACC%] train: 95.03%, val: 95.65%\n",
      "EPOCH: 197\n",
      "[LOSS] train: 7.571, val: 1.514\n",
      "[ACC%] train: 94.55%, val: 94.2%\n",
      "EPOCH: 198\n",
      "[LOSS] train: 7.556, val: 1.523\n",
      "[ACC%] train: 94.71%, val: 92.75%\n",
      "EPOCH: 199\n",
      "[LOSS] train: 7.59, val: 1.532\n",
      "[ACC%] train: 94.07%, val: 92.75%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conv = ConvNet(ctype='multi')\n",
    "\n",
    "EPOCHS = range(200)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=torch.FloatTensor(multi_weight))\n",
    "optimizer = optim.Adam(conv.parameters(), lr=.001)\n",
    "\n",
    "cv_loss_trn, cv_loss_val = [], []\n",
    "cv_accs_trn, cv_accs_val = [], []\n",
    "for i, (trn_idx, val_idx) in enumerate(kfold.split(X_train)):\n",
    "    print(\"Working on {}th Fold\".format(i))\n",
    "    \n",
    "    train_multi_ds = TensorDataset(X_train[trn_idx], y_multi_train[trn_idx])\n",
    "    val_multi_ds = TensorDataset(X_train[val_idx], y_multi_train[val_idx])\n",
    "    \n",
    "    train_multi_loader = DataLoader(train_multi_ds, batch_size=128, shuffle=True)\n",
    "    val_multi_loader = DataLoader(val_multi_ds, batch_size=128, shuffle=True)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    for epoch in EPOCHS:\n",
    "\n",
    "        train_batch_loss, train_batch_acc, train_cnt = 0, 0, 0\n",
    "        conv.train()\n",
    "        for x, y in train_multi_loader:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = conv(x)\n",
    "\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tmp_acc, tmp_t = acc_multi(y_pred, y)\n",
    "            train_batch_acc += tmp_acc\n",
    "            train_cnt += tmp_t\n",
    "\n",
    "            train_batch_loss += loss.item()\n",
    "\n",
    "        train_losses.append(train_batch_loss / train_cnt)\n",
    "        train_accs.append(train_batch_acc / train_cnt * 100)\n",
    "\n",
    "        val_batch_loss, val_batch_acc, val_cnt = 0, 0, 0\n",
    "        conv.eval()\n",
    "        for x, y in val_multi_loader:\n",
    "            y_pred = conv(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "\n",
    "            tmp_acc, tmp_t = acc_multi(y_pred, y)\n",
    "            val_batch_acc += tmp_acc\n",
    "            val_cnt += tmp_t\n",
    "\n",
    "            val_batch_loss += loss.item()\n",
    "            #print(\"Prediction: {}\".format(y_pred.argmax(axis=1)))\n",
    "            #print(\"Prediction: {}\".format(y_pred[:3]))\n",
    "\n",
    "        val_losses.append(val_batch_loss / val_cnt)\n",
    "        val_accs.append(val_batch_acc / val_cnt * 100)\n",
    "\n",
    "        print(\"EPOCH: {}\".format(epoch))\n",
    "        print(\"[LOSS] train: {}, val: {}\".format(round(train_batch_loss,3), round(val_batch_loss, 3)))\n",
    "        print(\"[ACC%] train: {}%, val: {}%\"\n",
    "              .format(round(train_batch_acc/train_cnt * 100, 2), round(val_batch_acc/val_cnt * 100, 2)))\n",
    "        #print(\"Prediction: {}\".format(conv(xx).argmax(axis=1)))\n",
    "        #print(\"True Value: {}\".format(yy))\n",
    "        \n",
    "    cv_loss_trn.append(train_losses)\n",
    "    cv_accs_trn.append(train_accs)\n",
    "    \n",
    "    cv_loss_val.append(val_losses)\n",
    "    cv_accs_val.append(val_accs)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T12:10:17.500931Z",
     "start_time": "2020-07-16T12:09:25.272883Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: tensor([5, 2, 2, 1, 2, 1, 2, 5, 4, 6, 9, 1, 9, 2, 6, 7, 8, 9, 8, 2, 6, 1, 5, 2,\n",
      "        2, 8, 4, 4, 0, 5, 0, 5, 3, 9, 6, 5, 9, 2, 2, 4, 3, 9, 8, 5, 3, 1, 1, 5,\n",
      "        5, 5, 1, 5, 1, 2, 5, 9, 2, 2, 1, 8, 8, 7, 4, 5, 6, 3, 1, 2, 9, 5, 2, 7,\n",
      "        2, 2, 7, 9, 9, 2, 2, 1, 5, 3, 2, 1, 1, 6, 4, 9, 9, 6, 2, 1, 2, 3, 2, 2,\n",
      "        2, 3, 2, 2, 2, 1, 2, 2, 5, 1, 2, 1, 1, 2, 0, 1, 2, 1, 5, 6, 1, 2, 1, 9,\n",
      "        2, 9, 1, 3, 2, 3, 2, 2], grad_fn=<NotImplemented>)\n",
      "True Label: tensor([9, 6, 8, 8, 5, 4, 0, 7, 4, 3, 8, 8, 7, 0, 4, 3, 1, 6, 2, 3, 4, 5, 7, 9,\n",
      "        7, 6, 0, 3, 9, 0, 2, 1, 9, 3, 4, 7, 4, 3, 0, 9, 3, 1, 8, 4, 0, 1, 1, 1,\n",
      "        0, 8, 7, 5, 2, 0, 7, 8, 0, 6, 7, 9, 2, 5, 6, 0, 9, 2, 2, 2, 5, 5, 4, 8,\n",
      "        7, 8, 8, 1, 1, 3, 5, 9, 0, 6, 8, 6, 6, 3, 9, 6, 4, 6, 1, 3, 9, 6, 0, 5,\n",
      "        9, 5, 7, 0, 0, 2, 8, 7, 7, 0, 8, 5, 2, 8, 1, 4, 7, 7, 1, 9, 6, 0, 1, 6,\n",
      "        2, 2, 0, 4, 8, 7, 6, 0])\n",
      "Prediction: tensor([2, 2, 2, 2, 7, 1, 2, 9, 9, 5, 2, 3, 1, 1, 8, 8, 4, 2, 1, 1, 2, 8, 1, 3,\n",
      "        2, 2, 2, 2, 2, 5, 1, 1, 0, 2, 7, 2, 2, 0, 9, 7, 2, 3, 7, 2, 5, 2],\n",
      "       grad_fn=<NotImplemented>)\n",
      "True Label: tensor([7, 7, 5, 0, 1, 2, 8, 8, 0, 6, 1, 4, 1, 5, 9, 8, 2, 0, 5, 7, 3, 2, 9, 8,\n",
      "        5, 2, 1, 5, 3, 8, 1, 3, 3, 6, 8, 2, 3, 4, 2, 4, 1, 3, 4, 8, 8, 3])\n",
      "4.68 9.77\n"
     ]
    }
   ],
   "source": [
    "test_batch_loss, test_batch_acc, test_cnt = 0, 0, 0\n",
    "for x, y in test_multi_loader:\n",
    "    y_pred = conv(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "\n",
    "    tmp_acc, tmp_t = acc_multi(y_pred, y)\n",
    "    test_batch_acc += tmp_acc\n",
    "    test_cnt += tmp_t\n",
    "\n",
    "    test_batch_loss += loss.item()\n",
    "    print(\"Prediction: {}\".format(y_pred.argmax(axis=1)))\n",
    "    print(\"True Label: {}\".format(y))\n",
    "\n",
    "print(round(test_batch_loss, 3), round(test_batch_acc / test_cnt * 100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T12:10:17.516890Z",
     "start_time": "2020-07-16T12:10:17.502926Z"
    }
   },
   "outputs": [],
   "source": [
    "def cv_plotter(cv_trn, cv_val, title='loss'):\n",
    "    # cv_score : Folds * epochs\n",
    "    trn_mean = np.array(cv_trn).mean(axis=0)\n",
    "    trn_std  = np.array(cv_trn).std(axis=0)\n",
    "    \n",
    "    val_mean = np.array(cv_val).mean(axis=0)\n",
    "    val_std  = np.array(cv_val).std(axis=0)\n",
    "    \n",
    "    _range = range(len(trn_mean))\n",
    "    \n",
    "    if title=='loss': legend = 'Losses'\n",
    "    elif title=='acc': legend = 'Accuracy'\n",
    "    else: pass\n",
    "    \n",
    "    plt.title(legend+\" / epoch\")\n",
    "    plt.plot(trn_mean, label=\"Training \" + legend)\n",
    "    plt.fill_between(_range, trn_mean-trn_std, trn_mean+trn_std, alpha=.1)\n",
    "    \n",
    "    plt.plot(val_mean, label=\"Validation \" + legend)\n",
    "    plt.fill_between(_range, val_mean-val_std, val_mean+val_std, alpha=.1)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T12:10:17.758243Z",
     "start_time": "2020-07-16T12:10:17.519883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_plotter(cv_loss_trn, cv_loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T12:10:18.371602Z",
     "start_time": "2020-07-16T12:10:17.759240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOy9d5gcxbW4/VZ3T9wclNMKIUAorBICSQTJwgKMCQYRRBJgwOCArzFcY2xfrvFnW74/gzHYxvhegzFBgSRhg8hRJAmBUESswgpJq7R5d2KH+v7omdmZ3Znd0QaFVb/PM8/udKiq7uk+deqcU6eElBIHBwcHh96Fcqgb4ODg4ODQ/TjC3cHBwaEX4gh3BwcHh16II9wdHBwceiGOcHdwcHDohTjC3cHBwaEX4gh3B4dehhDiWiHE8kPdDodDiyPcHXoUIcTbQog6IYTnULelJxFCTBNCfHCo2+HgEMcR7g49hhCiDDgNkMD5B7lu7WDWB3wDeOkg1+ngkBFHuDv0JNcAHwH/AOYl7xBC+IQQ9wohtgshGoQQy4UQvti+U4UQHwgh6oUQO4QQ18a2vy2EuCGpjBTzgxBCCiG+J4SoACpi2/4YK6NRCLFKCHFa0vGqEOIuIcQWIURTbP8QIcSfhRD3tmrvv4QQ/9HOtWYU7kKIU5Ku53MhxIykfW8LIX4rhFgRuw9LhRDFSfvPF0Ksj537thBiVNK+IUKI54QQ+4UQNUKIP7Wq9/exUdM2IcQ57bTdoTcipXQ+zqdHPsBm4LvAJEAH+iXt+zPwNjAIUIFpgAcYCjQBcwEXUAKMj53zNnBDUhnXAsuTvkvgNaAY8MW2XRUrQwN+DOwBvLF9dwBrgeMBAZTHjp0CVAFK7LhSIJjc/lbXOQDYBYg0+wYBNdjCXwG+HvveJ+madgFjgBzgWeCJ2L7jgEDsHBfwn7F76o7ds8+BP8TO8wKnJt0XHbgxdtwtsetp0z7n03s/h7wBzqd3foBTYwKmNPb9C+BHsf8VIASUpznvp8DzGcrMRrh/rYN21cXrBTYBF2Q4biPw9dj/3wdeaqfMbwN/z7DvJ8Djrba9AsxLuqb5SftOBKIxofwLYHHSPiXWEcwApgL7AS1NndcCm5O++2P3pv+hfi6cz8H7OGYZh55iHvCqlLI69v0pWkwzpdia5pY05w3JsD1bdiR/EUL8WAixMWbyqAcKYvV3VNdj2Fo/sb+Pt1Nne/b2YcAlMbNKfawNp2Jr++navB1bSy8FBsa+AyCltGLHDoq1fbuU0shQ756k84Kxf3PbuQaHXsbBdjo5HAXEbOeXAqoQIi5kPEChEKIc2xQSBkZgmxaS2YFtFklHAFsLjdM/zTGJNKcx+/pPgFnAeimlJYSowzbBxOsaAaxLU84TwLpYe0cBS9I1SAjhAs4ArsvQ5h3YmvuNGfaDLajjDMUe8VRjm1LGJtUlYsfuAiLAUCGE1o6AdziKcTR3h57gQsDENjGMj31GAe8B18Q00EeA+4QQA2OOzamxcMkngTOFEJcKITQhRIkQYnys3NXARUIIvxDiWGxzSHvkAQYx84UQ4r+A/KT9/wf8SggxUtiME0KUAEgpdwIrsTX2Z6WUoQx1nAaskVI2Ztj/BHCeEOKs2HV6hRAzhBCDk465SghxohDCD9wDPCOlNIHFwLlCiFmxTuTH2EL9A2AFsBuYL4TIiZU7vYP74XAU4Qh3h55gHvColPIrKeWe+Af4E3BlLEzxdmwNfiVQC/wO24H5FbaZ48ex7auxHZ1gOw+jwF5ss8mTHbTjFWAZ8CW2eSNMqgnkPmwB+irQCPwd8CXtfwxbc+6sSQYp5Q7gAuAu7E5mB7YjN/ndexw7omgPtrnq1ti5m7BNQg9ia/LnAedJKaMx4X8ecCzwFbATuKyddjocZQgpncU6HBzSIYQ4HVvzLouNNtIdswGYI6Xc0Mk63saOjvm/TjfUwSENjubu4JCGmBnkh8D/tSPY3cA/OyvYHRx6Eke4Ozi0IjZRqB47ouX+TMfFzCPzD1rDHBwOAMcs4+Dg4NALcTR3BwcHh17IYRHnXlpaKsvKyg51MxwcHByOKFatWlUtpeyTbt9hIdzLysr45JNPDnUzHBwcHI4ohBDbM+1zzDIODg4OvRBHuDs4ODj0Qhzh7uDg4NALOSxs7g4ODja6rrNz507C4fChborDYYTX62Xw4MG4XK6sz3GEu4PDYcTOnTvJy8ujrKwMOwmkw9GOlJKamhp27tzJ8OHDsz7PMcs4OBxGhMNhSkpKHMHukEAIQUlJyQGP5hzh7uBwmOEIdofWdOaZcIS7g4ODQy/EEe7dhWUe6hY4OHSZmpoaxo8fz/jx4+nfvz+DBg1KfI9Go1mVcd1117Fp06Z2j/nzn//Mk092lI4/e/bu3Yumafz973/vtjKPdA6LxGGTJ0+WR/QMVdMASweXr+NjHRzaYePGjYwaNepQNwOA//7v/yY3N5fbb789ZXtiAWbl8NENH3jgAZ5++mk8Hg+vv/56j9VjGAaadmjiUNI9G0KIVVLKyemOP3x+nSMZywAzO63GIQ2BGghUg6kf6pY4ZGDz5s2MGTOGm2++mYkTJ7J7925uuukmJk+ezOjRo7nnnnsSx5566qmsXr0awzAoLCzkzjvvpLy8nKlTp7Jv3z4Afv7zn3P//fcnjr/zzjuZMmUKxx9/PB988AEAgUCAiy++mPLycubOncvkyZNZvXp12vYtWLCA+++/n61bt7JnT2JtcF588UUmTpxIeXk5s2fPBqCpqYl58+YxduxYxo0bx5IlSxJtjbNw4UJuuOEGAK666ip+/OMfM3PmTO666y4++ugjpk6dyoQJE5g+fToVFRWALfh/9KMfMWbMGMaNG8df/vIXXnnlFS655JJEucuWLePSSy/t8u+RDUd+KKRlwaHWICzD1t47S6QJtJjWb0ZB8x76a8oWUwdFg846AaOBlo4x3AA5pfZvaoTtkVB75UaawJOXuk1KiDSCt6Bz7TmM+OW/1rOhKtPSrJ3jxIH53H3e6E6du2HDBh599FH++te/AjB//nyKi4sxDIOZM2cyZ84cTjzxxJRzGhoaOOOMM5g/fz633XYbjzzyCHfeeWebsqWUrFixghdeeIF77rmHl19+mQcffJD+/fvz7LPP8vnnnzNx4sS07aqsrKSuro5JkyYxZ84cFi9ezK233sqePXu45ZZbeO+99xg2bBi1tbWAPSLp06cPa9euRUpJfX19h9e+ZcsW3njjDRRFoaGhgeXLl6OqKi+//DI///nPWbRoEQ899BBVVVV8/vnnqKpKbW0thYWF3HrrrdTU1FBSUsKjjz7KdddlWku9ezlCJEg7RJugaU/XhGtXsXT70xkTl5S2gAvstz/hBgjs61xZHdETmrEZtYVsNkSDqd8tM/VcU7e/B2ti92F/Zl+GHrbvW+v9kUbQQz1z/45yRowYwUknnZT4vmDBAiZOnMjEiRPZuHEjGza0XZDK5/NxzjnnADBp0iQqKyvTln3RRRe1OWb58uVcfvnlAJSXlzN6dPpOacGCBVx2mb187OWXX86CBQsA+PDDD5k5cybDhg0DoLi4GIDXX3+d733ve4AdhVJUVNThtV9yySUJM1R9fT0XXXQRY8aM4fbbb2f9+vWJcm+++WZUVU3UpygKV1xxBU899RS1tbWsWrUqMYLoaY58zR1iArIZfIX2S6+6QFG7v55oEJDgzkndbpl2G0wdNHfLsXrI1iDVdm6zmaZTaF1Wd2BZdnvUdma4SWlryqYByPaPTZRr2Nfq8qdep2nYv0Fc844G7OPc/pZjIk1trz3SnFS2CcFa8BcDAvSAfV98RaAHW373uJZuRFs6EDMKmqfj9h/GdFbD7ilyclqe+4qKCv74xz+yYsUKCgsLueqqq9LGYbvdLc+wqqoYRnolzOPxtDkmW3/gggULqKmp4bHHHgOgqqqKbdu2IaVMG0KYbruiKCn1tb6W5Gv/2c9+xllnncV3v/tdNm/ezNlnn52xXIDrr7+eiy++GIDLLrssIfx7miNfc49jhO0XP9xg/9/dWJYtjMIxzTBlX+yBtZI0Y0u3BYwZab/cTPutbtayzQjIdiJ6TAPCseFppNEWmtkQ15xbHx9tsgUwxO5ds32fLKulvtb3MW35BjTvg+a9dhlGxNbsjdh900O2QLeslvZDzzwDDgkaGxvJy8sjPz+f3bt388orr7Q9yOraaPrUU09l8eLFAKxduzbtyGDDhg2YpsmuXbuorKyksrKSO+64g4ULFzJ9+nTefPNNtm+3s+LGzTKzZ8/mT3/6E2AL5Lq6OhRFoaioiIqKCizL4vnnn8/YroaGBgYNGgTAP/7xj8T22bNn89BDD2GaZkp9Q4YMobS0lPnz53Pttdd26Z4cCB0KdyHEI0KIfUKIdUnbLhFCrBdCWEKIya2O/6kQYrMQYpMQ4qyeaHRapLS1PGl13bnZ2sQjpS044uskJwuOuNYOqfXGy+jIFGJkaGtXrsFKs56zEU6/Pbk+PQyhOltwGpHU441MnZDRUn78Plhmi9mk9b2LX1c0S1NO2rYm3VMp05twMrX3cCDTb94R8RGdGbX/HsLw24kTJ3LiiScyZswYbrzxRqZPn556gJQtv3kn+cEPfsCuXbsYN24c9957L2PGjKGgINWX8tRTT/Gtb30rZdvFF1/MU089Rb9+/XjooYe44IILKC8v58orrwTg7rvvZu/evYwZM4bx48fz3nvvAfC73/2Os88+m1mzZjF48OCM7frJT37CHXfc0eaav/Od79C/f3/GjRtHeXl5omMCuOKKKxg+fDjHHXdcl+7JgdBhKKQQ4nSgGXuV9zGxbaMAC3gYuF1K+Uls+4nAAmAKMBB4HThOyvZUxi6GQoYb2tpyhQJ5/TpXHthCSajg8toCLlSbKlAUDXJji5/EBSLYZojcvvb/TXvth1t12U5CaDF7xJHS9hekI7mOAyE+evGX2OXrQduM1GxHKWS8L+nuoye3xWHZvA98xamml9bt9+bb5plwvX1fwDaNJAtad05qe3qSnNLsTEsHEyntyKAMv23GUEgpYx1p8vsquubM7gytn+FMWBbIWMevuDrVRsMwMAwDr9dLRUUFs2fPpqKi4pCFInaFm2++malTpzJv3rxOl3GgoZAd3iUp5btCiLJW2zbGCm59+AXAQillBNgmhNiMLeg/zLL93YO0bCHX2RfbMkBGbeEebWqrfcfNC4rSyhRjtmhTca3FMlo02uZ9dseTU2o/7HorYZqpjgMh0tQi4C3D/j8aaGlPppcznUM6GrAjdyzDvi4jBGpSdEprzTFuV08ejrfWoE09e5NPV4kGbD9MMpYV63SzEBCmkd1xB4JltPgpkv0PHSElqYId+3u2wra7kCagZlFnktYuLVtZOkCam5uZNWsWhmEgpeThhx8+IgX7+PHjKSoq4oEHHjio9Xb3nRoEfJT0fWdsWxuEEDcBNwEMHTq0m5uBbSboSLjrYVvzaf0CxyclmXpmu7Clg+JpO8Q29bbaefyFljHBEg/hi3Qg5OJ1ZIsRTbVFJ9qQ9KJZZtvrlTK9jV9Ke1QilJYyk0MPW9tUszETxCOLDgZxU1Hy7xGut58LNS/9OZZpX69l2rZ9f3H7z1G4IeZMzlKRiCsKeqitcG9vFJ3RxGFxUF1nUtp1diSsU66lc5FLhYWFrFq1qlPnHk5kis3vabr7qUjXnaf9ZaWUf5NSTpZSTu7TpxPmh46INHfssDNCtsmltVCKhzWG6jK/cHGbZ2vbuBltK/RadxJ6MNUOnYkDDV3UAx0fk85Cljy6aLPPbGmHZaZq4p1xmEl58MIUpUy979GA3X49g7M1WNvivA3W2L9Pe47ZcKOtgR+IfT/esaXr4DL5WeICNdO+g3Y/LRKjhXaPazXKOBjtsywn/LUV3S3cdwJDkr4PBqq6uY7sCdXbL2CyYzD5ATCitsAKN7RsM5MEXXuaqKWnf/FNva1QNiOpL66UmQVMynkH4HizrOyETLprOpB6okkdSBejIQ4K8bj3aNB+FiD9pDMpW+5DsjMw0+8Ubmi5Fwdy/+L1SpnaBqudQIB2lYCuOy6zJvHudCTgM5iPuoO4Wa1NlVaaepP3H32Cv7uF+wvA5UIIjxBiODASWNHNdRwY0YCthcUJ1bVoo4nol0jLi5qtycA00r/4lt5W6Onhzj1cZjT78+Jx3x2RSXPPFiMSG7VYR0a6ACljnXxD6naj1agu3XwDaPFbJL5btoaf7Hw+kN8pxUeTdN/NaDtCuiNN+SBprcnC/YAFaXe1T6ZGqEHsvrVzDxLO6KOLDm3uQogFwAygVAixE7gbqAUeBPoALwohVkspz5JSrhdCLAY2AAbwvY4iZQ4KlmELb8UVE+TNLXbkOJEm246YrcDK9LDEw9W6g7g22dFkHD3cvnM2mXTtPtCQunCj3UkcyZkw2zjJ2/nNQnV2KgRpxTrqVkI429/JbGX+snTAG9vXjnDvUC5K+/cQHbzOlmX7HzrjgG1tGpIyvRE2Y90miJitvisO4LjJxzJsfxm0jMzbMy0eCufzIaZDzV1KOVdKOUBK6ZJSDpZS/l1K+Xzsf4+Usp+U8qyk438tpRwhpTxeSrmsZ5t/AESaW6a666G2Jox4PPbhNvnFiJCI4U9HpLllNJIN6WLdD3RYb0aPbMEOaUxn7Qh3y7TvczSY+V5lZRJrp85MIwcgK603G9u7NDv8rWfMmNFmQtL999/Pd7/73XbblJubC9izQ+dcki4xlmTGzFl8snJlu/Xff//9BIPBxPV84xvfaJX7JWn0EA9USHQ6GUZe8f3SSiQhOxroPTNUOyJ5clMm7VrKw09oxXO3GJH0DuID7Yy6apbpLUgrtaPr6mgrm9+htU09ETYrO5+bKEFHppLsnKFz585l4cKFKdsWLlzI3Fjulpby0pczcOBAnlm8qIN2ZKZFuFtg6bz0ryUU5uUk1dk6CqfV95SRUWpntnHDBizL4t133yUQyCL4oJNkSrFwsDl6hPuRSjxOHVKdmWAP8w9UKFlmW0feUehsAlo6te6wyVpmxzNPWztx41FKcX9JWkdhB0K7zbGZ2hcvu/3fe86cOfz73/8mErFHIpWVlVRVVXHqqdPsuPOvn8XEk05m7PgJLF26tM35lZWVjCkvByAUCnH5FVcxbsIkLpt7JaFQiLgAvuWWWxLpgu+++27AzsleVVXFzJkzmTlrFgBlI46juno/SIv77ruPMeUTGFM+gfv/+ECivlFjxnHjd25h9LjxzJ49O1YPbe7nUwsWcPVVVzF79mxeeOGFxPbNmzdz5plnUl5ezsSJE9myZQsA//M//8PYsWMpLy9PZLKcMWMG8QmX1dXVlJWVAXYagksuuYTzzjuP2bNnJ2L0J06cyNixY1Pu1T//+c/ELNarr76apqYmhg8fjq7b73JjYyNlZWWJ753lyJsRcDRj6qmTX1o7BbMuJ9IS634YuEQOGZYBuLsvF78ezJzsLdNcAj3YYi5sLdyX3Ql71nBgzsh0+lpSB9FvDJw9P2OceklJCVOmTOHll17kggu/xcKFC7ns0ksRArxeL88/+zT5+flUV1dzyvTTOf/88zOu7/nQXx/G7/ez5rNVrFmzloknnRxrjsmvf/1riouLMU2TWbNmsWbNGm699Vbuu+8+3nrrLUqLC1Pux6pPVvLoP/7Bxx8sR0rJydNO5YzTT6eoqJCKis0seOJx/vfhh7j08it59tlnuerKK9vct0VPP81rLy9jU8UW/vTnPyfMM1deeSV33nkn3/rWtwiHw1iWxbJly1iyZAkff/wxfr8/kSemPT788EPWrFlDcVEhhq7z/LPPkF9QSHVNDaeccgrnn38+GzZs4Ne//jXvv/8+paWl1NbWkpeXx4wZM3jxxRe58MILWbhwIRdffDEuV9dmVzua+5FGpMnWwiwru3DKdKTEqh/Nwj0mbLvLz2JE7M43UGP7SJLvbSaberixZXu3hDRmoem3yUKaGl4497JLWbhoEVhmzCRzaew0yV0//wXjJkzizLPOYdeuXezduzdj2e++t5yrrrAF6LhxYxk3bmyivsWLFjJx4kQmTJjA+vXr2yYFa9XE5cvf51sXXEBOTg65ublcdOGFvLd8OQDDh5cxfrw9Wpg0cQKV27a1ucaVKz+hT2kfhg0byqyvzeDTTz+lrq6OpqYmdu3alchP4/V68fv9vP7661x33XX4/bYiFU8X3B5f//rXKS4sAMtAWgZ3/ewuxpWP48wzz0zcqzfffJM5c+ZQWlqaUu4NN9zAo48+CtBtOd8dzT2GblloikAcUAjAIUBasQk2ZvvD8PaIh+4JcZRr7rFr764kY9JKDbk0Ii2jrGxHB8m/6TnzY3bjTvxGQmmJJjF12tqqk7Bi9nhhm0wuvOA8brv9Dj79dBWhUJCJE8cD8ORTC9i/v5pVKz7C5XJRNuK4NGl+U8tOp9Vv27aN3997HytXrKCouJhrr722w3JkO3Hs8XTBAKqqEApHaD3pa8HCRXyxaRNlI+zEXY2NjTz77LMtqyK1iqTJlL5X0zSsmImrTVpgvz/xW6XcK4+PsuHHEA6HM5Y7ffp0KisreeeddzBNkzFjxqS91gOhV2jusgNNJaSbmFJiSUljWMdsJRQlksaQQVP48HCEdEh7M0qzIXnCztHoTI1jGS0T2XqClCyhB3kZxnh+pTbJxiDF8WjFYsTj4ZRY5ObmMuOM07n+xptSHKkNDQ307dsHl8vFW2+9nUil27roOKefdipPLrCds+vWrWfNmrUANDY2kZPjpyA/j71797JsWUtQXV5eHk1NbTOGnn7aaSx54QWCwSCBQIDnly7ltFNPzXTxKe+HZVk8/exzrPnsEyq3fEnlli9ZumQJCxYsID8/n8GDB7MkluI3EokQDAaZPXs2jzzyiO3cpSV9b1lZWSIlwjPPPJNUZWqoaMq9Sko7PGvWLBYvXkxNTU1KuQDXXHMNc+fO7baVmnqFcA9GTYLRWIJ/JIZlJf42hnWaIwZ1gSi1wSgRw6IhpBM2TBpDOsGoLdQtKYkYFnUhndpglKjZ8kNJJFHTStuJJB/XHmHDpDmiYx0uzst45M1RbZYxO++3yIaOorOyoosRNBlj5+OmoPS//9zLL+Pzz9dw+WUt639eecVcPvnkUyafPJUnFyzkhBOOT6NktHy/5ebv0NzczLgJk/if39/LlNgqTuXl45gwfjyjx47j+uuvT0mde9NNN3HOOecwc9bXU0qdOHEC115zNVOmTufkaadyw/XXMWHC+HauLck89O57DBo4MJGDHeyOZ8OGDezevZvHH/sHDzz4IOPGjWPatGns2bOHs88+m/PPP5/Jkyczfvx4fv/73wNw++2389BDDzFt2jSqq6vTXnebe/XUAk444QQARo8ezc/uuoszzjiD8vJybrvttpZzrrySurq6bgvV7DDl78GgKyl/zWA9dbE42FyvRjBqYlpdvyYB5HhUDMsW+ok5GwI0RaHQZzs7agJRcr0qnlarqzSGddyagktVaAwbGLFOQAgo9rtRhMCSdqchBG3O73GEgJy+bdMZH20I0bPRQrl9bfNM6xmyGdi4s45RyeuQmslx3N2IUACFRFreTpejpq56Fk+Qly2K1nZCobR6fkSZzmyVri3Z0q75TElN1hdPTtfKPPPMM8+wdOlSHn/88bSldHvK38OdYNRM9JndaVaRQHPEbLMNCbppoVsWpmWbeprDJi6/ghL7scKGScSwiBgWgtQ+XUoIRA3yPC4akoS+W7Uo8B3E3ONS2onGjmbNHXo+DNSMZrfiVEZ6qH1SAt3w20sLZJKgOtDmSiuNcO96szquN9mJnfR/e8K9vRmuncm1k1TWD37wA5YtW8ZLL73UUcuz5ogX7odq3BGKmi1mSympDURxqQpC0Mqk05awbiEtPSHYwT4nYpoZNfj29nWa9mZcOnQP0eAB2tsP1hPdXfXETD9CbWN3zu50K43QPCjSve2oqN2Uy0kpD9IK+A6Ee/I1SmmnYkiyij/44IMH0Pbs6BU290NB1LDQWwnxqGklTDgdEUljq49E078YYcOkKWSk2Osjpm3D7xKOYO95OuFIlem0ysOZuIDu7PN0yEaPrdvbzgzexAzfLk40SznnQA4/8OfAEe6dpBM/Z4dETcs280R0GkI6UdMibJgEIrbpKWKYsbptU1BIt7V9h96D1+OipqbGfpnbW/P2sEK2iZU/MFrPmj2EHVpGB3Q8P02aEORsrjvRYcclR/adoZSSmpoavF5vVsfHOeLNMr0JCdSH9IRDOBpK/fFDuoVLtWiOmAktvilkYHnA5zrIDlmHHmFw32J2Vjexf/++I0i4dwNCtNi7D6UfKLkdcVqPSlofk0174+ckl5Wurgx4vd52F+1OhyPcDzPai/QxLUl9UG8zHaU5YhA1LHI8KpqiIJE0hQ38bvu7w5GDS1UYPny4Pcv1YMfGH0o0j72kIdirYR0qAZ9uYfpgbduJbv4SO9VEpKnj5TLBXo/ZV5R6fPI19wCOcD/CyCT6o6ZFNGjhUm1hrpsWhiUp8rswLYl6JMy+dSCRM/5oEuzQcr16+NBq7q0Xpjf19DOYgzV2R5BtyKYeBi3UdoGWHsQR7r2MZCevaUlqmqNI7BGgW1GIWhYeTSHXoyWEfTBqoCgCj6Zk7AB0y8KVNAqwpES3rJQInohpRxB5NcdE1GniC6gfbUhpzxZunfn0UBBfP1d1te/4PNBY/HADKSucxK85U7K5LtLhmF0I8YgQYp8QYl3StmIhxGtCiIrY36LYdiGEeEAIsVkIsUYIMbFHWu2QNfFHU0o7QkdKOxSzLtgySzcQNWkKG9QEogSiRmImriXtWb7BqEF97HgAw7LPbwoZibDPuJO3KWzQGNITwj8+cxhok/bBIQ2WefSmhIg2Hx4jlvhELCPSve1JF1FkdlNeozRkY5D9B3B2q213Am9IKUcCb8S+A5yDvW7qSOAm4KHuaaZDd2Natl0+OSRTSntSWF3QjtapCUSpC9rCH2zbfiAm6C1pdwGNIZ3miJ3iIe7kjZgWtcEo9bFzI6b9qQtEMTI4CSOmiX40ORAd2tJdCdyOJHpwdng2y+y9i9BNRLoAACAASURBVL1majIXAI/F/n8MuDBp+z+lzUdAoRBiQHc11uHgYFoybc6cuPBv7dAN6RZh3WpzbJy4Ri+BpoiZkqNHImmK6DSGjDYzgoNJowgHh15JD45mO2tz7yel3A0gpdwthOgb2z4I2JF03M7Ytt2tCxBC3ISt3TN06NBONsPhSCB58pVhWtQ0R9FUBUWAYclEhJARi+v3aEosGZzdkeS40z+mUdPCrTrRQA4O6ehuh2rW83KllH8D/gZ24rBubofDYYwk1fGbTHPYINmdGIqaqIpAytRY/ohp0hgy8Lrs5Gzx/sPryuwUdnA4muiscN8rhBgQ09oHAPti23cCQ5KOGwxUdaWBDkcX6RLIxhPCCWFH4sSTtYHtHE41Can4XG0f63jOflNKNCHwedSU6B8Hh95GZ5/uF4B5sf/nAUuTtl8Ti5o5BWiIm28cHLpKIGIvulIfypwXPxi18+6HdNN26oZ0AlGDhlhkj2lJIqad0791GU40j0NvokPNXQixAJgBlAohdgJ3A/OBxUKIbwNfAfGM/i8B3wA2A0Gge5YUcXDAtt3XBaLtulgtKWkIGQmzj4lETzMnRko7+iffa6dZjod3qoog16N1ypZvSkkoaqCpihPr73DI6VC4SykzLQsyK82xEvheVxvl4JCJbHTrTPb81kQM24Hr1VQCsUgd05I0hHRyPS3mHUtKAlEDV0xoRxM5+FM7gKZwrFPRLSJqSzqIkG5iWFbKxDEHh57GmaHqcFTTFDaIalab0E87LNMWxIGokZj8FVFbjvW6FPI8rtjxekqnEk8HkbxYi27qFPhcqEIgkZ0W9KaUhHUTv1slGLUXhvG71cRoIb6QjKaIlNxCEdPEMKW9Qthh5G/QLTsb6kFfjayX4wh3h6OeiJEhcifSdqZocicQ1i0UYSCwY/3TkTzSiCd+87psbT7Xo+HVVEK6gRCiXVNOY1jHpSr4XCqBiEHEsAjpLQvGNIUNwqqFqpBwMMeXivRo9nKRTSEjljraotjfdsp72DBjkUeSqGHhTxOCmtwpxcNW49+jpkVYNzEl+Fz2KEcikZLEKmXpCMZSWnt8LdcfH1F1BlNKBO3XeTTgCHcHhy4QjB5YkitLysQ5zWEjZSQQVS3yfBqWhEDEwKXGhajEMC2ihoWitHRGrf2/umml+BfiS0W2nhxmWrbD2edqEb6BqNFmIpopZWJkYrfDpDliUOhzoSqC5oiBaankuDWaInrK+U2mRVAxsSx7GppLbVl3OJmo2XL9hmWhKUpsTQMD05LkuDUMy0okvmvdodjXKQnEOmKXptActsNnC3ypZjBT2nMq4ua0royeDhRTStRYZ3Ow6nWEu4PDISK+eleciGlhxFM7SGg9cLDTPXRP3pm4Oac9/0RYt4jokUTdcZoiJh7VnnsQipqYpky7slhy+mo9NkFNVQSNIYNcr4pA0BhumX4fiJj4PRCOjUhCUduMFDUtFCHQFGF3BpqS4ghvDBuJuuIjKMuU1MXupSLspHjxkY6mKpiWhUCQ521xnsfNQ5qioAqBbllEdBNFCBRFoAiBbtqmNkURiU7aq9nnq6pImJYktunM59KQ2H6cHI+KR1VpCBnkxvwxlpQ9tmKSI9wdHA4j2svn351YUmKZHdeV7gjDtIjlkLPNPFk6sONmLintTqr14vFxP0Vy3fHOz5KSaKy9EcOiMaQjFIjoVkYne/xemkmjpXj77fJtoetWFVQl1bQmRPaZAQJJZauKiSYERmyUYElQhN2WQMTE1CS6aRGMQK5X0Bw2yM/Nrp4DxRHuDg4OB4U2q9N1oayIaUE3pX2Ppimrs1MeTEuSnH0pGDUTBhjTkomOIGJamGEDlLamqu7i8HGZOzg4OPRCMvUTRpYjns7iCHcHBweHXogj3B0cHBx6IY5wd3BwcOiFOMLdwcHBoRfiCHcHBweHXogj3B0cHBx6IY5wd3BwcOhmQrrFSxvrqQsaSCnZtC+UMYdRT+FMYnJwcHDoJJurw7yxuZFThuVSEzB4Zm0tuW6FdXtC7A8YFHpVhhd7+KwqyLAiN9ef1IeIYTFhYA7DitxU7A8xQA0ypNjf7W1zhLuDg8NhT9Sw2BcwGJTvQiRlezQtSdiwyHEfWAbJrTVh1u0JIYEzjsmj0GeLws93B3llUwNRw8KlCoYUurl0XAmqAlWNOrVBgyGFbnLcCve+u4fn1tYhgf9bsR+AQfkutNh5/3Faf578rIattRG+PaUPL26s5+5XdyXa0DdHY1/A4PrpYf7rvBO7fI9a0yXhLoT4IXAjdnbR/5VS3i+EKAYWAWVAJXCplLKui+10cHA4jJBSsryymbH9fQnBGGfJujqGFbmZMCinzXlf7AvxmzeruHPmQEb19bK9LsqQQjv98Ge7grg0wbBCd0qZuxuj/PjfX1FRHeG4Ui/zJpcyboCfe9/dzcdfBYgaFt+e0ofzTyyiojrMixvrCegWJ/bzcc3EEiSw6PNaOz+NIVm/N8SKHYFE+Y+sdHHr9H58VhVk8ee1eF0KuW6FqClpCJt8UNmMhMQ5fpfCkEI3m/aHmTu+mCsmlPLxV824FMHs4wvQlJbO5+sj8zEt0FTBvEmlbK+L4HcrvLKpgYrqMDcOL+SCk4/pxl+mBSE7mURBCDEGWAhMAaLAy8At2MK+Vko5XwhxJ1AkpfxJe2VNnjxZfvLJJ51qR2N9DZFgU6fOdXDorexp0vm8KsiZI/NRlbbpZSOGhaYILCn5xSu72NesM3NEPjNG5DGk0JOxzAff38PJQ3PZ1RDlkZXVTBmSw58uHMaOhiilfo3VVUF++MJXuBTBtZNLeWFDPX63wvem9uXU4Xlct3grG/eFGZjvYuqwXJ5dW8fAfBcuVbC9LgrYibZG9/PRHLGoaooSNSQ5boUrJpTwxuZGttREUBV7JaxvjiqkLmTwekVjop1FPpXSHBebq8OcPDQXRcAH25sBUAUMKXRz1vEFnHVcAfuaDX7+yk6qA3YiswtGF/Efp/VLjAReWF/Hb96swudSuO6kPgwrdLNsUwPvbWvip18byDdHFXbpd9JcHor6DOj0+UKIVVLKyWn3dUG4XwKcJaW8Ifb9F0AE+DYwQ0q5WwgxAHhbSnl8e2U5wt3BIXveqGjgq/ooV08qRVMEhiWxLHuFJYCaoMH1i7dS1agztr+Pe2YPZlCBi6Xr69nTrNMcMVm6vo4Sv8YxJV7e29bEMcUettba6X0LvSpFPo0544o4ptjLvzbW4XMpvLWlyXYQxtpxXKmXL6vDnD48j+WVTfTLdWFJ8LkEPpfCxn1hjiv1EjYsvqqPMrjAzc6GKFdNLGHB6hpMC745qpBdDVEipuSK8SXkeWx79UdfNVPs1xhc4MbnUjjnhAKGFnowLcnSDXWs2hngllP6MTim9S/f1sTeZp2B+W4mD/bjUhWWrKvj129WAXDX1wYkBLGr1fKI9SGDL6vDjOrrI8/T1ryzrTZi3xN/y2jCiK101VUOV+E+ClgKTAVCwBvAJ8DVUsrCpOPqpJRF7ZXlCHeH3kxD2GB7XRS3KijN0Sjxayl24+qATki3GJjvTmjZUkper2gk16MydVhLTtjaoMFFj1UQ0C3KB/gJ6iYV1REEcPHYIi4cU8QvX6tiR32E60/qwxOf1qAqcMrQXJZtagBs7fXMkQVs2BtiR0OUm07uw40n96WqMco7W5vYXhehojrMmt0hAPI99qIepTkufnvOYL7cH6aqUWfe5FK+93wln+4KMmNEHluqI+xoiPK/c8o4tsTLqp0Bpg/PAwlLN9Txt4/3c0IfL/efP5R3tjYR0i3OOaFrmm9HLFlXhyklF48t7tF6OsthKdxjBX8be0HsZmADtpC/LhvhLoS4CbgJYOjQoZO2b9/eqTY4wt3hYLCnScetCopj2puUkt1NOqV+jbe2NLFgdQ1DCt0MK3ITMSSDC9xETcnbWxpZtTNAcur0/nku5p8zmNH9/bz6ZQO/fG0XUVNS4FWZf84QSnM15r9ZxapdQQDOPDYfBPTNcdEQMXn5i3quP6kPT35WwzHFHk4Zlsv+Zp2lG+oBWxj/f2cPZuqwXLbXRbh16XaqGnXmji/m1un9iZr2mqthw2Lj3hDjB/pTOpv49b23rZmGsMHXjyvAq9nL77U+rj5ksH5viGnDcgkbkqrGKCNKvGnvYTy/ejoz0dHKYSvcW1XyG2An8EMcs4zDEcz2ugjvbmvi0nHFVFSHufedPazba2uxI0o8HN/Hy6b9YbbURFAEWBKGFblpDJvUhczENrC3zzgmn/ED/RiWZF+zzpOf1VAdMBiU72ZbXYTxA/18c1QhT35Ww8562+7sdQm+P60fe5rs40tzNPY26ZjS1tDvnDmwjbB9c3Mja3YHmTepNMWEUBs0WLs7yOnH5LURzg6HlsNWuAsh+kop9wkhhgKvYpto7gJqkhyqxVLK/2yvHEe4O3SWPU06uW6F3Fa20jc3N1IbNDj/xMKELTqOYUk+/qqZ5ohFoU/l+D5e7l++l1U7A3z7pD48/PE+qgMGI0u9fFUfse3PY4uQwKe7glRUh+mTo3H28bYzb0C+iwtOLIqtuAOKArsaokhgaBrnZH3I4A/v7SGoW5zQx8fVE0twawqNYZO7X91Jvlfl1lP7U5I0ShBCUFkbYdmmeuaOL2kToeJwZHI4C/f3gBJAB26TUr4hhCgBFgNDga+AS6SUte2V4wh3h9qgQWPEpKwofaRGMpv2h7Ak7KiPcs9ruxha5OGRS4bz6Cf7MSzbJPLbN3cjgX65LqaV2TbrdXuCFPk0djVE2dWop5SpCNtcUtWoU+BVuW5yKX/9aB9lRR7uv2BYQtA6OHQnPSncu/TESilPS7OtBpjVlXIdej+WlHy4vZlA1GJYoZsf/esrmiImj88dkSLg39nSyMtfNuBzKZx7QiGaKrj52UqMmN3jmGIPFdVhLn1iM7ubWgT2+IF+5k0qZfGaWl77sgEJjO3vpyFs0DfXxQ9P68/wYg+7GqJ8sjPAqWV5jO3v47l1dUwanMPIUi/njiokx620ia5wcDgS6Dabe1dwNPfeiWFK9jTrKbMKK+sivLqpgVe+tMP54hT7NUxLMjDfxfxvDKEhbPLc2jqWrK+jNEdDNyVNEZMct0KBV+PGk/vQHDG5YHQR//vxfh5bVc0NU/rw9ZH5vLmlkcvKSxJhbVbsGVcce7NDDxN3FitC4HXZSkHUsDLmlTlszTLdhSPcAcsEodjLrh8CpLRXau9sJENTxOSfq6qpDhh4NEFzxGLFjmbqQiZTh+UycZCfFTsCrNwRQGBr1hePLabEr/HutkYuHlvMttoId7y4I1GmKuCy8SV8f1pfdFPym7d282FlMw/HQu2S2769PpqVScfBobsRwl5QWwgo8rtR07zDUdNCVQS6adEUtidMuVUFU3E5wj0TvUK4WyaFS6/GKDqW5hn3HPTqI4bF95dsx+dS+OP5QxFCYFqS1yoamDoslwJveuvdpv0h7n51FxFD0hwxaYyY9MlxETUtfC6FUX19HFPs4anVNQSiFkML3XxzVCHnjy7KaMNeuzvI1toILlUwbVhuG8dhd00ecXDoDhQhKPK7aA4buDSBz9WxpTsQNXBrCi5FQRcarrw+na6/x2zuRxsiWA2KivS2OyfrgHFXvoFr/3pc+9cTOfZs9MHTurX89pBS8tu3drO6yo6pXrEjwMlDc3n802r+/ME+jiv18ofzh1IXMlCEQAioCRis3BFg0ec15HtUxg30Y5iSG6b04fi+vjZ1XDWxBN2SGTuJZMYO8DN2QOYMeY5gd+hOBNBavfW7VdyaQkQ3CetWm/3J5HhUFCHI97myrjPH3fIeuJSe8+c4wj1bjAhFS65CRJtpOuOXRId3k89YSvyrH8XIHwoC8pb/huZTbiM66BRwdW8aUCklNUGDfI/98O5v1pn/1m7e3dbEtZNLeemLev728T4AHv5oP2P7+9i0P8y5j3zZpixVwCnDcrl7upeiohJQMj9K/gPM2JcJpXk3nso3CY2ea5uwHI4qVEUkJkLFv6vCNnV0xv7gURVyvRpNYYOoadvEPZqSEL4uj4KqmDRHDMB+ji0picQEvtel4NW659nuCRzhniW+DYtQm3djFAyj4LXbqL3kecyirmdzc+1eiat6A02n342ZP5j8V35Iwas/IlI2i8bZ92U8zzAlETP7VKdvbm7kd29VURsyGZDn4pujClmwugbdkvzw1H5cMaGEfrkufvf2br6/ZDslfo37zhvK9vooK75qpqzIk3i5Cn0qJ/T1keeCkse/RmTEWTSfeleX70VHeL94jpxP/4blziNy3Pk9Xp9Dz5BOW+4ITVXI92rUBez5AwLI92poikJIbxHA2dSpKoIcj4pHtd+dfJ9GIGJgWpDXanTpc9kzeTWlReP2uSyCUZM8T/ba+qHgyBbuehjX+qeJlM3uUU1ORJvxf/Z3ooNOITDlhxQ9Pxe1YXu3CHf3jveRikb42G+A5qXmmnfIe/sXuHd+ANLKeF0/e3knq6sC/PPyEfTLa3nIDFPy8Y5m1uwO8t62ZvY26Zx1fAHPr6tjZKmHqyaV8sL6Ov53xX4mDfLzs1kDE1kALxxThKYIcj0K4wf6KfRpFPo0yjOYSZTGnSiRerwbnyU49iqsgqFdvh/todZXApD78R+IDpuB9OT3aH0OPUOuV6M5bLQR8B5VwetWCURNDDM1usTnUlCFIMejETUsPC4FLWbS8LoUAlHbqRlHVQRuVRDS7XLyfPZ5lmULc0GLeU8gyG1HUOd51JRAA01RyPce/iPHI1u4r1mE77WfoA54mqYZ92DlDer+OqRF3tv/hYg0EJhyK5avBAAlVNMtxWt712CUjgItFv2huokOnoZ3y8uodVsxi49tc87nu4O8ucVOcfrTZTv460VluDUFS0p+umwHb29tQgDjBvgZN8DH02tqObbEw5+/VUaeR+WyccVs3Bdm7ABfIjzQvf0dPJFGLhxzXvZtr98GgJAGOZ/8haZZ87t2M7KozygYitqwA9/axwlO/l6P1ne00BlNurO4VNuUYbgswoaFz6USjJoAeN0qblXBckmaTAshbE06ErUS5g+fS8XnSh2tCgT+mIadEwt/dcfmJoSNKAKBR23R1A8UrQft4j3JkS3cJ15DKBzC8/avKFj2feouXgxq9w6V/KsewlP5Bs2n/Bijz2gwYzmnQ+1Ous0OS8e1fwOhUXNSNuv9JwDg2ru6jXBvipj86f29lPg1vjetL/e8XsW5j3zJzGPzMS3J21ub+O7UvlxaXpww2WyrjdAnR0tM0XdrCuUDU7XxnBX3o9VtJdC4k+Ckm7MKyYxr0qETLsL3xXMETv4P1KZd5C7/DYGTfkC0bEZn7kp6LBO1YTuh0XNx7fkM1+5V3Vf2QUSt34Zr18eET7zskIW9QqpAd2sKQkBYz26NT0UI3JpAESIhmJPRVDvJmGlJ1FjO+LhW7XPbgtLv1vC67P0h3S4jLpC9mkpAmPjdii2UfR0LZZ9bxedWUzRysG3oR6sL/sgW7kKgj76EqOKj4JVb8a17klD5td1XvpT41i8iUjaT0Nir7W2qG8udh+gG4b57yzr6mGEerxrIW0u2c/LQHOaOL2F5TSGztUK2rv2QB7adTIFX5eShufxrQx0fbG/GkvDTrw3gvBOL6Jfn4vm1dby6qYGAbnHuCQVcOz4PkaTdDC/uIP7bCKHWV2L5isn59K/oA09CH5g2uioFtX4blqeQ0Lh5+L54Dnflm7h3r0Kr20zBqz+keeodhMZe1dXbBNjOVGFGMQvLEEYYT8W/2jVbHa7krHgAT+WbmAVl6INPOWTtiAvSiGnhc6uoQhAxorQXGS2AHI+WojlLKQnpVkpn4dUU3JpCU9gg36shgaawPf8hrj0rQrSMGlWlzdAhx6MekLOytVCP43OpB21UcrhxZAv3GNFhZxAZegY5q/5KZOS5WP7Ox40mI0K1KJEG9AEnpWhZlq/4gMwyW2vCDMh3owr4+8r9DC30oAjY8ubbjNPg1ebh1Gk6f1y+N5Ex8CHXSE7U1/BlKMz+gM5z6+oo8KrMm1TK9LK8hOY9ZUguU4bkYklJVYPOsVv+Qc7CBdReujRrm7RWuxkhLZpP+gF57/4SrXpDdsK9oRKzsAyzsAyjaATein+j1VYQGjUHtb4S39onCY25sls01LgJyCgcjhSq7eBu2I5ZOLzLZR8sRKgW9/Z3AchZ+QD1g04+ZNq7x23HWRM2EuF4hT4XumkR0q1EVErcNBKfpNPatJHj0VCEidelUh/SsSyJR1NQ9ACFW1+DfqOhZCSF7YQKel1qYhZxYls3RaEcqSaV7qBXCHeAwCm34Vl8Ad5NSwlOuKFbytTqtwJgtHKcWr6SrM0yz62r5bdv7mZAnovSHI21e0KJfY/lb0NX+/DXq6YigefX1/HMmlpunNKHU4zTKFq5kiVzCmjUSvh8d5DxA/0Zo2MUIRji18lZ+0+UaBPeDU8TmvDt7K6z+gsAooNOxvIVo9Ztze68+koiQ08HIDJ8Fjmf/g2A8HHno9ZvI/+du9GqN2L06friv2pMuJuFw5FuOxGYtn/9ESXcvZtfQkiD4Nir8a99HPf2t4iWfa1H6hLCFtbBiEmklXMyWUjnJU0S0xTbSelzQdgwMWOrO7UXiy0Q+GNRJH63SkS3bI18+R9g9ZP2QRPnwYyfZizDrSrIo1a/7jl6TbdmFpYRHXgS3i+et4fr3UBcyJmFqcJd+opRQrVsq41w3aKt/OHdPWyvs5coMyzJvzfWM2/RVuY+uZnfvrmbyYNz8GiCL/aF+dVZg/h/5w7h+pNKmebZitVvHAiBEIKLxhTz1BXHctHYYhg0CQDX7lXkelSml+V1GPbo/eIZlGgTRkEZ/nVPgBHO6jq1mi+w3HlYuQMxCo9JdGrtISKNKKEazMIyACLDz7TvVd5AjL7jiA6biRQanm2vZdWGjlDrK7G8RUhvoS3gVS/a/g3dUvbBwvvlC+h9RhM4+T+wXLm4d37U7vFd0em9mi2o830utFaJzzxJKZAzmTO8mkqOWzugSTZeTcXvUaFxF6xZDCd8EwZNhq1vd3hupnY4dJ5eI9wBwsd/C7VpJ67dWaQysHTyXr8D184PMx6i1W3BcuWwtimXhatrqAkabK+LsKHJhxWo4Scv7mBrbYTFa2q5ZuFWXq9o4DvPbuOXr+1CNy0GFbiZO76YP54/lKeuGMEL143k7OMLmTEin+9O8uNq2oHeZ3Tauo3SUVjuPFy7Ps7u4i0T39oniA48iebTfo4SqsVb8e+sTtWqv8AoOR6EwCwaYXdqHaSliDtT48LdLD6O6KBTEmYY6S1AHzgZ97bXOywrG9T6bRhxLV3RMEpPwFXdvnAXoVoKXrwJpXFHu8cdDJSGr9BqNhE59lxQNKy8ASjNe9o9x+9WE8mnknGpCnleLUUcJofqCcCXNAsy16PaceE+jT65nh6Nz3YpCnz4F3t4cNrtcMxMqN8Ogeoeq9MhPb1KuEeGz8Jy59naexw9SM7781tepJigce94H+/WV8l/6y5EuC5teaJuG5vlIK59upJ7393Dhf/4ksue3Mzbu9249QZ21gf5/TeHsOxCjTP8lfx02U427Q/zqzP78O+SP3H/SfXcdvoAe2irKpTmtLxUWk0FAGZJhkWqFNUWjlXZCXe1cQdqYB+RY89FHzAZM38I7q/e6/hEy0CrrcAoPQGwbdpKtAkl1P7LqDZU2u2PC1whaDj34RQHamT4mWgNX6FVb8zqGhJICWZSvnXLQKvbmmKC0fucaJdrtY3WiOPe9RHuXR/jS34eDhHunR8AEBl6GgIwc/qjBOxnUgg7jjt5Jq+q2OaOHJeCe9eHKR1kbszZmO9zkeNWyfNqFPvd+N0qAouClfehbn8/cbxLUSjKcXc6FDCFdu43YLez4mU44TzI6w+D7Mgvqj7rXH3hBnjtF7B3fefOj7dp69tgtT/RqbfRq4Q7mpfo0NNx7/oo8TL41z6Of/0CfGv+iRLcT/Gi8/BsWop30xIsTz4i0ojvvd/y6Mr93LVsB794ZSeVtRGklET2VfB5uD+3ntqPJy4/htnHFTBnbDHfmjICgN+ekcNJQ3IZ9vm9PKD+gcvKi/n7nOF8s3Qfnu1vkfv+bzKaiNQa285tlByX8XKiA09GbaqyJws172330tXazS3lCUF04El2uGAHL6PasB1hRjBKbOEen5jVkd3dXbUSqXkx25lbEBlxFlLz4l2/0A773PlBei0+aZvStIvCF66leNF5oNv5bnzrF6FE6onG7PsARp/RCCOMWrc5Y/3avnV2W7tp9NAV3Dvex8wfTE6/Y+xp7Ln9UJv3oiqCIr+bXI+LHLdGTkxbL4g5IJWdKyl48Wa8uz5AEYJcj5pwErpVxQ4pjDkfc9waJTWf4vrsMVhyM2xalqg/XabCrNm/yRaMNZvhr9Pgnd9lvp/heogGoHSk/b3vGFDdUNWJ0NVgLTw9D9Y+DZ893vn2b37Nvh9b3up8GUcgvcahGkfvPwHv5hdRGncgPXn4Pn8MAG/Fv9nfrFPSuAP/e79BkTprB8yhPgJnbFvEovCF+Av6UBcyeL2ikQHuIO9RR/Hg45kxsRSAX5xpCzL3tn4AfG2QgSklWs0mlHAd/zkJrFwf6qYtALiqN+LZ+iqREWe3aadW8yWWt6jdyB590BQA8l+/A1f1Buq/8XDG8DmttgKJSDh/9QGT8X3xHFrtl/YkqQyoDfbC5GaR3WEZsb9q3Rb0QSenHOv58gW8m1+ieeodeDa/RGjUJe3mlJGefMIjz8P75VKEGcW7ZRkNZ/+Z6MDJ+Nc+QXjkN1GC+8h/7XYCJ/0Ao/QECl+4DqSJogfxr32S8AkX4v/kz0SHTCc67IyWezPA9km4d39CKMPox7VvLRKB1rAdtW4zZvHIjG3tLELY9m0gMRsyZT8gLB13GPmyawAAIABJREFU1UoYfSFeTUUiCeb2R4nUU6gZKMKdON7vbnU/m+1cP3n7VsEJHTtfxbrnwFMAJSPg5Z/A8NMg5oDmX7fCwAkw6brsLk5KeP9+WPEwHDPDbks0AKsetUdWX/t523Maq+y/+QPtv5ob+o+DXZ3Q3F+/G2q3Qelx8FXS6GXFw3bHdclj4CvsuJx1z9p/q7+EkV8/8HYcoXRJcxdC/EgIsV4IsU4IsUAI4RVCDBdCfCyEqBBCLBIi6ck9CCQmAO35DO2Tv4Me4vdiHkqkgWGVi1lujiZoKijS5MfbJvGXvXYkx6PT63hu3kievWYkc8YVMWegHQ0zsXxsmzosXzFgz1JVQtUoMbOOa4/9AGt1W5CKC6NoBP5PHkqr5Wg1mxJ27kyYhcdg+vskbMvu9vwDtRWYBUNAs7My6gPsUEZXVcz/ICUi0tjmPCWw364rp699mK8Ey5OP1lpzlxY5nzyEe+eHFC65GiSExl2TsT1xQqMvTwh2ANfO9/FsfY2clQ9S+MK15L/yI9TAXvLe/W8KXroFqXmpu3gxkWEz8X3+DwqXXouwdJqm3Zkajpo7ADNvYMv1tcbU0Wq+IHLsOUgEnm1vdNjW1ohIY7tDeU1VElp3rsfVJhe+qgiKctyU1K9DGCFEmb1wmUCg5ts5vJVAbEQWaYL1z7d9VuImwx0rOm5wuMHWUk84F6b9wJ5wtzN2f+oqoeJVePf/dWwiCdXbGvNj59qCdPAU2PoO7NsA594HE66G1U/YArc1jbvsv/lJI7qBE2DfetBDbY/PxO7P7Ws5+Tsw/gpo3gt12+C9e+0Op3oTrPy/luONSKopL07zXqiMmSdrt2Rffy+g08JdCDEIuBWYLKUcA6jA5cDvgD9IKUcCdUB28XidoGJvE/e//RU3PbONX79RRVPExCw6BtOdx1er30Bb/wz/Mk9hbb+LaHDZwmv4BT/ji8m/5NPBV/Pbq2bwwHe+gdS8HBteC0CprOWewK+4dbcdumWl0fZkIgVBLWpNS8bEuHBX67ZgFh1D6MTL0Boq2zr0LAOtbnO7JhkAhCBw0vdpnvJD9H7luPauznioWleBWdTSViu3H0b+0IRz2fPlUkqemIUIpsbnK8H9SJGUxlgIzMJj0GorUo5z7foYtbmKyNDTUPQAkWPPwcob2H77AbP4WEL/f3tnHibHVR3636mll9lntI4Wa7ElGWwsWZZ3LGMb7MiAZQIGgxMccHBYnLCExcD3HB55ISFAIGSBOBAQ++JgLAgmgDGbAYMsvG/yIq9axtqlGc163x+3qru6pqq7eu+Zub/vm6+7q6urztyqOvfcc885d9WlDB3/SkYWnUXqqV+TfvwWJrJ9yNhRZGyIfZd8kfHORVjDhzh40T8z0bWYI6e+DRkbBBT7X3p9ZN2a0f51uDu25lxfzs47yd61icyD38EZuA8ZH2FkyYsYnX8y6e0/LSkrAEqRfngzvd+6lNmbzqH99k/pZkG7QfwJThHozjgF7g7fZ25bQnvKpifr6u+fuE2PcBaflts33espv0PeXNBdX4P/fT/sf7JQniFPue++Xyvde74NT/4WRiMioR76gVboJ/4x9J+s3SG+AvYjVtpmwc3v1cowjme3wlO3Q/scPSl62SbY+G9w3gdhxYV6W/ciuPUjkzu/sOUOcMwZer8EUTOA7uB+9U+Q7dNhlMd4JbBv+xRs+Ryc9Brt0//Dl7XyHngQPne+Hqn4TIzpzvIXH9P3R9+xsDdZiO90oVq3jANkRWQUaAN2AOcDr/O+3wR8CPhMleeJ5Ik9g3zpdztYMTvN9+7fx88fO8jcDpdrjx7LeSM/B4FlF1zFx1cuRR55F4N7Hya14ASWLTgBuDB3nNF5a0jtuIOjzz1Iz81vRUYHGTrpTxhZeGakAstb7ntzlu/onBMKLPfR+Sfn3BqpZ27naEA52fu3I+Mj2nIvwfCqS/W5jh4ge+9X9UPphDJOx4awDzzF8LEXF2we7T+F9OM/gYlRsvd/CxkfwX3uvgLftX1kFxNts8HKT7aNLDyD9q2f1bVtPDdP5sEbmUh3c/DFn8DdsYWxeSeVlN3n8Ln/F4DsPV+h4zcfwz70NEPPfzVDq98AY0eZ6D6G/Zd+GTm6P6fEx/tWsO9VNzDRPh+Vao887kj/OjIPb8be9ygT7fPo/uE1WCN64Zbxdu06G517ItbBF9Lx+08jQ3tyHXMkStF56wfIPPIDRuecyOisVWQevZnMBddiBdrHkjFsSyYt25dxbFKD27Ae+h845kz9B1oxz1qRd48A0umtvnNoh3596vdeY+2E3iX5gw7t92Qbh5veqhUvQPtc2PDR/DlAW6jdx8DcE3Tvs2Ct7ggAHrtVy3DOu+C7b9EdzrExbp592/Xry/457/YI7uuk4dxrYfM1cP9NcOIr898dfEaXqs4E3CWLz4DuxTrufdWG6HMGObxbdy4vfBek2vXxuhbokUf3InjRB/Q+D98MX7pEK/LRIe2qOfMa6FsOj/xEd5YAS86G2av0aGNivOBen85UbLkrpZ4BPg48iVbqB4A7gP1KKb87fxqInHETkatFZIuIbBkYGKhIhnNWzua2d67jS5cfy+cvW8bahe3MaXcYmaddM6NzTqR/pXZPDB+3gSOnvT3yOKP9p2Dv3UbXLe9BicW+S7/CkdPfGevfVm4Hyk5hDe3B2fsw4+3zGVlyLvbeR7AO78Q+vIPx3mMZ717CePs8UqFwRnf33QCJlHtOxvknIxOjOM9Njhpw9j2GoBgLjTKGl78Ea+QQHb/8O9wB/TtnT2FtdmtwYJLff+iE16DsDNm79XyFdegZ0tt/ytEVLwUnzejis1GpzsSy+4x4i5DIxBgjSy9gon1uTpmrdNck63y899hYxQ55v7v77Bba7voiMnJYX7u1V+tOK9PLRMeCQCdb3LWR3vZ9Mo/8gCMnv4mJy7/G6MlXYQ0+h7WjcMTUHpjEzKEU/Ozvsb5yKfz+P+G/3wg/eLf+buAhmBO61p3z9euhnVo5+Urb87HnGNqnFZvl6n2etxE2/jukO+CGN+QnTdUEPHMHLFqXd18dc4Z2X+zbrr9b/iJY8kJId2lFGce+7Vo5F/NnH3sBdMzXnUSQg89ql0yw47NsWP1aeGaLbotSHPJcO3P0JD8isNjrxM59v+5cehbDK66HY1+sO4/Lv6FHKlu+oPd7/Bf6/7z6F/CK/9BzEOMjebfRDKAat0wvsBFYBiwA2oGobjlyWl0pdb1Sap1Sat2cOZWVC0g7+QpxJ8xv4x8uXswnL1nCaWdrKyNpXZPR/nUICufAkxxef11kJcYCRJjI6EQmZ8/DjM1aoZUviuzdelZ/rPdYXftm4em4z/5eP3wT46S230rHrz/KWM+yXIx4Ihnnrwbyrp8gtudCCcs9uugshhefQ/ahG1Hi6OzTPYUPl3VkgIn2wvZX2T6OrtpIZtv3sZ97kM6fXYeyU/n6OhUy3rOM8fb5TGR6c3Mj1TDRuZCx7iV03P5Jsvd8meHjNjA29wUMnvIWho5/JUdXXQoiBTkD2bs20XnrBycdS4YP0nH7PzE69wWMnH4NaTdF2/Hna4VRTBH6bPk8bN0EJ10Of/FLOPFV2k2y9zEYfC6vqHyctHaRHNoBu+7PRQYRjooa2ged/TqprWshnP9/tBV9xX9D/2o96Xhopz7P0QO55Dcgb9V/7+26Azn2PF1Yb/l52pKP8lGDVu59JTJ/RWDhWnhma+H2g88UumR8TvhjXfl065eKHxfyriq/AwQ47U1wwYcKRxBLzoKL/k67jPpP0u6oB74Lh3bB9l/p7zvmapdYnw4UYE98dNV0o5oJ1RcDjyulBpRSo8B3gLOAHhHx3T2LgGerlLFsxuaexN5XfzcySiWK0bknMpHq5OhxLy1wWRRjItuH89yD2Pu3M9a3itF5JzPWe5zODCUfdTKy4DSs4f10/fjdzNq0nu4fvYOx7iXsf9nntTWWEJXpZaxnmfYxh3B33aXDErsWF34hwuGz3ouyXEaWrGd03hqcsHIfHGCibe6kYw6uvhLlZOn7zmtI7djC4bPem8jHXhQRDp/1Hg6f/f7aDI1FOLDh3zm64qVMtM3lyLq3etstDq+/jiOnv0N/tmxGF5xK+omf0f67T5PZ9n2sI7sQdN2U3jaXroe+jQzt4/DZHyDjF8ZKdegh/cP/C89t09b5xJgOBbzlw7BPRxpx59fglx+HVRfDBddpX/XzLgFUPgU/rNxBK69DO+FpzyVjudHKPdMLL/skXHGDttgB3Cz80T9qBf2jD2qrGAqV+7wTtKI9MqAtZ89AYMVLdEfwTMxk9L7t0Lu0dPsvWKvdSAcDj7hvuYfJ9mj3zQM35dstDt9V5buuQMuz+vLitXjWXaWv0c3vgSO79SjFZ5an3GeQ370an/uTwBki0gYMARcAW4BbgVcB3wCuBG6qVshKKKvmiJ1i76u/i8okCKvyGF75Mtp/8wlEjTM+ayXYLgfP/wi9N14BYuVqy48uPB2FkHryFwwft4GRhWcwvPS8ipbQGznmXLL3fAl7z8P6nIAM7SGz7X+0yyRCYfr+7PG2uWQf+Dap7bdqK9Ftg7FhrOEDkeGYE50L2fuazbTd8xVQ4wyv3Fi2vJH/g1emoFZMdC3i8Pq/KX3ehWeQ3v5TlJ2B8TFST/4Sa/Vr8u6VHVtRs1cyMfcE0kGXy4mvgs1vgy+9XFt/nZ4rwnL1JGj3MXDgSW1RXvT3+SqV/au11X+fl0AVdssAdPTr7M2nfwe93v0adssc3Q/ZNZCNWLe3dwmc89dw6//TSqttNvQE/PWWA2/8sZYpqBSXnK2jqrb9uNBnDzByWCvGJMp94Vr9+uxW3YkMH4Lhg9HKHeD0N+uwxN/8K1z8sfjjHtqpfe3pMl1/3Yv09br7G/rz0oByT3fqeYpGWO57HgUUzCrhAagz1fjcbwduALYC93jHuh54H/AuEXkEmAV8vgZy1h3VNrtozHaYoROvYO9rb+bQ+g8x7BV/Gp+1ikPrr2PwpNfnFO1E+1z2X/JF9l7+Pxx60d8yvOKlFa+NOrjmjahUBx2//UQuZC5779dhfIShk66M/d3Y7Oeh2mYxNmuVdj95CU/WYGEYZBiV7ePIaX/FkdPf2dTa45Xg2hbpQE2VkcVno8Th8FnvYbxzAeknfp7PCFUTsPNupH81vW1u4UTpcRfAG38EL/6wvqZP3Abnvg/+/BZ44V/DrOWw7s/h5Z8unOh20jq+e3RQK5Uo5dw5Xyvlx3+hFVHHvELLXSk9oVrM9736tTDnedraXbh28nWy7Mnb3Kze99nJo8CcVZ3EZTh7pb6XfddMVKRMkPY5Oozywe/D40Wypw/tLLTay+H0t4Cd1pPHQbcOaGX73OT1gBOhVPEII9Cd2+a/1CGkm16ui6fFub4aQFVx7kqpv1FKHa+UOlEp9adKqWGl1GNKqdOUUscppS5TSpVokanLRMc8jh7/ioIFQoZXXsLgqdcU7Dc2fw0THfOqPp/KdDO49s06rf6pX+ns2vu+wciyCxL57/0JXMfLjrUGtZUY9rlPdWxL6Mo4dGVdvTybJUx0LWLP62/l6PNexfAx5+I+czvihxPu264tzv7VkyJgAOg5Bk56NfzpTXD1z3USUMdc7Qe+9LOw/t3RhsEiL/QxyiUDOqpDjcMJr4Cz3+Ep94DlPnIEJkaLK3fL1n54RE8sJqV/tVZ0I0cKt/uRMqV87qD/5/41+U4iKsY9zGlX6/bY/Fbt94/i0A7dFpXQOU+PCs6LWNN3ydk6cqkS18zjP4PPnDl5ZBXkp38Lj/4UznibnmP43X/AN16Xb9MGM73KD8wAhp7/asa6j6H9t5+g/ff/iowe4cjJb0r024mOfiZSnbmIGdsL46xV/ftmYFsyqYBWdzZvfXekXfraUvS2uaQ7ehABWf4iZHwYnvLCBP2kngUlJnlFylM6flx7lEsG4AWvgtd/Dy76iHZDdMzV/nG/ZIUf4x5l9QdZuBbecDO84LLksvWv8UYs9xRu37cdEO1uSsLi03QEzM578u3YXUS5pzt13HzfcfCTD0WXxzi8q3LLHXQsftjdBPD8S0DsvKusHHbcpUdhT8XUenroZnhgM5zxFp1AdtHf6VDS/U9qa74JGOU+1bBdjpz+1zj7Hyd7/zc5evwrGZ8dYxmGEWFs1qrcpKrvlomaUG1lsq6VU95Z186tKmSJ5BOHQjiWRWfaZXZ7muyyM/XQ3Y8B33GXDptL4mcuhwUnw3EvgZUxE/t2Kl+DBbRynxjNK/Wkyh207OUsMTnfy1PYeVfh9n2PQ1c/uJlkx1lzBbTP1mGfd3xBTyq3FcklAMh06czTw7vgyV8Xfjc+oitIhl0qtaB9DixbD/d/t/wiYr67Ki5TeOsm7Qo6/c35bSsv0tm1ex9rStEyo9ynICNLztULa6R7OBJyAZVibNZKnX2qJrCODKDsdOIVm1oB2xLa0w5tKb3uZ8a1SOfW5bSj3SphnJR2S/hRKjvu0squ1kv2OWm45F901EoS/FGB73c/6iUwZRIo93LJ9uhJ3B0B5b73MZ38019GmGq6Uy/Esf8JrdTPvy7Z75afD5nuyVb04d2Aqs5yL8aJr9Sjo+23Tf7u8O74Qnv7PeX+dIRyV0qXNlh06mT3XOd87Xo7UlkuTzUY5T4VEeHARf/C3su+U1aED2i/u4wNYR98Cmtwt3bJtPhkaVtKW+dpx69jLmRcmzbXzq1s79hWwdqeJVl0Kux+QCu0PdtgwZr6/QNJ8Se2fb9uOZZ7JfSv1srdD/H84bVe9ul7yzvOyg06Y3XjvyUr5AW6gz3+5bp+zDN35Ccec2GQdbDcAZau15PAj/88v23gIfjW6+H69dpPHkYp7a5yMlrJh/3uRwb0ZGrf8sm/9cOH/f+rgRjlPlVx0qhSw98I/Prx9p6HsI7sbvnJVEuE9pRDd9alK+PmVgYKLu8Gus5LWSw6FVDwvx/QvufjX1ZDqSukM2S555R7eR14YvrXwOAeXdTrD1+GnXfrRKFyJzNF4JQ/g3knlve7k14D4sA3r4Ab/kxfh1wCU50sdyel5wm2/0IrbaXgJ9fpyeVZx8FdX9ft/oUN+RyFwee0v33lRfqzP+Lz8QuS+bH0QbwCcRw0yt1QZ8Z6lqPEwd2xFXf3vZNKFjSStG3l/OUCk6oqAqScZKOKRO6YIP1rtI96x5062aXW/vZKaJsNSKFyF7v8eO+krLxIn/Pm98Gv/wWWnRs/P1APZq+AN/1URwo9c4fOBK635Q6w9Bw48LS2wp/dqkcvZ14D57xHW+Hf/jM99/DA9/T+vr995QY98R1O/trjKfdIy90vM2GUu6HeOGnGe5aSfeAGZPwoR1de0hQx0o5e37Mz4+gglIyjJ0NDCj7l1OkWdTP5ScWTr6jPOcrFdrXf2o8XP+rFuNd6LsAn26sjdfY+qt0y532w8S66bC+c+iZtNd/2KXj0Fl2PvsJckER4pZfZ/itdNiLTo0sXLH2hToR67iE9wb7zbp3J6/vb+5brnIJwrPzex/JJUmFSHfpYBxueqG+U+0xkbNZKZGKUsd5jGZtT5lC6BmRci66Mt9KQ6JWIMo7tvXfpyjqkbT1hWpOl4eJ43iXaPbM0WcmJhrD4ND2pOXxYW+718rf7LFuvJ0Ev+nsdz98MLBvO/Evt1x54GM7+q/qer+cYncn7y0/ouPST/0R3JpYNp/65/m7DR7Wb6MnfaLksRydn9S2bHCe/5xGt+OM6xs75ukxDg5l2KzEZSjM263h45Ae5wlqNxLZk0gLNwdBFf4I0nbWZqPfSeCe9Rv+1Eqe8QRccu/ub2k9b5oR5Rax5Xel96s2KC+HSz+jRVAVzSWVzwit0pM6a18HqwP9/0uX6b2JMW+Pbb4PhA9qitxytxIf2FXa8ex/TnWQcnf2FPvexYR0GW+dnzyj3GcjIknMZeeY3TXHJlBPRUrYffTow/wU6s/WXHwcUnPHWZkvUGER0tcpGcfqbC2PSw1iOzvh99Bb9fq63VKW3vgH7HtfK/egBPeHaFzGZ6tO1QM/tgF5k5T/P1R3IC99Zm/8l7l+o69ENLcl4z1IOXPzZssMoy0VEL0XXltKhin5cuqEEZ16jI1Ze/GHtrjA0h+e9XJdnOLpfly6AfFmGvY97r36kTMRkqk/nfN0JjA5qf/7RA/C76/NLINYJY7kbao6ILqUb9Je3oRgZn6CwWIAhksWnwdU/a7YUhhUXwtsvLNzWtVBPfPt+d39ZxGLRVrlY9526tg3orN4fvlfX5W+vjxvKmFGGqrAtoTPj0JF2cLw1RvvaUpMmQn1fusEwpbFsXTGzQLlL8WJpfsz+wWdh1316HmXjv+uKn9/8E724SD1ErctRDVMO8f7C20qRdW0y3opYvVmXzrQ7M33lhplD3/KAcn9KK287Fb+/n8i0b7u23OedoOdWXnE9HHoWfv4PdRHTKHcDACnbwrULb4cOLwY9DkHHqxsMM4q+5ToJanwEDjyl13MtRucCPeF67w16Ra+5z9fbF63Ta79e9JG6iGmeTAMA6ZRVkA1qieQsch+BggUwUrZlrHTDzMOvw79vu1bupcoji+jqmQMP6qqfwUJy81+gF0+pA9UskL1KRO4M/B0UkXeISJ+I/FhEtnmvdc7CMFSLnywUtNyzXlRL1s1XWmxP23RlXXrbXNpTNpmU8aEbZiDzX6Bfn7hN1+YpZbmDriWfatfv5yasElol1Syz95BSao1Sag1wCjAI3AhcC9yilFoB3OJ9NrQwvnXuWHrVIkskt0i0JUJfuy4TkHWd3H5tKSdXF8ZgmFH0LNGJVvd9V3/uTqDcUx1w0mt1zHv3ovrK51Grp/MC4FGl1BPARmCTt30TcGmNzmGoMbYlnhWej4jNuhY9oXVEBckvJG0wzHREYOEpOmYdklnuoJOWrvxBw7LCa6XcLwe+7r2fp5TaAeC9Ri7zIyJXi8gWEdkyMND4QvYGXSfdsQpvgazrRK5kZDAYAixcl3+fdElCy06+wlUNqFq5i0gKuAT4djm/U0pdr5Rap5RaN2dOa9cUny60p2y6vUWjU7ZlrHGDoVIWnqJf09162cAWpBYZqhuArUopPxJ/l4j0K6V2iEg/UGS5cEOjsCS/uIXxlRsMVTJnla4kmdQl0wRq8ZS/lrxLBmAzcKX3/krgphqcw1AhviJPJ1z0wmAwJMBydAXP529stiSxVGW5i0gb8BLgLwKb/wH4lohcBTwJXFbNOQyVk7IturMu+4ZGc9EvBoOhRpzV2kXdqlLuSqlBYFZo2x509IyhSTi2xdj4BG1prdC7M45JNjIYZhimKuQ0wxKhN+syNjGRi4Qxit1gmHmYmbVphu9bD4c4GgyGmYXRAFMUXTJg8uVLG9+6wWDAKPcpS8ax6Mw62Fbe5WJbgmssdoPBgPG5T1myKQdBlw+YULpio/GtGwwGH6PcpxgZ18IWyZUIEATb6HSDwRDCKPcphG0JnWm32WIYDIYpgHHQtjCubZF1rVwRObPqkcFgSIqx3FsM2xIcEdIpK7Cg9ChDoxOTlsEzGAyGOIxybyFc26I7qydKg2RTDkfHRkzBL4PBkBijLVoEx7boykxW7AC2CB1p0w8bDIbkGI3RZESgzbVz5XjjMLXXDQZDORjl3iR0fXU7t36pwWAw1BKj3JtAxrXoSEe7YAwGg6EWGOXeYNKOZWLVDQZD3TETqnVGgK5svp56W8q4YQwGQ/2pSrmLSI+I3CAiD4rIAyJypoj0iciPRWSb99pbK2GnIu1ph7Rt05aycW0rvhSvZZS+wWCoHdVa7v8M/FApdTywGngAuBa4RSm1ArjF+zytSTtWLgbdsS1621zSjl7izp8wzbo2HekiCtxO6T+DwWCoARUrdxHpAtYDnwdQSo0opfYDG4FN3m6bgEurFbIVsUToSNt0Zhy6Mi4dGQcR6EjbOJZFV8adlHRUdAEN2wXHKHeDwVAbqrHclwMDwBdE5A8i8jkRaQfmKaV2AHivc2sgZ0ug7DQT2Vlgu3RmHLKuk4s/t0XobUtVXk/dcsFO11Bag8Ewk6lGuTvAWuAzSqmTgSOU4YIRkatFZIuIbBkYGKhCjMYgAirVDrZLR3tHZCkAu9J66iJ5y13MHHdRzNyEwZCIajTJ08DTSqnbvc83oJX9LhHpB/Bed0f9WCl1vVJqnVJq3Zw5c6oQo77Yll4QY1ZXB9lslq6MS7ZENmnZWA650o/GNVOcVHuzJTAYpgQVK3el1E7gKRFZ5W26ALgf2Axc6W27EripKgmbTNbVPnRJd3qK3a69dW0FOotsL3T1Gws+DidjJp4NhgRUa4L+JfBVEUkBjwFvQHcY3xKRq4AngcuqPEfTsETIuBa4GXCC/vAaZ5ZGKSsnBaNHa3ueeuCkYXwU1ERjzicWpNpgaKQx5zMYpihVKXel1J3AuoivLqjmuM1EBJTS79tSFiIWpLsn71RL7IiMVTs9NZS77erOafhQYFsKxuugfEW8+QljuRsMpTBj/wCubdGTdRF0vHrWdbTLJBwBU0+3jI/ThMiZKDmS/MZtK+zw6uUX99vduKyKE5zDMcxYpv5T4mapxk1iW0LWtfT6pBkHx7LoyDh0ZTxFF6lIavjg2G70g2jZlSnbSrEc6JjjtWeZv7Ms7QsHLbebqY8Czil3mZrKy81A++zy27iS87TNMp3gDGfqX33bZSLTXXq/4E8syVVm7G1z6Ui79LWlcqGMGcfOhzVGPSC1fGiKKfBGRs7Ynhzlujx8+f2RRu5zHWQPtvtUVFyuDqUl3VVf+S3XJMUZpklVSCeDSnUiI4did8m6Vi6Esax49EjlXmPLPfa7NDBY/jGDEwdJsYqNVOJ+Y+fbwk/A8v+feswZBNtdLGC8tsevJ5aTV7aWBekOOHqwPufyr4GYnICZzBQ0fwrxk4lUqh0VyvB0bIuubN46t0VK72J6AAAUU0lEQVTKTzSKSpqppVvAKqbcK7C8LBtSHZXLUZZyD9gGlqWVin+ceswZBJXVVLPc3Uzh53plI4uVv2dr5dYLy95o6u3GmqZMsSdkMhnXpt1bX1QFFEratujJ6oqMRWu6lCJWidRKuRd5AH2FWQ5uW2UPg12lcgev+Jl3nHrMGUxlt4wTuib1kr+gw62B5Z7ugFRn9cepFLEg0z0151iazLRwy3SkHdpTNmpMOLj3MJZAV6ZGC2LEDW3Fqj6227InR+KEsV0dR54EEa3cLau8cESRvCIo5yEKK283W6hQbBcmxpIfrxSVKHfLqa0MlRJWtNUYHMWwg8q9ysfbSUPaU+zluvp8N5SdhqP7y3cT+qTavfvTrU947TRmipk/8YgIlu3Qk3UnK/Y490YSRRanRGphSSR5+MoZvtupvNIox3oPuobKsSjDo4rw51q7ZipR7q0wqShW9P1SD+s9eC2DcyJlH8fR2dJRxy2FndKRV5lu7dIp57dh3DbvmNPCDm0o00a5A/E3s9/7Q+H32d7SQ9e472vxYCY5hp3SijrVVnrfAqu5DKUW/F3S+QRJ4DKqtV+5EuVup5o/pK/2Hqqmw610UtXNFLZb1LWO67zDo5JyXYvB3/nHqqaDgBlZcG56KXeITwjylV2mWytKN6u3F5t8rHc8dZIbzrIg25OPIy9GpROO4TZL8tskFrFl1dbvXolylwbnC0TKUOXqW+XIHz6XFbonkira8HEmdRqin6UowvJWOoILGijVZiXPwEnZaajcQw+MnyTkZLwEm6y+Kf0bM9VWxLIq8vDVQulXo4Aj9wnIa8W4Akr9LqlcSTobqNxqi6Ii5V7jDqYSYu+vCq9PMYopdyelk6iyPRUcJ3QdXe+5iYwmCz+DFY6egp2CHcq6TZcREWbZye/XacQ0VO7hCI5AaJ4bcG2UGnJCcQVSE7dMGQ9tEv9p+HhJjx/+XxK5ixJaY7VS7iKFw/1ylHstO5hSOGlo6yu8D4tNyichaecU5duXCFedmy1tCU9S0AHlGgy3jZJtkrEg5btVomoI+Z/tlE4IS4qdmpEx/zNAufuJI3Z8zZO4h6doREMtJlTLvOFKPeSTIjIqVe5F/rd0hzfaqbFiKkUlHRB4rqEGKXcRrdidtLaQc/HmDVTuxX4bVJaZrvKPle3NT7TmfOER/1uUvOV2sFHWvm+cuRmv5EUJA8P/3kmXN5KdJswc5Q7xFzfu4Wklyx3Kn/yteMKuyEOQ6oj3tUbKVCvLPewmSPCw+r9plOVeEHUkeeVSteVeYScNeSXpr/aVO2aJDiPqWE5aR8GUOk6UvGWXtYg4huvV8vddLKX86Jlu3RH5o8yplhtRJdPvvy0YDlvJHoxY5V5Hn3vYzZCEoglPURZUjd0ycSF9xbCs2jxUUf97qeMGY/cbES0RDtfzlUolczoF+yVsw8gCdFb0AicixY+ZeGQW6jjj/tdylXtc22R78udwMvHZs7ZLroid/7/MMNfM9FPuInlFkNRiCyqOoDVQTCGUethKDRkrudGKKfeo4yU5R6SfNi66o0IXSy1cM1ETYqWuQcEEbAMe7LCi863mWoRCJtk37jypjuhnoVgnnpTwtS3m4iyng43bNxy2m+0tDHX2iXr+6pU41qJMz8wA28tKTGy5+g+gl+E5OuQdp5i1UcKCdTJahomY4laVWJKlShVUco5yql5W+nBYdnU1voIujoLtpZR74BpZVnkyVJKBHFagpfzCYfmdNIwNR+zn3Z+lMm3j2sN2QCLmm2qi3K3Ctir2W9uNfx4myVDG85Hp0gpeKd1WQ/tijAFjuSdGRLaLyD0icqeIbPG29YnIj0Vkm/faW+o4Nce3oMrx91qOt6qQm5+pr8Zyt93yHuykMsYerwrLPcm2pMeLIspqLOnzDUYzxYTSJfW5Q5mRSQ50zC1v0ZGwT9snXFMmVj6rMJorvE812dQQ0/lXGX/vU+CDL/Lbsp7HCuajbEe/ts2KueeqVO6NjLqqAbUYp5ynlFqjlPKX27sWuEUptQK4xfvcWHIhU2XeTE46r9hLulVKPGyWUzxcsJIbLc6ChfKUdIEc5VjuVbplgseNi1O2XR1pErS8YjMhy5gULKe9M126rTNl1F2PU1zFKioG295JxbhO/MzqCjvqSvYvd14l050/VrFrUo7fvZp5mjj5q7Xcp9jyjvVwQm0ENnnvNwGX1uEcxclVJixDGVlOYRxtqaSHolaSnVfEtb7R4jJqIydUy4goKbUt7hxJsFxdgMpPnhHxioxFXB836416Mvl946zfcpR70vZ20oWdSdLsykprn+QieryRYtzkdqIJ1Vop93In+m19bdv6ikew2G6yZ7KamjiljlsNM0y5K+BHInKHiFztbZunlNoB4L3OjfqhiFwtIltEZMvAwECVYkw6eHHFGoWdzl98N5vgYS0yCZmzVIss5lzpjebEjCpiw+1KnKcRbhl/cQonrY/tt0lUCYPcd4FRVKz7oMTILChv0vYOd+pJMxsrHtV4cuUia2JKQSSaPynz+lQbohkk3ClGHtebAC05V1In33g5x40LKy2Fn0/TAi6capX72UqptcAG4G0isj7pD5VS1yul1iml1s2ZM6dKMSKI8l8Wo6BUasKaL7n3TqGiKoi+ifKjFlH6SQj7guP8vVD6f4lU7nH5ADV46IJ1fsIKLZhN6rdRMb93OCU9TEWWe1i5JzQSKo3nF2/SNbfMYYmcCztVO4u7VscpB9vJJ3rFUa+olnISmcKF+vzQ5VLPQLZPu/OyvfUZfZRBVa2olHrWe90N3AicBuwSkX4A73V3tUJWRCNWjwmGXAb960Hl7lurQaqtVBjuGKyYRbb98xcjciI2Iga6VkPlYOq7k9YWffvsQsWe27etupDSgtFUggfbz2QsOIZoV1gpOSq11Nr69F9OznCBroBbxrd82+dEGwflKsVmKHfQbdXWV6TsRx2jWpKOsNy2aOOg2O9TbfnO2bIh01P/tixCxWcWkXYR6fTfAxcC9wKbgSu93a4EbqpWyJbFCUzcFlSwC2Uqhv2Q1dY5D1vqxSo0Otm8Uovq8OJuvrDMtXrgnHReXhHtixfRFnq4XZJ00OERV7gKYpBS/0OcCybdoZWRP4oID7tr6SOOqr4IWnZ/IRbLmlyuuqLoqyqTq6olzj9f15FDghGznwAVToiE4pZ7eMUqN6M74iYp+Gri3OcBN4q++Rzga0qpH4rI74FvichVwJPAZdWL2aLYKWBQW1t+GJbYkx/QVDuMDuZXo6lFnfPgCk1Fo3Ks/FA+1TF50eq4Gy/VkZc5qoOqNan25DHQQcIJaJar45yjfPWWDWpc/89R5yrV6frRM+kOHY8+uHeyDNUS63O3CifTLQvaZutrM3wQxipYpahZlruPkwUO6ns53alXWho+XNv2DGOngCMx37n6fvfvg2B+Rq5oWlySlh0fbmo5TVlFquJWVEo9BqyO2L4HuKAaoaYMvlL1lXmcj9ifZBk+nI/Hrcm5B4v7231S7foGs+zCTsGXLQrL0g+cUnmLsZ6IVNYuQTeGX4Z2ojP6OuRiyRWMDIaOYxe3ynz8EE5/AnFsuMZljb0M61zCUigRK4j/OdUJ6kBl54paPq9Ryt2ytHWb6tTXPleLp0mWu5v1jAwvIaughHYJt0y9y4NXwPTMUG0U/s3pX7x0V7wSTHVoazFdo8WGw1ElxSgI7cvklXupxUjKSeJpFrab99f7D2CxGHon61lRg5O/K5d0F4w/V3tLM5iNmjRXIV2iymMcYoMKZL6KVf+OPEimp/Ae9A2KeuEvOh+1LrHvlstVvIxyyxSx3GPP2ZzMWKPcqyU8VI5DJNkiCUmxLG9ircxL6GZh+JAn0zRIx7Zs6JyXTCG4bV6Hlp5ssVYSvWQ73qioxmFvlgN4ZQjqsaBHkHDn0egViyrJPK6WKOXuj2zD23Iylcg3qCabvU40byp3utDMeNaK3BiByb/ptK5kovT8wDq6cQtBlEuqozZutgJZKlywvBLC7TYVRmvVEjVxHlloLGLBlbhqmkXdMs15zoxyn4lYgXCtmUpBnf+IMMyk1CWTMthZ1NmKLViGLz0z7omoUOTIQmOBip7hOkBhitZ9Mpa7oVEkqQMy3XEDIaJJFvtuJFHugLqdKxhSO0PWGQ3XaAqG54aJqotU7toJTeowjXKfieRu2BlgpcXhL5YuMjk+udkUWIwN8D/n3rdYJ1dPgrWLiq0sltsvaLmHS4+UWAxmCsa5G6YqObfMDL/8qQ7PJdOC7WA5OrqqEdmiIkCFoahTFX91qnRHccXsZmHkSGGwRNKVy5J+Xydm0NU05DA+d41l1y40tdak2vUCGI2IkZ5JFruPCLTPSrZf+B4Jj3iTrE1QyeIvVWKU+0zELy07w1aDn1IkqbJYKyynqTVQWp5wGYxyLXd/nwYrd3NFZyJ+pqrBANpyn4nWe6VEFdUrRezC4fWzr43lPlMxD7PBp9oqpTONsKJOZLnHJGvFLb5TA4xyn6nMlLA3Q2kaWW5gOlCRWybCcvdrIdUJc1VnKjMpMsJgqCWV+tyDpNrrPplvlLvBYDCUQ7gEQaLibgEL3c3mF2GvI0a5GwwGQ7mUq9wLFvNpzHyXUe4Gg8FQLuWughVc2alBIa5VK3cRsUXkDyLyfe/zMhG5XUS2icg3RcSEZRgMhulFsMJoUveKk0q+KEwNqIXl/nbggcDnjwKfVEqtAPYBV9XgHAaDwdA6SES1yFLY6Ybml1Sl3EVkEfBS4HPeZwHOB27wdtkEXFrNOQwGg6HliCoFXAon3dAQ5Got908B7wX8vNpZwH6lcut2PQ0sjPqhiFwtIltEZMvAwECVYhgMBkMDqcRyF5kayl1EXgbsVkrdEdwcsWvk+mdKqeuVUuuUUuvmzJlTqRgGg8HQeCotydzATOBqMlnOBi4RkYuBDNCFtuR7RMTxrPdFwLPVi2kwGAwtRCWWe4OpWDKl1PuVUouUUkuBy4GfKqWuAG4FXuXtdiVwU9VSGgwGQythWfHrqbYI9ZDsfcC7ROQRtA/+83U4h8FgMDQXsVtaudekwIhS6mfAz7z3jwGn1eK4BoPB0LJYra3cW1cyg8FgaGWMcjcYDIZpiNhEBwi2Bka5GwwGQyU0sJRAJRjlbjAYDJVgLHeDwWCYhlhOS69i1bqSGQwGQyvTwoodjHI3GAyGaYlR7gaDwTANMcrdYDAYpiFGuRsMBsM0xCh3g8FgmIYY5W4wGAzTEKPcDQaDYRpilLvBYDBMQ4xyNxgMhmmIKBW5xGljhRAZAJ6o8OezgedqKE4taVXZjFzl0apyQevKZuQqj0rlWqKUilyEuiWUezWIyBal1LpmyxFFq8pm5CqPVpULWlc2I1d51EMu45YxGAyGaYhR7gaDwTANmQ7K/fpmC1CEVpXNyFUerSoXtK5sRq7yqLlcU97nbjAYDIbJTAfL3WAwGAwhjHI3GAyGaciUVu4i8kci8pCIPCIi1zZRjsUicquIPCAi94nI273tHxKRZ0TkTu/v4ibItl1E7vHOv8Xb1iciPxaRbd5rbxPkWhVolztF5KCIvKMZbSYi/yUiu0Xk3sC2yDYSzae9e+5uEVnbYLk+JiIPeue+UUR6vO1LRWQo0G6fbbBcsddNRN7vtddDInJRveQqIts3A3JtF5E7ve2NbLM4HVG/+0wpNSX/ABt4FFgOpIC7gOc3SZZ+YK33vhN4GHg+8CHg3U1up+3A7NC2fwSu9d5fC3y0Ba7lTmBJM9oMWA+sBe4t1UbAxcDN6JWRzwBub7BcFwKO9/6jAbmWBvdrQntFXjfvObgLSAPLvGfWbqRsoe8/AVzXhDaL0xF1u8+msuV+GvCIUuoxpdQI8A1gYzMEUUrtUEpt9d4fAh4AFjZDloRsBDZ57zcBlzZRFoALgEeVUpVmKVeFUuoXwN7Q5rg22gh8SWl+C/SISH+j5FJK/UgpNeZ9/C2wqB7nLleuImwEvqGUGlZKPQ48gn52Gy6biAjwauDr9Tp/HEV0RN3us6ms3BcCTwU+P00LKFQRWQqcDNzubbrGG1b9VzPcH4ACfiQid4jI1d62eUqpHaBvOmBuE+QKcjmFD1yz2wzi26iV7rs3oq07n2Ui8gcR+bmInNMEeaKuWyu11znALqXUtsC2hrdZSEfU7T6byspdIrY1Na5TRDqA/wbeoZQ6CHwGOBZYA+xADwkbzdlKqbXABuBtIrK+CTLEIiIp4BLg296mVmizYrTEfSciHwTGgK96m3YAxyilTgbeBXxNRLoaKFLcdWuJ9vJ4LYVGRMPbLEJHxO4asa2sdpvKyv1pYHHg8yLg2SbJgoi46Iv2VaXUdwCUUruUUuNKqQngP6njcDQOpdSz3utu4EZPhl3+EM973d1ouQJsALYqpXZBa7SZR1wbNf2+E5ErgZcBVyjPQeu5PfZ47+9A+7ZXNkqmItet6e0FICIO8MfAN/1tjW6zKB1BHe+zqazcfw+sEJFlnvV3ObC5GYJ4vrzPAw8opf4psD3oI3sFcG/4t3WWq11EOv336Mm4e9HtdKW325XATY2UK0SBNdXsNgsQ10abgdd70QxnAAf8YXUjEJE/At4HXKKUGgxsnyMitvd+ObACeKyBcsVdt83A5SKSFpFlnly/a5RcAV4MPKiUetrf0Mg2i9MR1PM+a8RMcb3+0DPKD6N73A82UY4XoodMdwN3en8XA18G7vG2bwb6GyzXcnSkwl3AfX4bAbOAW4Bt3mtfk9qtDdgDdAe2NbzN0J3LDmAUbTFdFddG6OHyv3n33D3AugbL9QjaF+vfZ5/19n2ld43vArYCL2+wXLHXDfig114PARsafS297V8E3hzat5FtFqcj6nafmfIDBoPBMA2Zym4Zg8FgMMRglLvBYDBMQ4xyNxgMhmmIUe4Gg8EwDTHK3WAwGKYhRrkbDAbDNMQod4PBYJiG/H84xUB848JhCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_plotter(cv_accs_trn, cv_accs_val, title='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T10:56:16.792374Z",
     "start_time": "2020-07-15T10:56:16.664701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Losses / epoch\")\n",
    "plt.plot(train_losses, label='Training Losses')\n",
    "plt.plot(val_losses, label='Validation Losses')\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T10:56:17.025751Z",
     "start_time": "2020-07-15T10:56:16.888118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Accuracy / epoch\")\n",
    "plt.plot(np.array(train_accs)/train_cnt, label='Training Accuracy')\n",
    "plt.plot(np.array(val_accs)/val_cnt, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T03:41:52.506532Z",
     "start_time": "2020-07-11T03:41:52.331979Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2, 6, 1, 6, 7, 5, 0, 2, 6, 5, 2, 0, 8, 7, 8, 7, 6, 3, 8, 8, 3, 7, 5, 8,\n",
       "        4, 6, 2, 8, 3, 3, 3, 1, 8, 3, 1, 1, 2, 1, 4, 3, 1, 6, 2, 9, 0, 1],\n",
       "       grad_fn=<NotImplemented>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-18T08:19:19.293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 0th Fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:88: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8860],\n",
      "        [-0.2666],\n",
      "        [-1.4569]], grad_fn=<SliceBackward>) tensor([20, 65, 18])\n",
      "tensor([[3.7514],\n",
      "        [2.5064],\n",
      "        [3.3119]], grad_fn=<SliceBackward>) tensor([73, 67, 74])\n",
      "tensor([[6.4337],\n",
      "        [7.1279],\n",
      "        [7.2359]], grad_fn=<SliceBackward>) tensor([68, 79, 63])\n",
      "tensor([[10.5921],\n",
      "        [ 9.4735],\n",
      "        [11.9652]], grad_fn=<SliceBackward>) tensor([90, 22, 60])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:88: UserWarning: Using a target size (torch.Size([111])) that is different to the input size (torch.Size([111, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14.7119],\n",
      "        [14.5639],\n",
      "        [16.4172]], grad_fn=<SliceBackward>) tensor([24, 23, 70])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pha\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:88: UserWarning: Using a target size (torch.Size([70])) that is different to the input size (torch.Size([70, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "[LOSS] train: 258.504, val: 52.225\n",
      "tensor([[18.1485],\n",
      "        [18.8382],\n",
      "        [17.6593]], grad_fn=<SliceBackward>) tensor([22, 64, 23])\n",
      "tensor([[21.3063],\n",
      "        [22.3260],\n",
      "        [21.4384]], grad_fn=<SliceBackward>) tensor([67, 53, 74])\n",
      "tensor([[28.2925],\n",
      "        [26.0352],\n",
      "        [29.0171]], grad_fn=<SliceBackward>) tensor([20, 81, 63])\n",
      "tensor([[32.1914],\n",
      "        [31.2046],\n",
      "        [32.3236]], grad_fn=<SliceBackward>) tensor([63, 80, 46])\n",
      "tensor([[35.1348],\n",
      "        [38.9005],\n",
      "        [38.1344]], grad_fn=<SliceBackward>) tensor([80, 62, 24])\n",
      "EPOCH: 1\n",
      "[LOSS] train: 168.073, val: 37.531\n",
      "tensor([[41.2028],\n",
      "        [36.8497],\n",
      "        [44.8961]], grad_fn=<SliceBackward>) tensor([66, 81, 59])\n",
      "tensor([[47.0528],\n",
      "        [48.3502],\n",
      "        [44.3552]], grad_fn=<SliceBackward>) tensor([70, 58, 67])\n",
      "tensor([[50.6605],\n",
      "        [49.2132],\n",
      "        [51.8926]], grad_fn=<SliceBackward>) tensor([94, 93, 45])\n",
      "tensor([[59.8185],\n",
      "        [56.6967],\n",
      "        [56.7938]], grad_fn=<SliceBackward>) tensor([86, 65, 73])\n",
      "tensor([[59.1147],\n",
      "        [66.4622],\n",
      "        [57.1058]], grad_fn=<SliceBackward>) tensor([66, 63, 70])\n",
      "EPOCH: 2\n",
      "[LOSS] train: 93.001, val: 17.872\n",
      "tensor([[69.2710],\n",
      "        [69.2797],\n",
      "        [60.0969]], grad_fn=<SliceBackward>) tensor([69, 75, 67])\n",
      "tensor([[65.9761],\n",
      "        [70.0278],\n",
      "        [62.6874]], grad_fn=<SliceBackward>) tensor([81, 68, 79])\n",
      "tensor([[72.3789],\n",
      "        [64.1838],\n",
      "        [64.6003]], grad_fn=<SliceBackward>) tensor([73, 65, 22])\n",
      "tensor([[60.5574],\n",
      "        [62.4938],\n",
      "        [66.1316]], grad_fn=<SliceBackward>) tensor([70, 67, 54])\n",
      "tensor([[57.5740],\n",
      "        [60.3821],\n",
      "        [61.5384]], grad_fn=<SliceBackward>) tensor([65, 73, 70])\n",
      "EPOCH: 3\n",
      "[LOSS] train: 76.224, val: 18.613\n",
      "tensor([[59.2303],\n",
      "        [57.1170],\n",
      "        [60.9884]], grad_fn=<SliceBackward>) tensor([74, 67, 84])\n",
      "tensor([[64.3897],\n",
      "        [62.6621],\n",
      "        [60.8676]], grad_fn=<SliceBackward>) tensor([62, 58, 62])\n",
      "tensor([[65.4422],\n",
      "        [61.2555],\n",
      "        [65.0291]], grad_fn=<SliceBackward>) tensor([71, 73, 90])\n",
      "tensor([[72.3924],\n",
      "        [66.8938],\n",
      "        [69.0008]], grad_fn=<SliceBackward>) tensor([22, 62, 72])\n",
      "tensor([[68.1057],\n",
      "        [62.4694],\n",
      "        [65.6634]], grad_fn=<SliceBackward>) tensor([22, 30, 68])\n",
      "EPOCH: 4\n",
      "[LOSS] train: 73.901, val: 16.17\n",
      "tensor([[63.8306],\n",
      "        [59.0745],\n",
      "        [59.6942]], grad_fn=<SliceBackward>) tensor([75, 26, 49])\n",
      "tensor([[60.0626],\n",
      "        [63.1202],\n",
      "        [60.2675]], grad_fn=<SliceBackward>) tensor([56, 65, 20])\n",
      "tensor([[61.6097],\n",
      "        [62.1516],\n",
      "        [55.2131]], grad_fn=<SliceBackward>) tensor([63, 22, 57])\n",
      "tensor([[53.7881],\n",
      "        [65.4124],\n",
      "        [53.7618]], grad_fn=<SliceBackward>) tensor([78, 73, 23])\n",
      "tensor([[59.0508],\n",
      "        [60.3657],\n",
      "        [62.5316]], grad_fn=<SliceBackward>) tensor([71, 49, 22])\n",
      "EPOCH: 5\n",
      "[LOSS] train: 72.632, val: 16.021\n",
      "tensor([[64.9661],\n",
      "        [60.4473],\n",
      "        [55.8896]], grad_fn=<SliceBackward>) tensor([70, 28, 22])\n",
      "tensor([[62.5259],\n",
      "        [60.5167],\n",
      "        [66.6774]], grad_fn=<SliceBackward>) tensor([20, 56, 67])\n",
      "tensor([[68.5627],\n",
      "        [74.5267],\n",
      "        [67.5904]], grad_fn=<SliceBackward>) tensor([61, 41, 78])\n",
      "tensor([[63.7911],\n",
      "        [57.8705],\n",
      "        [70.8004]], grad_fn=<SliceBackward>) tensor([65, 75, 85])\n",
      "tensor([[72.5680],\n",
      "        [67.7007],\n",
      "        [67.8933]], grad_fn=<SliceBackward>) tensor([57, 46, 65])\n",
      "EPOCH: 6\n",
      "[LOSS] train: 72.172, val: 15.654\n",
      "tensor([[62.9169],\n",
      "        [64.8055],\n",
      "        [63.3616]], grad_fn=<SliceBackward>) tensor([60, 54, 19])\n",
      "tensor([[61.8480],\n",
      "        [62.7508],\n",
      "        [58.5436]], grad_fn=<SliceBackward>) tensor([49, 89, 41])\n",
      "tensor([[65.2674],\n",
      "        [61.6718],\n",
      "        [63.4805]], grad_fn=<SliceBackward>) tensor([65, 74, 20])\n",
      "tensor([[63.6988],\n",
      "        [62.7648],\n",
      "        [62.4203]], grad_fn=<SliceBackward>) tensor([63, 61, 71])\n",
      "tensor([[63.1957],\n",
      "        [58.5624],\n",
      "        [60.8033]], grad_fn=<SliceBackward>) tensor([71, 73, 77])\n",
      "EPOCH: 7\n",
      "[LOSS] train: 71.769, val: 15.931\n",
      "tensor([[59.4736],\n",
      "        [61.4095],\n",
      "        [63.8378]], grad_fn=<SliceBackward>) tensor([24, 26, 49])\n",
      "tensor([[60.5845],\n",
      "        [62.7707],\n",
      "        [60.0331]], grad_fn=<SliceBackward>) tensor([19, 74, 23])\n",
      "tensor([[64.1489],\n",
      "        [68.2953],\n",
      "        [60.0561]], grad_fn=<SliceBackward>) tensor([52, 80, 65])\n",
      "tensor([[66.6574],\n",
      "        [60.5855],\n",
      "        [59.9256]], grad_fn=<SliceBackward>) tensor([73, 48, 49])\n",
      "tensor([[61.4197],\n",
      "        [64.2994],\n",
      "        [62.1827]], grad_fn=<SliceBackward>) tensor([67, 58, 62])\n",
      "EPOCH: 8\n",
      "[LOSS] train: 71.461, val: 15.867\n",
      "tensor([[67.2694],\n",
      "        [62.0829],\n",
      "        [66.7150]], grad_fn=<SliceBackward>) tensor([60, 48, 60])\n",
      "tensor([[65.8066],\n",
      "        [70.9178],\n",
      "        [63.3799]], grad_fn=<SliceBackward>) tensor([73, 72, 67])\n",
      "tensor([[67.3513],\n",
      "        [59.9806],\n",
      "        [62.6217]], grad_fn=<SliceBackward>) tensor([51, 72, 74])\n",
      "tensor([[58.7854],\n",
      "        [63.2368],\n",
      "        [65.9529]], grad_fn=<SliceBackward>) tensor([64, 48, 56])\n",
      "tensor([[60.9452],\n",
      "        [59.2023],\n",
      "        [66.4237]], grad_fn=<SliceBackward>) tensor([54, 67, 29])\n",
      "EPOCH: 9\n",
      "[LOSS] train: 71.905, val: 16.213\n",
      "tensor([[59.7736],\n",
      "        [61.7201],\n",
      "        [64.9339]], grad_fn=<SliceBackward>) tensor([26, 73, 30])\n",
      "tensor([[62.4882],\n",
      "        [65.3653],\n",
      "        [64.6190]], grad_fn=<SliceBackward>) tensor([65, 65, 69])\n",
      "tensor([[64.2643],\n",
      "        [63.8916],\n",
      "        [66.8843]], grad_fn=<SliceBackward>) tensor([68, 59, 64])\n",
      "tensor([[65.5219],\n",
      "        [67.1723],\n",
      "        [66.3526]], grad_fn=<SliceBackward>) tensor([71, 73, 76])\n",
      "tensor([[66.1360],\n",
      "        [61.1716],\n",
      "        [68.2510]], grad_fn=<SliceBackward>) tensor([68, 58, 75])\n",
      "EPOCH: 10\n",
      "[LOSS] train: 71.592, val: 16.629\n",
      "tensor([[60.6688],\n",
      "        [66.6177],\n",
      "        [67.1867]], grad_fn=<SliceBackward>) tensor([90, 69, 51])\n",
      "tensor([[62.9425],\n",
      "        [63.9699],\n",
      "        [70.1417]], grad_fn=<SliceBackward>) tensor([65, 71, 67])\n",
      "tensor([[66.7873],\n",
      "        [67.4260],\n",
      "        [69.3402]], grad_fn=<SliceBackward>) tensor([67, 75, 73])\n",
      "tensor([[61.5295],\n",
      "        [67.3853],\n",
      "        [65.5994]], grad_fn=<SliceBackward>) tensor([67, 70, 48])\n",
      "tensor([[63.1802],\n",
      "        [65.6568],\n",
      "        [65.0825]], grad_fn=<SliceBackward>) tensor([50, 63, 68])\n",
      "EPOCH: 11\n",
      "[LOSS] train: 71.182, val: 17.392\n",
      "tensor([[62.7499],\n",
      "        [60.9174],\n",
      "        [64.7761]], grad_fn=<SliceBackward>) tensor([59, 59, 58])\n",
      "tensor([[58.9799],\n",
      "        [61.1859],\n",
      "        [61.6637]], grad_fn=<SliceBackward>) tensor([78, 80, 66])\n",
      "tensor([[57.2742],\n",
      "        [57.5310],\n",
      "        [60.5185]], grad_fn=<SliceBackward>) tensor([72, 59, 65])\n",
      "tensor([[58.1403],\n",
      "        [63.4683],\n",
      "        [63.6953]], grad_fn=<SliceBackward>) tensor([58, 62, 71])\n",
      "tensor([[66.0533],\n",
      "        [64.7768],\n",
      "        [63.0370]], grad_fn=<SliceBackward>) tensor([80, 22, 21])\n",
      "EPOCH: 12\n",
      "[LOSS] train: 71.679, val: 18.512\n",
      "tensor([[63.4494],\n",
      "        [63.3417],\n",
      "        [63.5383]], grad_fn=<SliceBackward>) tensor([23, 61, 86])\n",
      "tensor([[62.5568],\n",
      "        [63.5996],\n",
      "        [63.9994]], grad_fn=<SliceBackward>) tensor([57, 64, 80])\n",
      "tensor([[67.2294],\n",
      "        [64.5617],\n",
      "        [62.5720]], grad_fn=<SliceBackward>) tensor([53, 88, 90])\n",
      "tensor([[60.5942],\n",
      "        [61.6323],\n",
      "        [63.6082]], grad_fn=<SliceBackward>) tensor([25, 40, 59])\n",
      "tensor([[66.9774],\n",
      "        [64.1211],\n",
      "        [64.8212]], grad_fn=<SliceBackward>) tensor([56, 74, 69])\n",
      "EPOCH: 13\n",
      "[LOSS] train: 70.793, val: 18.745\n",
      "tensor([[64.8610],\n",
      "        [66.0165],\n",
      "        [63.0667]], grad_fn=<SliceBackward>) tensor([50, 67, 73])\n",
      "tensor([[63.9472],\n",
      "        [63.7468],\n",
      "        [62.8100]], grad_fn=<SliceBackward>) tensor([21, 65, 72])\n",
      "tensor([[65.1823],\n",
      "        [62.3699],\n",
      "        [59.0900]], grad_fn=<SliceBackward>) tensor([57, 62, 65])\n",
      "tensor([[66.7854],\n",
      "        [64.1657],\n",
      "        [60.4252]], grad_fn=<SliceBackward>) tensor([64, 60, 71])\n",
      "tensor([[67.4347],\n",
      "        [62.2027],\n",
      "        [64.2493]], grad_fn=<SliceBackward>) tensor([18, 59, 71])\n",
      "EPOCH: 14\n",
      "[LOSS] train: 71.347, val: 19.308\n",
      "tensor([[64.2873],\n",
      "        [61.1794],\n",
      "        [64.0984]], grad_fn=<SliceBackward>) tensor([60, 79, 28])\n",
      "tensor([[58.3015],\n",
      "        [64.1215],\n",
      "        [67.4537]], grad_fn=<SliceBackward>) tensor([18, 59, 49])\n",
      "tensor([[68.0217],\n",
      "        [67.2430],\n",
      "        [62.9669]], grad_fn=<SliceBackward>) tensor([70, 63, 55])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[63.6575],\n",
      "        [69.3416],\n",
      "        [64.9629]], grad_fn=<SliceBackward>) tensor([63, 54, 21])\n",
      "tensor([[59.7338],\n",
      "        [63.7904],\n",
      "        [65.8307]], grad_fn=<SliceBackward>) tensor([73, 65, 73])\n",
      "EPOCH: 15\n",
      "[LOSS] train: 70.82, val: 19.366\n",
      "tensor([[68.1098],\n",
      "        [60.2084],\n",
      "        [60.8114]], grad_fn=<SliceBackward>) tensor([64, 48, 94])\n",
      "tensor([[65.0466],\n",
      "        [63.4110],\n",
      "        [64.2477]], grad_fn=<SliceBackward>) tensor([59, 73, 51])\n",
      "tensor([[62.1667],\n",
      "        [69.3335],\n",
      "        [65.3916]], grad_fn=<SliceBackward>) tensor([69, 68, 72])\n",
      "tensor([[66.0738],\n",
      "        [64.6467],\n",
      "        [66.0893]], grad_fn=<SliceBackward>) tensor([23, 68, 59])\n",
      "tensor([[61.8784],\n",
      "        [66.2549],\n",
      "        [65.0042]], grad_fn=<SliceBackward>) tensor([74, 43, 34])\n",
      "EPOCH: 16\n",
      "[LOSS] train: 71.482, val: 20.144\n",
      "tensor([[67.3831],\n",
      "        [62.2787],\n",
      "        [61.6711]], grad_fn=<SliceBackward>) tensor([80, 68, 74])\n",
      "tensor([[62.4887],\n",
      "        [61.3032],\n",
      "        [61.5157]], grad_fn=<SliceBackward>) tensor([67, 65, 74])\n",
      "tensor([[60.4197],\n",
      "        [64.1049],\n",
      "        [65.1870]], grad_fn=<SliceBackward>) tensor([78, 26, 74])\n",
      "tensor([[64.4351],\n",
      "        [60.3069],\n",
      "        [57.4532]], grad_fn=<SliceBackward>) tensor([62, 82, 20])\n",
      "tensor([[63.5427],\n",
      "        [66.7301],\n",
      "        [66.4458]], grad_fn=<SliceBackward>) tensor([79, 28, 72])\n",
      "EPOCH: 17\n",
      "[LOSS] train: 71.23, val: 21.121\n",
      "tensor([[62.7781],\n",
      "        [64.1686],\n",
      "        [66.3518]], grad_fn=<SliceBackward>) tensor([80, 26, 20])\n",
      "tensor([[66.8764],\n",
      "        [66.1996],\n",
      "        [66.8460]], grad_fn=<SliceBackward>) tensor([22, 21, 75])\n",
      "tensor([[66.4215],\n",
      "        [61.6611],\n",
      "        [67.4265]], grad_fn=<SliceBackward>) tensor([53, 70, 81])\n",
      "tensor([[66.0498],\n",
      "        [63.6034],\n",
      "        [67.0532]], grad_fn=<SliceBackward>) tensor([74, 74, 78])\n",
      "tensor([[64.7655],\n",
      "        [63.2233],\n",
      "        [63.5974]], grad_fn=<SliceBackward>) tensor([86, 73, 60])\n",
      "EPOCH: 18\n",
      "[LOSS] train: 71.332, val: 20.99\n",
      "tensor([[65.0991],\n",
      "        [64.7474],\n",
      "        [66.2940]], grad_fn=<SliceBackward>) tensor([73, 27, 51])\n",
      "tensor([[68.2087],\n",
      "        [62.7852],\n",
      "        [58.9596]], grad_fn=<SliceBackward>) tensor([71, 72, 65])\n",
      "tensor([[63.3090],\n",
      "        [56.7409],\n",
      "        [64.5453]], grad_fn=<SliceBackward>) tensor([75, 67, 22])\n",
      "tensor([[61.7490],\n",
      "        [67.6141],\n",
      "        [56.7090]], grad_fn=<SliceBackward>) tensor([65, 68, 87])\n",
      "tensor([[63.2779],\n",
      "        [62.6679],\n",
      "        [61.8489]], grad_fn=<SliceBackward>) tensor([66, 60, 50])\n",
      "EPOCH: 19\n",
      "[LOSS] train: 71.243, val: 21.224\n",
      "tensor([[65.1779],\n",
      "        [61.0753],\n",
      "        [60.4375]], grad_fn=<SliceBackward>) tensor([58, 20, 69])\n",
      "tensor([[63.2531],\n",
      "        [61.8236],\n",
      "        [63.7604]], grad_fn=<SliceBackward>) tensor([30, 20, 49])\n",
      "tensor([[68.6853],\n",
      "        [67.8869],\n",
      "        [67.0185]], grad_fn=<SliceBackward>) tensor([68, 20, 69])\n",
      "tensor([[67.3147],\n",
      "        [65.4502],\n",
      "        [63.2960]], grad_fn=<SliceBackward>) tensor([78, 69, 74])\n",
      "tensor([[63.2687],\n",
      "        [68.1547],\n",
      "        [68.9327]], grad_fn=<SliceBackward>) tensor([21, 65, 80])\n",
      "EPOCH: 20\n",
      "[LOSS] train: 71.693, val: 20.675\n",
      "tensor([[64.4570],\n",
      "        [63.8615],\n",
      "        [62.5556]], grad_fn=<SliceBackward>) tensor([72, 55, 65])\n",
      "tensor([[64.8361],\n",
      "        [63.0470],\n",
      "        [65.4810]], grad_fn=<SliceBackward>) tensor([74, 54, 60])\n",
      "tensor([[65.5946],\n",
      "        [64.6298],\n",
      "        [64.6042]], grad_fn=<SliceBackward>) tensor([69, 80, 68])\n",
      "tensor([[61.9973],\n",
      "        [64.5785],\n",
      "        [64.8162]], grad_fn=<SliceBackward>) tensor([66, 75, 46])\n",
      "tensor([[64.7715],\n",
      "        [62.7625],\n",
      "        [65.1993]], grad_fn=<SliceBackward>) tensor([65, 62, 61])\n",
      "EPOCH: 21\n",
      "[LOSS] train: 70.996, val: 20.15\n",
      "tensor([[61.6121],\n",
      "        [65.5176],\n",
      "        [63.1632]], grad_fn=<SliceBackward>) tensor([79, 23, 46])\n",
      "tensor([[62.8060],\n",
      "        [60.1545],\n",
      "        [62.7621]], grad_fn=<SliceBackward>) tensor([48, 53, 68])\n",
      "tensor([[62.3614],\n",
      "        [60.0874],\n",
      "        [60.8695]], grad_fn=<SliceBackward>) tensor([69, 51, 78])\n",
      "tensor([[62.4385],\n",
      "        [65.6099],\n",
      "        [61.3390]], grad_fn=<SliceBackward>) tensor([65, 68, 21])\n",
      "tensor([[61.2324],\n",
      "        [64.0012],\n",
      "        [63.7721]], grad_fn=<SliceBackward>) tensor([69, 64, 65])\n",
      "EPOCH: 22\n",
      "[LOSS] train: 70.875, val: 19.892\n",
      "tensor([[62.9379],\n",
      "        [63.2235],\n",
      "        [61.6425]], grad_fn=<SliceBackward>) tensor([67, 71, 71])\n",
      "tensor([[63.6005],\n",
      "        [66.2809],\n",
      "        [66.3846]], grad_fn=<SliceBackward>) tensor([61, 52, 51])\n",
      "tensor([[67.3750],\n",
      "        [64.0664],\n",
      "        [67.0414]], grad_fn=<SliceBackward>) tensor([60, 75, 59])\n",
      "tensor([[66.5353],\n",
      "        [65.9727],\n",
      "        [67.3921]], grad_fn=<SliceBackward>) tensor([58, 43, 70])\n",
      "tensor([[68.1632],\n",
      "        [66.2198],\n",
      "        [69.0864]], grad_fn=<SliceBackward>) tensor([67, 48, 69])\n",
      "EPOCH: 23\n",
      "[LOSS] train: 71.612, val: 19.525\n",
      "tensor([[66.0443],\n",
      "        [61.8005],\n",
      "        [61.7414]], grad_fn=<SliceBackward>) tensor([71, 72, 69])\n",
      "tensor([[61.9609],\n",
      "        [61.9089],\n",
      "        [63.5840]], grad_fn=<SliceBackward>) tensor([20, 69, 73])\n",
      "tensor([[63.9266],\n",
      "        [64.2578],\n",
      "        [67.1719]], grad_fn=<SliceBackward>) tensor([54, 78, 76])\n",
      "tensor([[63.6506],\n",
      "        [59.7095],\n",
      "        [61.0678]], grad_fn=<SliceBackward>) tensor([73, 18, 66])\n",
      "tensor([[55.9783],\n",
      "        [62.2188],\n",
      "        [63.5610]], grad_fn=<SliceBackward>) tensor([80, 25, 73])\n",
      "EPOCH: 24\n",
      "[LOSS] train: 71.215, val: 20.132\n",
      "tensor([[59.5779],\n",
      "        [63.1377],\n",
      "        [61.3757]], grad_fn=<SliceBackward>) tensor([68, 79, 60])\n",
      "tensor([[64.1432],\n",
      "        [61.4988],\n",
      "        [60.5263]], grad_fn=<SliceBackward>) tensor([57, 56, 70])\n"
     ]
    }
   ],
   "source": [
    "conv = ConvNet(ctype='regression')\n",
    "\n",
    "EPOCHS = range(200)\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = optim.Adam(conv.parameters(), lr=.001)\n",
    "\n",
    "cv_loss_trn, cv_loss_val = [], []\n",
    "cv_accs_trn, cv_accs_val = [], []\n",
    "for i, (trn_idx, val_idx) in enumerate(kfold.split(X_train)):\n",
    "    print(\"Working on {}th Fold\".format(i))\n",
    "    \n",
    "    train_reg_ds = TensorDataset(X_train[trn_idx], y_reg_train[trn_idx])\n",
    "    val_reg_ds = TensorDataset(X_train[val_idx], y_reg_train[val_idx])\n",
    "    \n",
    "    train_reg_loader = DataLoader(train_reg_ds, batch_size=128, shuffle=True)\n",
    "    val_reg_loader = DataLoader(val_reg_ds, batch_size=128, shuffle=True)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    for epoch in EPOCHS:\n",
    "\n",
    "        train_batch_loss = 0\n",
    "        cnt = 0\n",
    "        conv.train()\n",
    "        for x, y in train_reg_loader:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = conv(x)\n",
    "\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(y_pred[:3], y[:3])\n",
    "\n",
    "            train_batch_loss += loss.item()\n",
    "            cnt += 1\n",
    "\n",
    "        train_losses.append(train_batch_loss / cnt)\n",
    "\n",
    "        val_batch_loss = 0\n",
    "        cnt = 0\n",
    "        conv.eval()\n",
    "        for x, y in val_reg_loader:\n",
    "            y_pred = conv(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "\n",
    "            val_batch_loss += loss.item()\n",
    "            cnt += 1\n",
    "\n",
    "        val_losses.append(val_batch_loss / cnt)\n",
    "\n",
    "        print(\"EPOCH: {}\".format(epoch))\n",
    "        print(\"[LOSS] train: {}, val: {}\".format(round(train_batch_loss,3), round(val_batch_loss, 3)))\n",
    "        \n",
    "    cv_loss_trn.append(train_losses)\n",
    "    \n",
    "    cv_loss_val.append(val_losses)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T06:16:53.297065Z",
     "start_time": "2020-07-08T06:16:53.162321Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ConvNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b90400406e19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_accs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_accs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ConvNet' is not defined"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "conv = ConvNet(ctype='binary')\n",
    "\n",
    "EPOCHS = range(100)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(conv.parameters(), lr=.001)\n",
    "\n",
    "for epoch in EPOCHS:\n",
    "    \n",
    "    train_batch_loss, train_batch_acc, train_cnt = 0, 0, 0\n",
    "    conv.train()\n",
    "    for x, y in train_binary_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = conv(x)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print(\"Prediction: {}\".format(conv(x).argmax(axis=1)))\n",
    "        #print(\"True Value: {}\".format(y))\n",
    "        tmp_acc, tmp_t, tmp_cf = acc_binary(y_pred, y)\n",
    "        train_batch_acc += tmp_acc\n",
    "        train_cnt += tmp_t\n",
    "        \n",
    "        train_batch_loss += loss.item()\n",
    "    \n",
    "    train_losses.append(train_batch_loss)\n",
    "    train_accs.append(train_batch_acc)\n",
    "    \n",
    "    val_batch_loss, val_batch_acc, val_cnt = 0, 0, 0\n",
    "    conv.eval()\n",
    "    for x, y in test_binary_loader:\n",
    "        y_pred = conv(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        \n",
    "        tmp_acc, tmp_t, tmp_cf = acc_binary(y_pred, y)\n",
    "        val_batch_acc += tmp_acc\n",
    "        val_cnt += tmp_t\n",
    "        \n",
    "        val_batch_loss += loss.item()\n",
    "        \n",
    "    val_losses.append(val_batch_loss)\n",
    "    val_accs.append(val_batch_acc)\n",
    "    \n",
    "    print(\"EPOCH: {}\".format(epoch))\n",
    "    print(\"[LOSS] train: {}, val: {}\".format(round(train_batch_loss,3), round(val_batch_loss, 3)))\n",
    "    print(\"[ACC%] train: {}%, val: {}%\"\n",
    "          .format(round(train_batch_acc/train_cnt * 100, 2), round(val_batch_acc/val_cnt * 100, 2)))\n",
    "    #print(\"Prediction: {}\".format(conv(xx).argmax(axis=1)))\n",
    "    #print(\"True Value: {}\".format(yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T05:51:56.321973Z",
     "start_time": "2020-07-07T05:51:56.315216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1976)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.tensor([0.1, 0.2, 0.3, 0.9], dtype=torch.float)\n",
    "true = torch.tensor([0, 0, 0, 1], dtype=torch.float)\n",
    "loss_fn(pred, true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
